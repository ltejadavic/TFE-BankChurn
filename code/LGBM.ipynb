{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d491bbf6",
   "metadata": {},
   "source": [
    "1 — Imports, configuración y rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8711fa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp: LGBM_FULL_SMOTENC\n",
      "DATA_DIR: /Users/luistejada/Downloads/TFE Churn Bancario/preproc_datasets/full\n",
      "ARTIF_DIR: /Users/luistejada/Downloads/TFE Churn Bancario/artifacts/LGBM_FULL_SMOTENC\n"
     ]
    }
   ],
   "source": [
    "# 1 — Imports, configuración y rutas\n",
    "import json, os, warnings, time, re, glob\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score, precision_recall_curve, roc_auc_score, roc_curve,\n",
    "    f1_score, recall_score, balanced_accuracy_score, confusion_matrix, precision_score\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Balanceo (SMOTENC)\n",
    "from imblearn.over_sampling import SMOTENC, SMOTE\n",
    "\n",
    "# LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "try:\n",
    "    from lightgbm import early_stopping, log_evaluation\n",
    "    _LGBM_CB_OK = True\n",
    "except Exception:\n",
    "    _LGBM_CB_OK = False\n",
    "\n",
    "# === Toggles de experimento ===\n",
    "USE_REDUCED = False\n",
    "USE_BALANCED_TRAIN = True\n",
    "BALANCE_IN_CV = True\n",
    "RANDOM_STATE = 42\n",
    "DO_TUNE = True\n",
    "DO_CV_BASELINE = True\n",
    "DO_CV_TUNED = True\n",
    "CV_FOLDS = 5\n",
    "MI_TOPK = 30\n",
    "\n",
    "# === Nombres y rutas ===\n",
    "ROOT = Path.cwd().parent\n",
    "EXP_NAME = f\"LGBM_{'REDUCED' if USE_REDUCED else 'FULL'}_{'SMOTENC' if USE_BALANCED_TRAIN else 'IMB'}\"\n",
    "ARTIF_DIR = ROOT / \"artifacts\" / EXP_NAME\n",
    "OUT_RESULTS = ARTIF_DIR / \"results\"\n",
    "OUT_FIGS    = ARTIF_DIR / \"figs\"\n",
    "OUT_PREDS   = ARTIF_DIR / \"preds\"\n",
    "OUT_PARAMS  = ARTIF_DIR / \"best_params\"\n",
    "for p in [OUT_RESULTS, OUT_FIGS, OUT_PREDS, OUT_PARAMS]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Dataset preprocesado\n",
    "DATA_DIR = ROOT / \"preproc_datasets\" / \"full\"\n",
    "\n",
    "print(\"Exp:\", EXP_NAME)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"ARTIF_DIR:\", ARTIF_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7446ed3f",
   "metadata": {},
   "source": [
    "2 — Carga de artefactos (X, y, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f75a6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (6000, 15) (2000, 15) (2000, 15)\n",
      "y train/val/test: (6000,) (2000,) (2000,)\n",
      "n features: 15\n"
     ]
    }
   ],
   "source": [
    "def load_xy_full(dir_full: Path):\n",
    "    X_train = np.load(dir_full / \"X_train_full.npy\")\n",
    "    X_val   = np.load(dir_full / \"X_val_full.npy\")\n",
    "    X_test  = np.load(dir_full / \"X_test_full.npy\")\n",
    "\n",
    "    y_train = pd.read_parquet(dir_full / \"y_train.parquet\")[\"Exited\"].to_numpy()\n",
    "    y_val   = pd.read_parquet(dir_full / \"y_val.parquet\")[\"Exited\"].to_numpy()\n",
    "    y_test  = pd.read_parquet(dir_full / \"y_test.parquet\")[\"Exited\"].to_numpy()\n",
    "\n",
    "    feat = pd.read_parquet(dir_full / \"feature_names_full.parquet\")[\"feature\"].tolist()\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, feat\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, feature_names = load_xy_full(DATA_DIR)\n",
    "print(\"Shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "print(\"y train/val/test:\", y_train.shape, y_val.shape, y_test.shape)\n",
    "print(\"n features:\", len(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2296ece1",
   "metadata": {},
   "source": [
    "3 — Métricas y selección de umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "152bf567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_auc(y_true, y_proba): \n",
    "    return float(average_precision_score(y_true, y_proba))\n",
    "\n",
    "def roc_auc(y_true, y_proba): \n",
    "    return float(roc_auc_score(y_true, y_proba))\n",
    "\n",
    "def find_best_threshold(y_true, y_proba, metric=\"f1\"):\n",
    "    thr_grid = np.linspace(0.0, 1.0, 1001)\n",
    "    best_thr, best_score = 0.5, -1.0\n",
    "    for thr in thr_grid:\n",
    "        y_pred = (y_proba >= thr).astype(int)\n",
    "        if metric == \"f1\":\n",
    "            score = f1_score(y_true, y_pred, zero_division=0)\n",
    "        elif metric == \"recall\":\n",
    "            score = recall_score(y_true, y_pred, zero_division=0)\n",
    "        else:\n",
    "            raise ValueError(\"metric no soportada\")\n",
    "        if score > best_score:\n",
    "            best_score, best_thr = score, thr\n",
    "    return float(best_thr), float(best_score)\n",
    "\n",
    "def compute_all_metrics(y_true, y_proba, thr):\n",
    "    y_pred = (y_proba >= thr).astype(int)\n",
    "    return {\n",
    "        \"pr_auc\": pr_auc(y_true, y_proba),\n",
    "        \"roc_auc\": roc_auc(y_true, y_proba),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"bal_acc\": balanced_accuracy_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "def sanitize_params(p, use_balanced_train=True):\n",
    "    p = dict(p)\n",
    "    p.pop(\"verbose\", None)\n",
    "    p.setdefault(\"verbosity\", -1)\n",
    "    p[\"metric\"] = \"average_precision\"\n",
    "    if use_balanced_train:\n",
    "        p[\"class_weight\"] = None\n",
    "    return p\n",
    "\n",
    "def pred_proba_best(mdl, X):\n",
    "    \"\"\"Usa siempre la mejor iteración si existe (blindaje para reloads).\"\"\"\n",
    "    it = getattr(mdl, \"best_iteration_\", None)\n",
    "    if it is not None:\n",
    "        return mdl.predict_proba(X, num_iteration=it)[:, 1]\n",
    "    return mdl.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e8131",
   "metadata": {},
   "source": [
    "4 - Helpers MI Top-K y balanceo in-memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6afc2bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from imblearn.over_sampling import SMOTENC, SMOTE\n",
    "\n",
    "def fit_mi_selector(X_tr, y_tr, topk=30, seed=42):\n",
    "    mi = mutual_info_classif(X_tr, y_tr, random_state=seed)\n",
    "    order = np.argsort(mi)[::-1][:min(topk, X_tr.shape[1])]\n",
    "    return order, mi\n",
    "\n",
    "def apply_keep_idx(X, keep_idx):\n",
    "    return X[:, keep_idx] if keep_idx is not None else X\n",
    "\n",
    "def _bool_mask_from_indices(indices, n_features):\n",
    "    mask = np.zeros(n_features, dtype=bool)\n",
    "    mask[np.asarray(indices, dtype=int)] = True\n",
    "    return mask\n",
    "\n",
    "def load_categorical_mask(dir_full, feature_names, X_sample=None):\n",
    "    n_features = len(feature_names)\n",
    "\n",
    "    # 1) feature_names_full.parquet con is_cat\n",
    "    fn_parq = dir_full / \"feature_names_full.parquet\"\n",
    "    if fn_parq.exists():\n",
    "        df = pd.read_parquet(fn_parq)\n",
    "        if \"is_cat\" in df.columns:\n",
    "            m = df[\"is_cat\"].astype(bool).to_numpy()\n",
    "            if len(m) == n_features:\n",
    "                print(\"[CAT] Cargado is_cat desde feature_names_full.parquet\")\n",
    "                return m\n",
    "\n",
    "    # 2) JSONs con índices o máscara\n",
    "    for jname in [\"categorical_indices_full.json\", \"categorical_indices.json\",\n",
    "                  \"categorical_features_full.json\", \"categorical_features.json\",\n",
    "                  \"preproc_meta.json\", \"enc_meta.json\", \"metadata.json\"]:\n",
    "        f = dir_full / jname\n",
    "        if f.exists():\n",
    "            try:\n",
    "                data = json.loads(f.read_text())\n",
    "                for key in [\"categorical_indices\", \"cat_indices\", \"categorical_features\", \"categorical_cols_idx\"]:\n",
    "                    if key in data:\n",
    "                        idx = data[key]\n",
    "                        if isinstance(idx, dict) and \"indices\" in idx:\n",
    "                            idx = idx[\"indices\"]\n",
    "                        mask = _bool_mask_from_indices(idx, n_features)\n",
    "                        print(f\"[CAT] Cargado índices categóricos desde {jname} clave '{key}'\")\n",
    "                        return mask\n",
    "                for key in [\"categorical_mask\", \"categorical_features_mask\", \"is_cat_mask\"]:\n",
    "                    if key in data and len(data[key]) == n_features:\n",
    "                        print(f\"[CAT] Cargada máscara categórica desde {jname} clave '{key}'\")\n",
    "                        return np.asarray(data[key], dtype=bool)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # 3) NPY de máscara\n",
    "    for nname in [\"categorical_mask_full.npy\", \"categorical_mask.npy\", \"cat_mask_full.npy\", \"cat_mask.npy\"]:\n",
    "        f = dir_full / nname\n",
    "        if f.exists():\n",
    "            m = np.load(f)\n",
    "            if m.shape[0] == n_features:\n",
    "                print(f\"[CAT] Cargada máscara categórica desde {nname}\")\n",
    "                return m.astype(bool)\n",
    "\n",
    "    # 4) Fallback heurístico\n",
    "    print(\"[CAT] Metadatos categóricos no encontrados. Usando heurística...\")\n",
    "    if X_sample is None:\n",
    "        return np.zeros(n_features, dtype=bool)\n",
    "\n",
    "    n = min(20000, X_sample.shape[0])\n",
    "    sample = X_sample[:n]\n",
    "    mask = np.zeros(n_features, dtype=bool)\n",
    "    for j in range(n_features):\n",
    "        vals = np.unique(sample[:, j])\n",
    "        if vals.size <= 2 and np.all(np.isin(vals, [0, 1])):\n",
    "            mask[j] = True\n",
    "        elif vals.size <= 10 and np.allclose(vals, np.round(vals), atol=1e-6):\n",
    "            mask[j] = True\n",
    "    print(f\"[CAT] Heurística: {mask.sum()} columnas categóricas detectadas de {n_features}\")\n",
    "    return mask\n",
    "\n",
    "def reduce_mask(mask, keep_idx):\n",
    "    if keep_idx is None:\n",
    "        return mask\n",
    "    if mask is None:\n",
    "        return None\n",
    "    mask = np.asarray(mask)\n",
    "    return mask[keep_idx]\n",
    "\n",
    "def _to_cat_indices(categorical_mask, n_features):\n",
    "    if categorical_mask is None:\n",
    "        return []\n",
    "    arr = np.asarray(categorical_mask)\n",
    "\n",
    "    if arr.dtype == bool:\n",
    "        if arr.shape[0] != n_features:\n",
    "            raise ValueError(\n",
    "                f\"categorical_mask length ({arr.shape[0]}) != n_features ({n_features})\"\n",
    "            )\n",
    "        return np.flatnonzero(arr).tolist()\n",
    "\n",
    "    return [int(i) for i in arr.ravel().tolist()]\n",
    "\n",
    "def maybe_resample(X_tr, y_tr, categorical_mask=None, RANDOM_STATE=42):\n",
    "\n",
    "    cat_idx = _to_cat_indices(categorical_mask, X_tr.shape[1]) if categorical_mask is not None else []\n",
    "\n",
    "    if len(cat_idx) == 0:\n",
    "        sm = SMOTE(random_state=RANDOM_STATE)\n",
    "        return sm.fit_resample(X_tr, y_tr)\n",
    "    else:\n",
    "        sm = SMOTENC(categorical_features=cat_idx, random_state=RANDOM_STATE)\n",
    "        return sm.fit_resample(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87a1100",
   "metadata": {},
   "source": [
    "5 — Hiperparámetros persistentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "08947fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HP] Cargando mejores hiperparámetros previos: BEST_LGBM_FULL_SMOTENC.json\n"
     ]
    }
   ],
   "source": [
    "VIEW_TAG = \"REDUCED\" if USE_REDUCED else \"FULL\"\n",
    "BAL_TAG  = \"SMOTENC\" if USE_BALANCED_TRAIN else \"IMB\"\n",
    "BEST_HP_FILE = OUT_PARAMS / f\"BEST_LGBM_{VIEW_TAG}_{BAL_TAG}.json\"\n",
    "\n",
    "def get_lgbm_defaults(seed=RANDOM_STATE):\n",
    "    mdl = LGBMClassifier(random_state=seed)\n",
    "    return mdl.get_params()\n",
    "\n",
    "def load_best_or_default():\n",
    "    if BEST_HP_FILE.exists():\n",
    "        try:\n",
    "            best = json.loads(BEST_HP_FILE.read_text())\n",
    "            print(\"[HP] Cargando mejores hiperparámetros previos:\", BEST_HP_FILE.name)\n",
    "            base = get_lgbm_defaults()\n",
    "            base.update(best)\n",
    "            return base, True\n",
    "        except Exception as e:\n",
    "            print(\"[HP] Aviso: no se pudo leer BEST (uso defaults).\", e)\n",
    "    print(\"[HP] Usando hiperparámetros DEFAULT.\")\n",
    "    return get_lgbm_defaults(), False\n",
    "\n",
    "seed_params, loaded_best_flag = load_best_or_default()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7ba43",
   "metadata": {},
   "source": [
    "6 — Entrenamiento BASELINE partiendo del seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e116a051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CAT] Metadatos categóricos no encontrados. Usando heurística...\n",
      "[CAT] Heurística: 10 columnas categóricas detectadas de 15\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.669681\n",
      "[100]\tvalid_0's average_precision: 0.68309\n",
      "[150]\tvalid_0's average_precision: 0.691147\n",
      "[200]\tvalid_0's average_precision: 0.694647\n",
      "[250]\tvalid_0's average_precision: 0.69566\n",
      "[300]\tvalid_0's average_precision: 0.69594\n",
      "[350]\tvalid_0's average_precision: 0.693782\n",
      "[400]\tvalid_0's average_precision: 0.692243\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's average_precision: 0.696435\n",
      "[BASELINE] best_iteration: 236\n",
      "[BASELINE] Mejor umbral (val) por F1: 0.392 | F1(val)=0.6394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pr_auc': 0.6964347470013181,\n",
       " 'roc_auc': 0.8585935704579772,\n",
       " 'precision': 0.5953389830508474,\n",
       " 'f1': 0.6393629124004551,\n",
       " 'recall': 0.6904176904176904,\n",
       " 'bal_acc': 0.7852590649200819}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6 — Entrenamiento BASELINE partiendo del seed\n",
    "_fit_kwargs = {}\n",
    "_callbacks = []\n",
    "if _LGBM_CB_OK:\n",
    "    _callbacks = [early_stopping(stopping_rounds=200), log_evaluation(period=50)]\n",
    "else:\n",
    "    _fit_kwargs[\"early_stopping_rounds\"] = 200\n",
    "\n",
    "# Asegurar compatibilidad de parámetros y evitar class_weight cuando hay sobre-muestreo\n",
    "seed_params = sanitize_params(seed_params, use_balanced_train=USE_BALANCED_TRAIN)\n",
    "\n",
    "# === Cargar máscara categórica desde metadatos del preprocesamiento ===\n",
    "CAT_MASK_FULL = load_categorical_mask(DATA_DIR, feature_names, X_sample=X_train)\n",
    "\n",
    "# === Reducción MI Top-K ===\n",
    "keep_idx_global = None\n",
    "feature_names_used = feature_names\n",
    "X_train_fit, X_val_fit, X_test_fit = X_train, X_val, X_test\n",
    "\n",
    "if USE_REDUCED:\n",
    "    keep_idx_global, _mi = fit_mi_selector(X_train, y_train, topk=MI_TOPK, seed=RANDOM_STATE)\n",
    "    X_train_fit = apply_keep_idx(X_train, keep_idx_global)\n",
    "    X_val_fit   = apply_keep_idx(X_val,   keep_idx_global)\n",
    "    X_test_fit  = apply_keep_idx(X_test,  keep_idx_global)\n",
    "    feature_names_used = [feature_names[i] for i in keep_idx_global]\n",
    "\n",
    "# máscara alineada con las features\n",
    "CAT_MASK_USED = reduce_mask(CAT_MASK_FULL, keep_idx_global)\n",
    "\n",
    "# === Balanceo SOLO en train ===\n",
    "X_train_final, y_train_final = X_train_fit, y_train\n",
    "if USE_BALANCED_TRAIN:\n",
    "    X_train_final, y_train_final = maybe_resample(X_train_fit, y_train, categorical_mask=CAT_MASK_USED)\n",
    "\n",
    "model = LGBMClassifier(**seed_params)\n",
    "\n",
    "_fit_call = dict(\n",
    "    eval_set=[(X_val_fit, y_val)],\n",
    "    eval_metric=\"aucpr\",\n",
    "    **_fit_kwargs\n",
    ")\n",
    "if _LGBM_CB_OK:\n",
    "    _fit_call[\"callbacks\"] = _callbacks\n",
    "\n",
    "model.fit(X_train_final, y_train_final, **_fit_call)\n",
    "\n",
    "best_iter = getattr(model, \"best_iteration_\", None)\n",
    "print(f\"[BASELINE] best_iteration: {best_iter}\")\n",
    "\n",
    "# Validación y umbral óptimo\n",
    "proba_val = pred_proba_best(model, X_val_fit)\n",
    "thr_val, best_f1_val = find_best_threshold(y_val, proba_val, metric=\"f1\")\n",
    "print(f\"[BASELINE] Mejor umbral (val) por F1: {thr_val:.3f} | F1(val)={best_f1_val:.4f}\")\n",
    "\n",
    "val_metrics = compute_all_metrics(y_val, proba_val, thr_val)\n",
    "val_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f8ea81",
   "metadata": {},
   "source": [
    "7 - Optimización incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0b47f482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:45:45,998] A new study created in memory with name: LGBM_FULL_SMOTENC_AP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OPTUNA] Iniciando estudio 'LGBM_FULL_SMOTENC_AP' con 40 pruebas...\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.649198\n",
      "[100]\tvalid_0's average_precision: 0.659042\n",
      "[150]\tvalid_0's average_precision: 0.66209\n",
      "[200]\tvalid_0's average_precision: 0.665066\n",
      "[250]\tvalid_0's average_precision: 0.66948\n",
      "[300]\tvalid_0's average_precision: 0.672239\n",
      "[350]\tvalid_0's average_precision: 0.673856\n",
      "[400]\tvalid_0's average_precision: 0.674555\n",
      "[450]\tvalid_0's average_precision: 0.674824\n",
      "[500]\tvalid_0's average_precision: 0.674914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:45:48,338] Trial 0 finished with value: 0.6756544443881454 and parameters: {'learning_rate': 0.019906996673933378, 'n_estimators': 2900, 'num_leaves': 192, 'max_depth': 10, 'min_child_samples': 124, 'subsample': 0.8832290311184181, 'colsample_bytree': 0.608233797718321, 'reg_alpha': 7.072114131472227, 'reg_lambda': 1.452824663751602, 'min_split_gain': 0.21233911067827616}. Best is trial 0 with value: 0.6756544443881454.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[550]\tvalid_0's average_precision: 0.675518\n",
      "[600]\tvalid_0's average_precision: 0.675257\n",
      "[650]\tvalid_0's average_precision: 0.675257\n",
      "[700]\tvalid_0's average_precision: 0.675257\n",
      "[750]\tvalid_0's average_precision: 0.675257\n",
      "Early stopping, best iteration is:\n",
      "[559]\tvalid_0's average_precision: 0.675654\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.661508\n",
      "[100]\tvalid_0's average_precision: 0.658636\n",
      "[150]\tvalid_0's average_precision: 0.659526\n",
      "[200]\tvalid_0's average_precision: 0.660313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:45:50,016] Trial 1 finished with value: 0.6626238031642654 and parameters: {'learning_rate': 0.009778325945801386, 'n_estimators': 1200, 'num_leaves': 89, 'max_depth': 8, 'min_child_samples': 65, 'subsample': 0.7465447373174767, 'colsample_bytree': 0.7824279936868144, 'reg_alpha': 0.8431013932082461, 'reg_lambda': 0.0009962513222055108, 'min_split_gain': 0.5142344384136116}. Best is trial 0 with value: 0.6756544443881454.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's average_precision: 0.662624\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.660876\n",
      "[100]\tvalid_0's average_precision: 0.670874\n",
      "[150]\tvalid_0's average_precision: 0.676532\n",
      "[200]\tvalid_0's average_precision: 0.67804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:45:51,907] Trial 2 finished with value: 0.680014195168313 and parameters: {'learning_rate': 0.04446862319918233, 'n_estimators': 900, 'num_leaves': 162, 'max_depth': 8, 'min_child_samples': 68, 'subsample': 0.6390688456025535, 'colsample_bytree': 0.8736932106048627, 'reg_alpha': 0.015876781526923997, 'reg_lambda': 0.0004075596440072873, 'min_split_gain': 0.4951769101112702}. Best is trial 2 with value: 0.680014195168313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\tvalid_0's average_precision: 0.679721\n",
      "[300]\tvalid_0's average_precision: 0.679721\n",
      "[350]\tvalid_0's average_precision: 0.679721\n",
      "[400]\tvalid_0's average_precision: 0.679721\n",
      "Early stopping, best iteration is:\n",
      "[227]\tvalid_0's average_precision: 0.680014\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.591641\n",
      "[100]\tvalid_0's average_precision: 0.602881\n",
      "[150]\tvalid_0's average_precision: 0.608848\n",
      "[200]\tvalid_0's average_precision: 0.618294\n",
      "[250]\tvalid_0's average_precision: 0.626954\n",
      "[300]\tvalid_0's average_precision: 0.63324\n",
      "[350]\tvalid_0's average_precision: 0.644292\n",
      "[400]\tvalid_0's average_precision: 0.645347\n",
      "[450]\tvalid_0's average_precision: 0.646027\n",
      "[500]\tvalid_0's average_precision: 0.654557\n",
      "[550]\tvalid_0's average_precision: 0.659983\n",
      "[600]\tvalid_0's average_precision: 0.6624\n",
      "[650]\tvalid_0's average_precision: 0.664146\n",
      "[700]\tvalid_0's average_precision: 0.666175\n",
      "[750]\tvalid_0's average_precision: 0.667311\n",
      "[800]\tvalid_0's average_precision: 0.668367\n",
      "[850]\tvalid_0's average_precision: 0.669643\n",
      "[900]\tvalid_0's average_precision: 0.669722\n",
      "[950]\tvalid_0's average_precision: 0.669916\n",
      "[1000]\tvalid_0's average_precision: 0.670126\n",
      "[1050]\tvalid_0's average_precision: 0.669851\n",
      "[1100]\tvalid_0's average_precision: 0.669844\n",
      "[1150]\tvalid_0's average_precision: 0.669529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:45:56,507] Trial 3 finished with value: 0.6701583199848199 and parameters: {'learning_rate': 0.005676262589955587, 'n_estimators': 2800, 'num_leaves': 78, 'max_depth': -1, 'min_child_samples': 195, 'subsample': 0.9100531293444458, 'colsample_bytree': 0.9757995766256756, 'reg_alpha': 2.9794544625913595, 'reg_lambda': 0.09761125443110447, 'min_split_gain': 0.9218742350231168}. Best is trial 2 with value: 0.680014195168313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[997]\tvalid_0's average_precision: 0.670158\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.660945\n",
      "[100]\tvalid_0's average_precision: 0.662264\n",
      "[150]\tvalid_0's average_precision: 0.665067\n",
      "[200]\tvalid_0's average_precision: 0.66269\n",
      "[250]\tvalid_0's average_precision: 0.663326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:45:57,902] Trial 4 finished with value: 0.6660339046544103 and parameters: {'learning_rate': 0.006930112765148064, 'n_estimators': 1200, 'num_leaves': 26, 'max_depth': 8, 'min_child_samples': 63, 'subsample': 0.8170784332632994, 'colsample_bytree': 0.6563696899899051, 'reg_alpha': 1.025616274847307, 'reg_lambda': 0.0002359137306347715, 'min_split_gain': 0.9868869366005173}. Best is trial 2 with value: 0.680014195168313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\tvalid_0's average_precision: 0.665186\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's average_precision: 0.666034\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.67059\n",
      "[100]\tvalid_0's average_precision: 0.685216\n",
      "[150]\tvalid_0's average_precision: 0.68706\n",
      "[200]\tvalid_0's average_precision: 0.686142\n",
      "[250]\tvalid_0's average_precision: 0.686534\n",
      "[300]\tvalid_0's average_precision: 0.688838\n",
      "[350]\tvalid_0's average_precision: 0.68758\n",
      "[400]\tvalid_0's average_precision: 0.685525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:45:59,551] Trial 5 finished with value: 0.6892733705293801 and parameters: {'learning_rate': 0.08632815369661433, 'n_estimators': 1200, 'num_leaves': 17, 'max_depth': -1, 'min_child_samples': 78, 'subsample': 0.6463476238100518, 'colsample_bytree': 0.9452413703502374, 'reg_alpha': 0.13076473382928538, 'reg_lambda': 0.004513257622008946, 'min_split_gain': 0.06355835028602363}. Best is trial 5 with value: 0.6892733705293801.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[450]\tvalid_0's average_precision: 0.682962\n",
      "[500]\tvalid_0's average_precision: 0.683155\n",
      "Early stopping, best iteration is:\n",
      "[316]\tvalid_0's average_precision: 0.689273\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.626329\n",
      "[100]\tvalid_0's average_precision: 0.633323\n",
      "[150]\tvalid_0's average_precision: 0.646379\n",
      "[200]\tvalid_0's average_precision: 0.655292\n",
      "[250]\tvalid_0's average_precision: 0.658691\n",
      "[300]\tvalid_0's average_precision: 0.66157\n",
      "[350]\tvalid_0's average_precision: 0.663362\n",
      "[400]\tvalid_0's average_precision: 0.665246\n",
      "[450]\tvalid_0's average_precision: 0.666775\n",
      "[500]\tvalid_0's average_precision: 0.667339\n",
      "[550]\tvalid_0's average_precision: 0.669083\n",
      "[600]\tvalid_0's average_precision: 0.671129\n",
      "[650]\tvalid_0's average_precision: 0.673024\n",
      "[700]\tvalid_0's average_precision: 0.67374\n",
      "[750]\tvalid_0's average_precision: 0.6748\n",
      "[800]\tvalid_0's average_precision: 0.675739\n",
      "[850]\tvalid_0's average_precision: 0.676864\n",
      "[900]\tvalid_0's average_precision: 0.67754\n",
      "[950]\tvalid_0's average_precision: 0.678476\n",
      "[1000]\tvalid_0's average_precision: 0.679475\n",
      "[1050]\tvalid_0's average_precision: 0.679959\n",
      "[1100]\tvalid_0's average_precision: 0.680586\n",
      "[1150]\tvalid_0's average_precision: 0.680954\n",
      "[1200]\tvalid_0's average_precision: 0.681195\n",
      "[1250]\tvalid_0's average_precision: 0.681331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:01,724] Trial 6 finished with value: 0.6814142348264602 and parameters: {'learning_rate': 0.015746438450976667, 'n_estimators': 1500, 'num_leaves': 191, 'max_depth': 4, 'min_child_samples': 155, 'subsample': 0.8245108790277985, 'colsample_bytree': 0.9083868719818244, 'reg_alpha': 0.02944272359149678, 'reg_lambda': 0.04108318894699928, 'min_split_gain': 0.42754101835854963}. Best is trial 5 with value: 0.6892733705293801.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300]\tvalid_0's average_precision: 0.680951\n",
      "[1350]\tvalid_0's average_precision: 0.680575\n",
      "[1400]\tvalid_0's average_precision: 0.680271\n",
      "Early stopping, best iteration is:\n",
      "[1207]\tvalid_0's average_precision: 0.681414\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.659389\n",
      "[100]\tvalid_0's average_precision: 0.65661\n",
      "[150]\tvalid_0's average_precision: 0.658476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:02,772] Trial 7 finished with value: 0.6624091151648945 and parameters: {'learning_rate': 0.005491525066424382, 'n_estimators': 1000, 'num_leaves': 23, 'max_depth': 8, 'min_child_samples': 88, 'subsample': 0.9022204554172195, 'colsample_bytree': 0.6915192661966489, 'reg_alpha': 0.00024260488932164486, 'reg_lambda': 0.0028103296447636083, 'min_split_gain': 0.16122128725400442}. Best is trial 5 with value: 0.6892733705293801.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's average_precision: 0.657563\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's average_precision: 0.662409\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.669481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:03,504] Trial 8 finished with value: 0.6704573832756178 and parameters: {'learning_rate': 0.15431261011638706, 'n_estimators': 2600, 'num_leaves': 168, 'max_depth': 8, 'min_child_samples': 164, 'subsample': 0.9584365199693973, 'colsample_bytree': 0.7272013899887455, 'reg_alpha': 0.000355025561231308, 'reg_lambda': 0.001379354235277248, 'min_split_gain': 0.4271077886262563}. Best is trial 5 with value: 0.6892733705293801.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's average_precision: 0.667988\n",
      "[150]\tvalid_0's average_precision: 0.664768\n",
      "[200]\tvalid_0's average_precision: 0.664999\n",
      "[250]\tvalid_0's average_precision: 0.664999\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's average_precision: 0.670457\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.671118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:04,120] Trial 9 finished with value: 0.6765909067417198 and parameters: {'learning_rate': 0.10220655100897388, 'n_estimators': 2700, 'num_leaves': 17, 'max_depth': -1, 'min_child_samples': 190, 'subsample': 0.7292811728083021, 'colsample_bytree': 0.8075162486973464, 'reg_alpha': 0.3274121520988885, 'reg_lambda': 0.0065788201191231774, 'min_split_gain': 0.9717820827209607}. Best is trial 5 with value: 0.6892733705293801.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's average_precision: 0.67527\n",
      "[150]\tvalid_0's average_precision: 0.675066\n",
      "[200]\tvalid_0's average_precision: 0.674836\n",
      "[250]\tvalid_0's average_precision: 0.674836\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's average_precision: 0.676591\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.676968\n",
      "[100]\tvalid_0's average_precision: 0.671785\n",
      "[150]\tvalid_0's average_precision: 0.669748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:05,065] Trial 10 finished with value: 0.6793339259556741 and parameters: {'learning_rate': 0.11160520780208899, 'n_estimators': 1200, 'num_leaves': 25, 'max_depth': -1, 'min_child_samples': 154, 'subsample': 0.6304655048035832, 'colsample_bytree': 0.9486757327801338, 'reg_alpha': 0.4625809500171002, 'reg_lambda': 0.02958571414754742, 'min_split_gain': 0.24741350827669434}. Best is trial 5 with value: 0.6892733705293801.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's average_precision: 0.669024\n",
      "[250]\tvalid_0's average_precision: 0.669024\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's average_precision: 0.679334\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.628984\n",
      "[100]\tvalid_0's average_precision: 0.64279\n",
      "[150]\tvalid_0's average_precision: 0.653763\n",
      "[200]\tvalid_0's average_precision: 0.657911\n",
      "[250]\tvalid_0's average_precision: 0.661286\n",
      "[300]\tvalid_0's average_precision: 0.664635\n",
      "[350]\tvalid_0's average_precision: 0.667544\n",
      "[400]\tvalid_0's average_precision: 0.669038\n",
      "[450]\tvalid_0's average_precision: 0.670893\n",
      "[500]\tvalid_0's average_precision: 0.672265\n",
      "[550]\tvalid_0's average_precision: 0.673249\n",
      "[600]\tvalid_0's average_precision: 0.674043\n",
      "[650]\tvalid_0's average_precision: 0.674651\n",
      "[700]\tvalid_0's average_precision: 0.674684\n",
      "[750]\tvalid_0's average_precision: 0.675102\n",
      "[800]\tvalid_0's average_precision: 0.675216\n",
      "[850]\tvalid_0's average_precision: 0.675532\n",
      "[900]\tvalid_0's average_precision: 0.67573\n",
      "[950]\tvalid_0's average_precision: 0.675453\n",
      "[1000]\tvalid_0's average_precision: 0.675401\n",
      "[1050]\tvalid_0's average_precision: 0.675452\n",
      "[1100]\tvalid_0's average_precision: 0.67551\n",
      "Early stopping, best iteration is:\n",
      "[905]\tvalid_0's average_precision: 0.675928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:06,789] Trial 11 finished with value: 0.6759279316878005 and parameters: {'learning_rate': 0.023266614206805883, 'n_estimators': 2000, 'num_leaves': 245, 'max_depth': 4, 'min_child_samples': 163, 'subsample': 0.9019902779453758, 'colsample_bytree': 0.9351456153675048, 'reg_alpha': 2.815473529852417, 'reg_lambda': 0.003557587072605683, 'min_split_gain': 0.39560419853905165}. Best is trial 5 with value: 0.6892733705293801.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.667203\n",
      "[100]\tvalid_0's average_precision: 0.683339\n",
      "[150]\tvalid_0's average_precision: 0.683832\n",
      "[200]\tvalid_0's average_precision: 0.684878\n",
      "[250]\tvalid_0's average_precision: 0.683704\n",
      "[300]\tvalid_0's average_precision: 0.67796\n",
      "[350]\tvalid_0's average_precision: 0.677414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:08,153] Trial 12 finished with value: 0.6857574516292847 and parameters: {'learning_rate': 0.12639865324310517, 'n_estimators': 1150, 'num_leaves': 43, 'max_depth': 4, 'min_child_samples': 49, 'subsample': 0.7038072679919442, 'colsample_bytree': 0.9797447789375463, 'reg_alpha': 0.0698312618749519, 'reg_lambda': 0.001149422634021616, 'min_split_gain': 0.09326545536393184}. Best is trial 5 with value: 0.6892733705293801.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\tvalid_0's average_precision: 0.674205\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's average_precision: 0.685757\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.671538\n",
      "[100]\tvalid_0's average_precision: 0.685001\n",
      "[150]\tvalid_0's average_precision: 0.691138\n",
      "[200]\tvalid_0's average_precision: 0.691121\n",
      "[250]\tvalid_0's average_precision: 0.687963\n",
      "[300]\tvalid_0's average_precision: 0.686182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:09,035] Trial 13 finished with value: 0.6922081052076836 and parameters: {'learning_rate': 0.0968972456365368, 'n_estimators': 2000, 'num_leaves': 80, 'max_depth': 4, 'min_child_samples': 37, 'subsample': 0.6369743380933038, 'colsample_bytree': 0.950519614978828, 'reg_alpha': 0.06058181602847856, 'reg_lambda': 0.002215571184493588, 'min_split_gain': 0.1688131998720223}. Best is trial 13 with value: 0.6922081052076836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[350]\tvalid_0's average_precision: 0.6821\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's average_precision: 0.692208\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.683067\n",
      "[100]\tvalid_0's average_precision: 0.680267\n",
      "[150]\tvalid_0's average_precision: 0.664416\n",
      "[200]\tvalid_0's average_precision: 0.658774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:11,189] Trial 14 finished with value: 0.6905876083409045 and parameters: {'learning_rate': 0.09819167862083925, 'n_estimators': 1600, 'num_leaves': 146, 'max_depth': -1, 'min_child_samples': 126, 'subsample': 0.6147083677176132, 'colsample_bytree': 0.8568057696843706, 'reg_alpha': 0.027560179756205217, 'reg_lambda': 0.0002969077237519454, 'min_split_gain': 0.025869914068978477}. Best is trial 13 with value: 0.6922081052076836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\tvalid_0's average_precision: 0.656679\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's average_precision: 0.690588\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.664604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:12,235] Trial 15 finished with value: 0.6709473165171316 and parameters: {'learning_rate': 0.08815961994797127, 'n_estimators': 2450, 'num_leaves': 75, 'max_depth': 10, 'min_child_samples': 53, 'subsample': 0.6040568606200313, 'colsample_bytree': 0.9387070577400086, 'reg_alpha': 0.5331481964372673, 'reg_lambda': 0.040302749561892705, 'min_split_gain': 0.35087159055922157}. Best is trial 13 with value: 0.6922081052076836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's average_precision: 0.670748\n",
      "[150]\tvalid_0's average_precision: 0.669532\n",
      "[200]\tvalid_0's average_precision: 0.669532\n",
      "[250]\tvalid_0's average_precision: 0.669532\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's average_precision: 0.670947\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.673066\n",
      "[100]\tvalid_0's average_precision: 0.689406\n",
      "[150]\tvalid_0's average_precision: 0.683034\n",
      "[200]\tvalid_0's average_precision: 0.678564\n",
      "[250]\tvalid_0's average_precision: 0.674028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:14,650] Trial 16 finished with value: 0.6894064595249314 and parameters: {'learning_rate': 0.0629050400921003, 'n_estimators': 1100, 'num_leaves': 232, 'max_depth': -1, 'min_child_samples': 115, 'subsample': 0.6338595983121055, 'colsample_bytree': 0.8144677967905564, 'reg_alpha': 0.0006258047230043463, 'reg_lambda': 0.00018033939383481294, 'min_split_gain': 0.02117032378431194}. Best is trial 13 with value: 0.6922081052076836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\tvalid_0's average_precision: 0.671125\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's average_precision: 0.689406\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.67798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:15,483] Trial 17 finished with value: 0.6809676514139752 and parameters: {'learning_rate': 0.09178207143054895, 'n_estimators': 2000, 'num_leaves': 167, 'max_depth': -1, 'min_child_samples': 114, 'subsample': 0.6787905946961714, 'colsample_bytree': 0.7496292654704676, 'reg_alpha': 1.843367640988326, 'reg_lambda': 0.0008639079649502969, 'min_split_gain': 0.33673333296394103}. Best is trial 13 with value: 0.6922081052076836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's average_precision: 0.677669\n",
      "[150]\tvalid_0's average_precision: 0.677656\n",
      "[200]\tvalid_0's average_precision: 0.677656\n",
      "[250]\tvalid_0's average_precision: 0.677656\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's average_precision: 0.680968\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.650636\n",
      "[100]\tvalid_0's average_precision: 0.665222\n",
      "[150]\tvalid_0's average_precision: 0.674329\n",
      "[200]\tvalid_0's average_precision: 0.683186\n",
      "[250]\tvalid_0's average_precision: 0.685536\n",
      "[300]\tvalid_0's average_precision: 0.685243\n",
      "[350]\tvalid_0's average_precision: 0.683019\n",
      "[400]\tvalid_0's average_precision: 0.683937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:17,142] Trial 18 finished with value: 0.6859261316525435 and parameters: {'learning_rate': 0.04525788185174506, 'n_estimators': 2600, 'num_leaves': 197, 'max_depth': 6, 'min_child_samples': 78, 'subsample': 0.6893281617223777, 'colsample_bytree': 0.9347650346135907, 'reg_alpha': 0.058236980239855074, 'reg_lambda': 0.0002875635681518399, 'min_split_gain': 0.04411923996036053}. Best is trial 13 with value: 0.6922081052076836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's average_precision: 0.685926\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.639362\n",
      "[100]\tvalid_0's average_precision: 0.646999\n",
      "[150]\tvalid_0's average_precision: 0.654103\n",
      "[200]\tvalid_0's average_precision: 0.658954\n",
      "[250]\tvalid_0's average_precision: 0.664097\n",
      "[300]\tvalid_0's average_precision: 0.668155\n",
      "[350]\tvalid_0's average_precision: 0.669002\n",
      "[400]\tvalid_0's average_precision: 0.673648\n",
      "[450]\tvalid_0's average_precision: 0.675185\n",
      "[500]\tvalid_0's average_precision: 0.678257\n",
      "[550]\tvalid_0's average_precision: 0.680624\n",
      "[600]\tvalid_0's average_precision: 0.680932\n",
      "[650]\tvalid_0's average_precision: 0.680897\n",
      "[700]\tvalid_0's average_precision: 0.681933\n",
      "[750]\tvalid_0's average_precision: 0.682096\n",
      "[800]\tvalid_0's average_precision: 0.682545\n",
      "[850]\tvalid_0's average_precision: 0.68205\n",
      "[900]\tvalid_0's average_precision: 0.681961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:18,812] Trial 19 finished with value: 0.6827522784178828 and parameters: {'learning_rate': 0.0204496765699653, 'n_estimators': 2250, 'num_leaves': 33, 'max_depth': 4, 'min_child_samples': 109, 'subsample': 0.6591641187804929, 'colsample_bytree': 0.866226768018493, 'reg_alpha': 0.5353725497629153, 'reg_lambda': 0.00512395342222733, 'min_split_gain': 0.287559581283407}. Best is trial 13 with value: 0.6922081052076836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[950]\tvalid_0's average_precision: 0.681993\n",
      "Early stopping, best iteration is:\n",
      "[790]\tvalid_0's average_precision: 0.682752\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.674464\n",
      "[100]\tvalid_0's average_precision: 0.687748\n",
      "[150]\tvalid_0's average_precision: 0.677735\n",
      "[200]\tvalid_0's average_precision: 0.673473\n",
      "[250]\tvalid_0's average_precision: 0.668267\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's average_precision: 0.690169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:20,973] Trial 20 finished with value: 0.6901688974397252 and parameters: {'learning_rate': 0.07226639920449827, 'n_estimators': 2550, 'num_leaves': 71, 'max_depth': -1, 'min_child_samples': 98, 'subsample': 0.605297901568919, 'colsample_bytree': 0.7890836132067094, 'reg_alpha': 0.004132175623442268, 'reg_lambda': 0.0009805018679087218, 'min_split_gain': 0.07123314947054762}. Best is trial 13 with value: 0.6922081052076836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.671246\n",
      "[100]\tvalid_0's average_precision: 0.681638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:22,339] Trial 21 finished with value: 0.6830664062793997 and parameters: {'learning_rate': 0.05584558535090659, 'n_estimators': 2200, 'num_leaves': 52, 'max_depth': -1, 'min_child_samples': 89, 'subsample': 0.6023163306184741, 'colsample_bytree': 0.7888307653615044, 'reg_alpha': 0.0003418157305580054, 'reg_lambda': 0.00580376845173071, 'min_split_gain': 0.4873171861017841}. Best is trial 13 with value: 0.6922081052076836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\tvalid_0's average_precision: 0.677007\n",
      "[200]\tvalid_0's average_precision: 0.678192\n",
      "[250]\tvalid_0's average_precision: 0.678192\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's average_precision: 0.683066\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.671678\n",
      "[100]\tvalid_0's average_precision: 0.68583\n",
      "[150]\tvalid_0's average_precision: 0.678915\n",
      "[200]\tvalid_0's average_precision: 0.672307\n",
      "[250]\tvalid_0's average_precision: 0.666681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:25,823] Trial 22 finished with value: 0.685846433538468 and parameters: {'learning_rate': 0.07168456287527604, 'n_estimators': 2150, 'num_leaves': 89, 'max_depth': -1, 'min_child_samples': 96, 'subsample': 0.6449774839393205, 'colsample_bytree': 0.8353014619352742, 'reg_alpha': 0.014620699232622705, 'reg_lambda': 0.000442919238872098, 'min_split_gain': 0.022458110239471696}. Best is trial 13 with value: 0.6922081052076836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's average_precision: 0.685846\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.681824\n",
      "[100]\tvalid_0's average_precision: 0.688774\n",
      "[150]\tvalid_0's average_precision: 0.690137\n",
      "[200]\tvalid_0's average_precision: 0.685243\n",
      "[250]\tvalid_0's average_precision: 0.679766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:27,078] Trial 23 finished with value: 0.6937671420019428 and parameters: {'learning_rate': 0.17988556126799463, 'n_estimators': 2700, 'num_leaves': 44, 'max_depth': 6, 'min_child_samples': 76, 'subsample': 0.6708774513067567, 'colsample_bytree': 0.7430244354277076, 'reg_alpha': 0.00010132038587194589, 'reg_lambda': 0.007185480757400133, 'min_split_gain': 0.047588177386444504}. Best is trial 23 with value: 0.6937671420019428.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\tvalid_0's average_precision: 0.675301\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's average_precision: 0.693767\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.676943\n",
      "[100]\tvalid_0's average_precision: 0.683306\n",
      "[150]\tvalid_0's average_precision: 0.679542\n",
      "[200]\tvalid_0's average_precision: 0.678233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:28,251] Trial 24 finished with value: 0.6864966991036772 and parameters: {'learning_rate': 0.1516153316113088, 'n_estimators': 2700, 'num_leaves': 23, 'max_depth': 10, 'min_child_samples': 35, 'subsample': 0.7817494093209323, 'colsample_bytree': 0.840412009100321, 'reg_alpha': 0.00036953986635734486, 'reg_lambda': 0.0032708341675769465, 'min_split_gain': 0.10938694187575364}. Best is trial 23 with value: 0.6937671420019428.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\tvalid_0's average_precision: 0.678021\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's average_precision: 0.686497\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.673985\n",
      "[100]\tvalid_0's average_precision: 0.689181\n",
      "[150]\tvalid_0's average_precision: 0.681507\n",
      "[200]\tvalid_0's average_precision: 0.680428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:29,108] Trial 25 finished with value: 0.6898070774498181 and parameters: {'learning_rate': 0.134048869237695, 'n_estimators': 2400, 'num_leaves': 66, 'max_depth': 6, 'min_child_samples': 154, 'subsample': 0.7046204922935544, 'colsample_bytree': 0.691126505587233, 'reg_alpha': 0.00031443221670244035, 'reg_lambda': 0.012232748735371628, 'min_split_gain': 0.1027844907809374}. Best is trial 23 with value: 0.6937671420019428.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\tvalid_0's average_precision: 0.684215\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's average_precision: 0.689807\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.663888\n",
      "[100]\tvalid_0's average_precision: 0.679662\n",
      "[150]\tvalid_0's average_precision: 0.67751\n",
      "[200]\tvalid_0's average_precision: 0.677562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:30,531] Trial 26 finished with value: 0.6800945550622964 and parameters: {'learning_rate': 0.08488809213830671, 'n_estimators': 2650, 'num_leaves': 130, 'max_depth': 6, 'min_child_samples': 67, 'subsample': 0.7060846722925868, 'colsample_bytree': 0.8354677762395447, 'reg_alpha': 0.0009820433419143397, 'reg_lambda': 0.09605802729928539, 'min_split_gain': 0.17967898479600297}. Best is trial 23 with value: 0.6937671420019428.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\tvalid_0's average_precision: 0.672\n",
      "[300]\tvalid_0's average_precision: 0.672936\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's average_precision: 0.680095\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.673582\n",
      "[100]\tvalid_0's average_precision: 0.678796\n",
      "[150]\tvalid_0's average_precision: 0.682778\n",
      "[200]\tvalid_0's average_precision: 0.687159\n",
      "[250]\tvalid_0's average_precision: 0.689226\n",
      "[300]\tvalid_0's average_precision: 0.691291\n",
      "[350]\tvalid_0's average_precision: 0.693168\n",
      "[400]\tvalid_0's average_precision: 0.692776\n",
      "[450]\tvalid_0's average_precision: 0.689599\n",
      "[500]\tvalid_0's average_precision: 0.687842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:32,466] Trial 27 finished with value: 0.6940357332343345 and parameters: {'learning_rate': 0.04362872946154633, 'n_estimators': 2950, 'num_leaves': 84, 'max_depth': 6, 'min_child_samples': 39, 'subsample': 0.6150719443388198, 'colsample_bytree': 0.6495808754701029, 'reg_alpha': 0.00024231919624716984, 'reg_lambda': 0.001223974597996582, 'min_split_gain': 0.01893996490776941}. Best is trial 27 with value: 0.6940357332343345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[550]\tvalid_0's average_precision: 0.68592\n",
      "Early stopping, best iteration is:\n",
      "[381]\tvalid_0's average_precision: 0.694036\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.669526\n",
      "[100]\tvalid_0's average_precision: 0.674919\n",
      "[150]\tvalid_0's average_precision: 0.674697\n",
      "[200]\tvalid_0's average_precision: 0.675197\n",
      "[250]\tvalid_0's average_precision: 0.679221\n",
      "[300]\tvalid_0's average_precision: 0.681473\n",
      "[350]\tvalid_0's average_precision: 0.685317\n",
      "[400]\tvalid_0's average_precision: 0.686886\n",
      "[450]\tvalid_0's average_precision: 0.686188\n",
      "[500]\tvalid_0's average_precision: 0.687436\n",
      "[550]\tvalid_0's average_precision: 0.688697\n",
      "[600]\tvalid_0's average_precision: 0.688506\n",
      "[650]\tvalid_0's average_precision: 0.689914\n",
      "[700]\tvalid_0's average_precision: 0.689413\n",
      "[750]\tvalid_0's average_precision: 0.689573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:35,426] Trial 28 finished with value: 0.6903353815430644 and parameters: {'learning_rate': 0.020830362984007166, 'n_estimators': 2500, 'num_leaves': 118, 'max_depth': 6, 'min_child_samples': 19, 'subsample': 0.6818221021419233, 'colsample_bytree': 0.6120217137832059, 'reg_alpha': 0.014279518310770114, 'reg_lambda': 0.001269625992510396, 'min_split_gain': 0.06443704582651885}. Best is trial 27 with value: 0.6940357332343345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[800]\tvalid_0's average_precision: 0.689224\n",
      "[850]\tvalid_0's average_precision: 0.689654\n",
      "Early stopping, best iteration is:\n",
      "[658]\tvalid_0's average_precision: 0.690335\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.675675\n",
      "[100]\tvalid_0's average_precision: 0.677451\n",
      "[150]\tvalid_0's average_precision: 0.67651\n",
      "[200]\tvalid_0's average_precision: 0.676849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:38,415] Trial 29 finished with value: 0.6793937264850278 and parameters: {'learning_rate': 0.07209884338494811, 'n_estimators': 2600, 'num_leaves': 181, 'max_depth': 10, 'min_child_samples': 19, 'subsample': 0.6192431059200858, 'colsample_bytree': 0.6314745815632127, 'reg_alpha': 0.0001803066483556883, 'reg_lambda': 0.0053472754515608185, 'min_split_gain': 0.04976359843181262}. Best is trial 27 with value: 0.6940357332343345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\tvalid_0's average_precision: 0.675473\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's average_precision: 0.679394\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.671484\n",
      "[100]\tvalid_0's average_precision: 0.683208\n",
      "[150]\tvalid_0's average_precision: 0.686076\n",
      "[200]\tvalid_0's average_precision: 0.684289\n",
      "[250]\tvalid_0's average_precision: 0.682363\n",
      "[300]\tvalid_0's average_precision: 0.681224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:40,037] Trial 30 finished with value: 0.6878437444420145 and parameters: {'learning_rate': 0.06817630476056928, 'n_estimators': 2700, 'num_leaves': 36, 'max_depth': 8, 'min_child_samples': 51, 'subsample': 0.694731196260598, 'colsample_bytree': 0.6492666311404743, 'reg_alpha': 0.0002671864962099014, 'reg_lambda': 0.008723635787826842, 'min_split_gain': 0.10487058039352706}. Best is trial 27 with value: 0.6940357332343345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's average_precision: 0.687844\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.683897\n",
      "[100]\tvalid_0's average_precision: 0.687873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:40,688] Trial 31 finished with value: 0.6911917564819916 and parameters: {'learning_rate': 0.14403221776025815, 'n_estimators': 2550, 'num_leaves': 88, 'max_depth': 4, 'min_child_samples': 19, 'subsample': 0.6122307388993724, 'colsample_bytree': 0.8853299679820834, 'reg_alpha': 0.04141952314781954, 'reg_lambda': 0.0016696504765061544, 'min_split_gain': 0.32212421803682956}. Best is trial 27 with value: 0.6940357332343345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\tvalid_0's average_precision: 0.68454\n",
      "[200]\tvalid_0's average_precision: 0.68278\n",
      "[250]\tvalid_0's average_precision: 0.68278\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's average_precision: 0.691192\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.666917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:41,481] Trial 32 finished with value: 0.6835260845348519 and parameters: {'learning_rate': 0.16517265200404338, 'n_estimators': 2600, 'num_leaves': 80, 'max_depth': 4, 'min_child_samples': 19, 'subsample': 0.6316274010382068, 'colsample_bytree': 0.9455562370804077, 'reg_alpha': 0.005922912094477865, 'reg_lambda': 0.004223683653328875, 'min_split_gain': 0.5140044725357775}. Best is trial 27 with value: 0.6940357332343345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's average_precision: 0.680566\n",
      "[150]\tvalid_0's average_precision: 0.681854\n",
      "[200]\tvalid_0's average_precision: 0.681854\n",
      "[250]\tvalid_0's average_precision: 0.681854\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's average_precision: 0.683526\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.677002\n",
      "[100]\tvalid_0's average_precision: 0.689236\n",
      "[150]\tvalid_0's average_precision: 0.691241\n",
      "[200]\tvalid_0's average_precision: 0.69141\n",
      "[250]\tvalid_0's average_precision: 0.689054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:42,279] Trial 33 finished with value: 0.694277612698997 and parameters: {'learning_rate': 0.15678602416893928, 'n_estimators': 2800, 'num_leaves': 45, 'max_depth': 4, 'min_child_samples': 85, 'subsample': 0.6178428016850243, 'colsample_bytree': 0.752256862165041, 'reg_alpha': 0.00019797157674667282, 'reg_lambda': 0.03782582342164131, 'min_split_gain': 0.025267229083416713}. Best is trial 33 with value: 0.694277612698997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\tvalid_0's average_precision: 0.687669\n",
      "[350]\tvalid_0's average_precision: 0.685665\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's average_precision: 0.694278\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.677944\n",
      "[100]\tvalid_0's average_precision: 0.685818\n",
      "[150]\tvalid_0's average_precision: 0.679097\n",
      "[200]\tvalid_0's average_precision: 0.676799\n",
      "[250]\tvalid_0's average_precision: 0.672709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:43,012] Trial 34 finished with value: 0.6879969675864455 and parameters: {'learning_rate': 0.18715267807355368, 'n_estimators': 1800, 'num_leaves': 96, 'max_depth': 4, 'min_child_samples': 56, 'subsample': 0.6667380383542079, 'colsample_bytree': 0.7197188276286746, 'reg_alpha': 0.0005893563794702811, 'reg_lambda': 0.11622950123613142, 'min_split_gain': 0.032082759191435765}. Best is trial 33 with value: 0.694277612698997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's average_precision: 0.687997\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.648143\n",
      "[100]\tvalid_0's average_precision: 0.649789\n",
      "[150]\tvalid_0's average_precision: 0.655405\n",
      "[200]\tvalid_0's average_precision: 0.659221\n",
      "[250]\tvalid_0's average_precision: 0.662913\n",
      "[300]\tvalid_0's average_precision: 0.666901\n",
      "[350]\tvalid_0's average_precision: 0.667414\n",
      "[400]\tvalid_0's average_precision: 0.669524\n",
      "[450]\tvalid_0's average_precision: 0.672953\n",
      "[500]\tvalid_0's average_precision: 0.675267\n",
      "[550]\tvalid_0's average_precision: 0.67737\n",
      "[600]\tvalid_0's average_precision: 0.678293\n",
      "[650]\tvalid_0's average_precision: 0.680446\n",
      "[700]\tvalid_0's average_precision: 0.682244\n",
      "[750]\tvalid_0's average_precision: 0.684842\n",
      "[800]\tvalid_0's average_precision: 0.68636\n",
      "[850]\tvalid_0's average_precision: 0.687945\n",
      "[900]\tvalid_0's average_precision: 0.688059\n",
      "[950]\tvalid_0's average_precision: 0.687996\n",
      "[1000]\tvalid_0's average_precision: 0.688369\n",
      "[1050]\tvalid_0's average_precision: 0.688658\n",
      "[1100]\tvalid_0's average_precision: 0.689111\n",
      "[1150]\tvalid_0's average_precision: 0.689575\n",
      "[1200]\tvalid_0's average_precision: 0.689675\n",
      "[1250]\tvalid_0's average_precision: 0.689726\n",
      "[1300]\tvalid_0's average_precision: 0.690304\n",
      "[1350]\tvalid_0's average_precision: 0.691278\n",
      "[1400]\tvalid_0's average_precision: 0.691643\n",
      "[1450]\tvalid_0's average_precision: 0.691452\n",
      "[1500]\tvalid_0's average_precision: 0.690772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:45,688] Trial 35 finished with value: 0.6918427594251736 and parameters: {'learning_rate': 0.01570200993126221, 'n_estimators': 3000, 'num_leaves': 69, 'max_depth': 4, 'min_child_samples': 37, 'subsample': 0.6177680062239366, 'colsample_bytree': 0.7399345606198131, 'reg_alpha': 0.0003086541340937849, 'reg_lambda': 0.03146836029100747, 'min_split_gain': 0.018609338794905356}. Best is trial 33 with value: 0.694277612698997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1550]\tvalid_0's average_precision: 0.690272\n",
      "[1600]\tvalid_0's average_precision: 0.690361\n",
      "Early stopping, best iteration is:\n",
      "[1411]\tvalid_0's average_precision: 0.691843\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.669681\n",
      "[100]\tvalid_0's average_precision: 0.68309\n",
      "[150]\tvalid_0's average_precision: 0.691147\n",
      "[200]\tvalid_0's average_precision: 0.694647\n",
      "[250]\tvalid_0's average_precision: 0.69566\n",
      "[300]\tvalid_0's average_precision: 0.69594\n",
      "[350]\tvalid_0's average_precision: 0.693782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:46,750] Trial 36 finished with value: 0.6964347470013181 and parameters: {'learning_rate': 0.10766792175362039, 'n_estimators': 2750, 'num_leaves': 34, 'max_depth': 4, 'min_child_samples': 109, 'subsample': 0.7334701365259861, 'colsample_bytree': 0.7909280979547718, 'reg_alpha': 0.0008825496524176745, 'reg_lambda': 0.2832044524407928, 'min_split_gain': 0.009848973222124005}. Best is trial 36 with value: 0.6964347470013181.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\tvalid_0's average_precision: 0.692243\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's average_precision: 0.696435\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.673255\n",
      "[100]\tvalid_0's average_precision: 0.689808\n",
      "[150]\tvalid_0's average_precision: 0.68427\n",
      "[200]\tvalid_0's average_precision: 0.684468\n",
      "[250]\tvalid_0's average_precision: 0.67945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:47,479] Trial 37 finished with value: 0.6904881840219965 and parameters: {'learning_rate': 0.1770650514696194, 'n_estimators': 2800, 'num_leaves': 21, 'max_depth': 4, 'min_child_samples': 69, 'subsample': 0.6498930572522668, 'colsample_bytree': 0.85505616963291, 'reg_alpha': 0.002722860004096894, 'reg_lambda': 0.3095416105134431, 'min_split_gain': 0.045594663951182314}. Best is trial 36 with value: 0.6964347470013181.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\tvalid_0's average_precision: 0.679321\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's average_precision: 0.690488\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.659568\n",
      "[100]\tvalid_0's average_precision: 0.674276\n",
      "[150]\tvalid_0's average_precision: 0.683339\n",
      "[200]\tvalid_0's average_precision: 0.685121\n",
      "[250]\tvalid_0's average_precision: 0.683872\n",
      "[300]\tvalid_0's average_precision: 0.683449\n",
      "[350]\tvalid_0's average_precision: 0.684369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:48,252] Trial 38 finished with value: 0.6856806196633409 and parameters: {'learning_rate': 0.09439820685378629, 'n_estimators': 2000, 'num_leaves': 18, 'max_depth': 4, 'min_child_samples': 144, 'subsample': 0.7064279998953301, 'colsample_bytree': 0.7057054573600376, 'reg_alpha': 0.014523636493984624, 'reg_lambda': 0.9084844724424889, 'min_split_gain': 0.1276135795342389}. Best is trial 36 with value: 0.6964347470013181.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's average_precision: 0.685681\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.676086\n",
      "[100]\tvalid_0's average_precision: 0.685383\n",
      "[150]\tvalid_0's average_precision: 0.684673\n",
      "[200]\tvalid_0's average_precision: 0.684529\n",
      "[250]\tvalid_0's average_precision: 0.684529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:46:49,092] Trial 39 finished with value: 0.6863925291944197 and parameters: {'learning_rate': 0.10444636959696961, 'n_estimators': 2500, 'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 56, 'subsample': 0.6047426688945986, 'colsample_bytree': 0.6359589101899661, 'reg_alpha': 0.00043006707647222093, 'reg_lambda': 0.00015744078163520723, 'min_split_gain': 0.35983464423894834}. Best is trial 36 with value: 0.6964347470013181.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\tvalid_0's average_precision: 0.684529\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's average_precision: 0.686393\n",
      "[OPTUNA] Mejor AP(val): 0.696435\n",
      "[OPTUNA] Params ganadores: {'learning_rate': 0.10766792175362039, 'n_estimators': 2750, 'num_leaves': 34, 'max_depth': 4, 'min_child_samples': 109, 'subsample': 0.7334701365259861, 'colsample_bytree': 0.7909280979547718, 'reg_alpha': 0.0008825496524176745, 'reg_lambda': 0.2832044524407928, 'min_split_gain': 0.009848973222124005}\n",
      "[OPTUNA] best_iteration (del trial): 236\n",
      "[OPTUNA] Guardado BEST en: BEST_LGBM_FULL_SMOTENC.json\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.669681\n",
      "[100]\tvalid_0's average_precision: 0.68309\n",
      "[150]\tvalid_0's average_precision: 0.691147\n",
      "[200]\tvalid_0's average_precision: 0.694647\n",
      "[250]\tvalid_0's average_precision: 0.69566\n",
      "[300]\tvalid_0's average_precision: 0.69594\n",
      "[350]\tvalid_0's average_precision: 0.693782\n",
      "[400]\tvalid_0's average_precision: 0.692243\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's average_precision: 0.696435\n",
      "[OPTUNA] Reentreno final completado. best_iteration_ = 236\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "tuned_model = None\n",
    "\n",
    "N_TRIALS = 40\n",
    "STUDY_NAME = f\"LGBM_{VIEW_TAG}_{BAL_TAG}_AP\"\n",
    "SAMPLER = TPESampler(seed=RANDOM_STATE, multivariate=True, group=False)\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=STUDY_NAME, sampler=SAMPLER)\n",
    "\n",
    "SEARCH_KEYS = [\n",
    "    \"learning_rate\", \"n_estimators\", \"num_leaves\", \"max_depth\",\n",
    "    \"min_child_samples\", \"subsample\", \"colsample_bytree\",\n",
    "    \"reg_alpha\", \"reg_lambda\", \"min_split_gain\", \"class_weight\"\n",
    "]\n",
    "\n",
    "def suggest_lgbm_params(trial, base=None):\n",
    "    p = {}\n",
    "    p[\"learning_rate\"]     = trial.suggest_float(\"learning_rate\", 0.005, 0.2, log=True)\n",
    "    p[\"n_estimators\"]      = trial.suggest_int(\"n_estimators\", 800, 3000, step=50)\n",
    "    p[\"num_leaves\"]        = trial.suggest_int(\"num_leaves\", 16, 256)\n",
    "    p[\"max_depth\"]         = trial.suggest_categorical(\"max_depth\", [-1, 4, 6, 8, 10])\n",
    "    p[\"min_child_samples\"] = trial.suggest_int(\"min_child_samples\", 10, 200)\n",
    "    p[\"subsample\"]         = trial.suggest_float(\"subsample\", 0.6, 1.0)\n",
    "    p[\"colsample_bytree\"]  = trial.suggest_float(\"colsample_bytree\", 0.6, 1.0)\n",
    "    p[\"reg_alpha\"]         = trial.suggest_float(\"reg_alpha\", 1e-4, 10.0, log=True)\n",
    "    p[\"reg_lambda\"]        = trial.suggest_float(\"reg_lambda\", 1e-4, 10.0, log=True)\n",
    "    p[\"min_split_gain\"]    = trial.suggest_float(\"min_split_gain\", 0.0, 1.0)\n",
    "    if USE_BALANCED_TRAIN:\n",
    "        p[\"class_weight\"] = None\n",
    "    else:\n",
    "        p[\"class_weight\"] = trial.suggest_categorical(\"class_weight\", [None, \"balanced\"])\n",
    "\n",
    "    p[\"random_state\"] = RANDOM_STATE\n",
    "    p[\"n_jobs\"] = -1\n",
    "    p[\"metric\"] = \"average_precision\"\n",
    "    p[\"verbosity\"] = -1\n",
    "    return p\n",
    "\n",
    "# máscara a usar en Optuna\n",
    "_MASK_FOR_TUNING = CAT_MASK_USED if USE_REDUCED else CAT_MASK_FULL\n",
    "_X_FOR_TUNING = X_train_fit\n",
    "_Y_FOR_TUNING = y_train\n",
    "_X_VAL_FOR_TUNING = X_val_fit\n",
    "_Y_VAL_FOR_TUNING = y_val\n",
    "\n",
    "def objective(trial):\n",
    "    hp = suggest_lgbm_params(trial)\n",
    "    hp = sanitize_params(hp, use_balanced_train=USE_BALANCED_TRAIN)\n",
    "\n",
    "    mdl = LGBMClassifier(**hp)\n",
    "\n",
    "    X_tr, y_tr = _X_FOR_TUNING, _Y_FOR_TUNING\n",
    "    if USE_BALANCED_TRAIN:\n",
    "        X_tr, y_tr = maybe_resample(X_tr, y_tr, categorical_mask=_MASK_FOR_TUNING)\n",
    "\n",
    "    fit_call = dict(\n",
    "        eval_set=[(_X_VAL_FOR_TUNING, _Y_VAL_FOR_TUNING)],\n",
    "        eval_metric=\"aucpr\",\n",
    "        **_fit_kwargs\n",
    "    )\n",
    "    if _LGBM_CB_OK:\n",
    "        fit_call[\"callbacks\"] = _callbacks\n",
    "\n",
    "    mdl.fit(X_tr, y_tr, **fit_call)\n",
    "    proba_val_t = pred_proba_best(mdl, _X_VAL_FOR_TUNING)\n",
    "    ap = average_precision_score(_Y_VAL_FOR_TUNING, proba_val_t)\n",
    "    trial.set_user_attr(\"best_iteration\", getattr(mdl, \"best_iteration_\", None))\n",
    "    return ap\n",
    "\n",
    "print(f\"[OPTUNA] Iniciando estudio '{STUDY_NAME}' con {N_TRIALS} pruebas...\")\n",
    "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=False)\n",
    "\n",
    "best = study.best_trial\n",
    "print(f\"[OPTUNA] Mejor AP(val): {best.value:.6f}\")\n",
    "print(f\"[OPTUNA] Params ganadores:\", best.params)\n",
    "print(f\"[OPTUNA] best_iteration (del trial):\", best.user_attrs.get(\"best_iteration\"))\n",
    "\n",
    "best_params = dict(best.params)\n",
    "best_params.update({\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"n_jobs\": -1,\n",
    "    \"metric\": \"average_precision\",\n",
    "    \"verbosity\": -1\n",
    "})\n",
    "with open(BEST_HP_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(best_params, f, indent=2, ensure_ascii=False)\n",
    "print(\"[OPTUNA] Guardado BEST en:\", BEST_HP_FILE.name)\n",
    "\n",
    "tuned_model = LGBMClassifier(**best_params)\n",
    "\n",
    "fit_call = dict(\n",
    "    eval_set=[(_X_VAL_FOR_TUNING, _Y_VAL_FOR_TUNING)],\n",
    "    eval_metric=\"aucpr\",\n",
    "    **_fit_kwargs\n",
    ")\n",
    "if _LGBM_CB_OK:\n",
    "    fit_call[\"callbacks\"] = _callbacks\n",
    "\n",
    "X_train_tuned, y_train_tuned = _X_FOR_TUNING, _Y_FOR_TUNING\n",
    "if USE_BALANCED_TRAIN:\n",
    "    X_train_tuned, y_train_tuned = maybe_resample(_X_FOR_TUNING, _Y_FOR_TUNING, categorical_mask=_MASK_FOR_TUNING)\n",
    "\n",
    "tuned_model.fit(X_train_tuned, y_train_tuned, **fit_call)\n",
    "print(\"[OPTUNA] Reentreno final completado. best_iteration_ =\", getattr(tuned_model, \"best_iteration_\", None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da21ffe",
   "metadata": {},
   "source": [
    "8 — Cross-Validation (OOF) para baseline y tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "655c22d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_oof_cv(model_params, X, y, k_folds=CV_FOLDS, seed=RANDOM_STATE, exp_suffix=\"BASELINE\", categorical_mask=None):\n",
    "    skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
    "    oof_proba = np.zeros_like(y, dtype=float)\n",
    "    fold_rows = []\n",
    "\n",
    "    base_params = dict(model_params)\n",
    "    base_params.pop(\"verbose\", None)\n",
    "    base_params.setdefault(\"verbosity\", -1)\n",
    "    base_params.setdefault(\"metric\", \"average_precision\")\n",
    "\n",
    "    _fit_kwargs_local = {}\n",
    "    _callbacks_local = []\n",
    "    if _LGBM_CB_OK:\n",
    "        _callbacks_local = [early_stopping(stopping_rounds=200), log_evaluation(period=50)]\n",
    "    else:\n",
    "        _fit_kwargs_local[\"early_stopping_rounds\"] = 200\n",
    "\n",
    "    for f, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
    "        X_tr, X_va = X[tr_idx], X[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "        # Balanceo SOLO en train del fold\n",
    "        if USE_BALANCED_TRAIN and BALANCE_IN_CV:\n",
    "            X_tr, y_tr = maybe_resample(X_tr, y_tr, categorical_mask=categorical_mask)\n",
    "\n",
    "        mdl = LGBMClassifier(**base_params)\n",
    "        _fit_call = dict(\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            eval_metric=\"aucpr\",\n",
    "            **_fit_kwargs_local\n",
    "        )\n",
    "        if _LGBM_CB_OK:\n",
    "            _fit_call[\"callbacks\"] = _callbacks_local\n",
    "\n",
    "        mdl.fit(X_tr, y_tr, **_fit_call)\n",
    "        proba_va = pred_proba_best(mdl, X_va)\n",
    "        oof_proba[va_idx] = proba_va\n",
    "\n",
    "        fold_rows.append({\n",
    "            \"fold\": f,\n",
    "            \"pr_auc\": average_precision_score(y_va, proba_va),\n",
    "            \"roc_auc\": roc_auc_score(y_va, proba_va)\n",
    "        })\n",
    "\n",
    "    oof_pr = average_precision_score(y, oof_proba)\n",
    "    oof_roc = roc_auc_score(y, oof_proba)\n",
    "    thr_oof, _ = find_best_threshold(y, oof_proba, metric=\"f1\")\n",
    "    y_oof_pred = (oof_proba >= thr_oof).astype(int)\n",
    "    oof_f1  = f1_score(y, y_oof_pred, zero_division=0)\n",
    "    oof_rec = recall_score(y, y_oof_pred, zero_division=0)\n",
    "    oof_bal = balanced_accuracy_score(y, y_oof_pred)\n",
    "\n",
    "    cv_tag = f\"{EXP_NAME}_{exp_suffix}_CV{CV_FOLDS}\"\n",
    "    cv_csv = OUT_RESULTS / f\"cv_summary_{cv_tag}.csv\"\n",
    "    folds_df = pd.DataFrame(fold_rows)\n",
    "    agg_row = pd.DataFrame([{\n",
    "        \"fold\": \"OOF\", \"pr_auc\": oof_pr, \"roc_auc\": oof_roc,\n",
    "        \"thr\": thr_oof, \"f1\": oof_f1, \"recall\": oof_rec, \"bal_acc\": oof_bal\n",
    "    }])\n",
    "    cv_df = pd.concat([folds_df, agg_row], ignore_index=True)\n",
    "    cv_df.to_csv(cv_csv, index=False)\n",
    "\n",
    "    oof_path = OUT_PREDS / f\"oof_{cv_tag}.parquet\"\n",
    "    pd.DataFrame({\"oof_proba\": oof_proba, \"y_true\": y}).to_parquet(oof_path, index=False)\n",
    "\n",
    "    print(f\"[CV-{exp_suffix}] Guardados: {cv_csv.name} | {oof_path.name}\")\n",
    "    return {\"oof_pr_auc\": oof_pr, \"oof_roc_auc\": oof_roc, \"thr\": thr_oof,\n",
    "            \"oof_f1\": oof_f1, \"oof_recall\": oof_rec, \"oof_bal_acc\": oof_bal}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b2356b",
   "metadata": {},
   "source": [
    "9 — Evaluación en test + guardados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "27900e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.676361\n",
      "[100]\tvalid_0's average_precision: 0.677282\n",
      "[150]\tvalid_0's average_precision: 0.67827\n",
      "[200]\tvalid_0's average_precision: 0.676592\n",
      "[250]\tvalid_0's average_precision: 0.675391\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's average_precision: 0.680367\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.680816\n",
      "[100]\tvalid_0's average_precision: 0.67861\n",
      "[150]\tvalid_0's average_precision: 0.675773\n",
      "[200]\tvalid_0's average_precision: 0.674951\n",
      "[250]\tvalid_0's average_precision: 0.677869\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's average_precision: 0.682887\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.697127\n",
      "[100]\tvalid_0's average_precision: 0.711845\n",
      "[150]\tvalid_0's average_precision: 0.712725\n",
      "[200]\tvalid_0's average_precision: 0.714068\n",
      "[250]\tvalid_0's average_precision: 0.711009\n",
      "[300]\tvalid_0's average_precision: 0.71228\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's average_precision: 0.715596\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.680369\n",
      "[100]\tvalid_0's average_precision: 0.687777\n",
      "[150]\tvalid_0's average_precision: 0.691292\n",
      "[200]\tvalid_0's average_precision: 0.690127\n",
      "[250]\tvalid_0's average_precision: 0.692355\n",
      "[300]\tvalid_0's average_precision: 0.695173\n",
      "[350]\tvalid_0's average_precision: 0.694872\n",
      "[400]\tvalid_0's average_precision: 0.695701\n",
      "[450]\tvalid_0's average_precision: 0.69174\n",
      "[500]\tvalid_0's average_precision: 0.694022\n",
      "Early stopping, best iteration is:\n",
      "[330]\tvalid_0's average_precision: 0.69631\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.656058\n",
      "[100]\tvalid_0's average_precision: 0.643875\n",
      "[150]\tvalid_0's average_precision: 0.642678\n",
      "[200]\tvalid_0's average_precision: 0.640188\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's average_precision: 0.656383\n",
      "[CV-BASELINE] Guardados: cv_summary_LGBM_FULL_SMOTENC_BASELINE_CV5.csv | oof_LGBM_FULL_SMOTENC_BASELINE_CV5.parquet\n",
      "[OK][BASE] Guardados: \n",
      "  - Seed HPs   : LGBM_FULL_SMOTENC_BASE_seed_params.json \n",
      "  - Fitted HPs : LGBM_FULL_SMOTENC_BASE_fitted_params.json \n",
      "  - Importancias: LGBM_FULL_SMOTENC_feature_importances.csv \n",
      "  - Preds test  : preds_test_LGBM_FULL_SMOTENC.parquet \n",
      "  - Baselines   : baselines.csv\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.676361\n",
      "[100]\tvalid_0's average_precision: 0.677282\n",
      "[150]\tvalid_0's average_precision: 0.67827\n",
      "[200]\tvalid_0's average_precision: 0.676592\n",
      "[250]\tvalid_0's average_precision: 0.675391\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's average_precision: 0.680367\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.680816\n",
      "[100]\tvalid_0's average_precision: 0.67861\n",
      "[150]\tvalid_0's average_precision: 0.675773\n",
      "[200]\tvalid_0's average_precision: 0.674951\n",
      "[250]\tvalid_0's average_precision: 0.677869\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's average_precision: 0.682887\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.697127\n",
      "[100]\tvalid_0's average_precision: 0.711845\n",
      "[150]\tvalid_0's average_precision: 0.712725\n",
      "[200]\tvalid_0's average_precision: 0.714068\n",
      "[250]\tvalid_0's average_precision: 0.711009\n",
      "[300]\tvalid_0's average_precision: 0.71228\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's average_precision: 0.715596\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.680369\n",
      "[100]\tvalid_0's average_precision: 0.687777\n",
      "[150]\tvalid_0's average_precision: 0.691292\n",
      "[200]\tvalid_0's average_precision: 0.690127\n",
      "[250]\tvalid_0's average_precision: 0.692355\n",
      "[300]\tvalid_0's average_precision: 0.695173\n",
      "[350]\tvalid_0's average_precision: 0.694872\n",
      "[400]\tvalid_0's average_precision: 0.695701\n",
      "[450]\tvalid_0's average_precision: 0.69174\n",
      "[500]\tvalid_0's average_precision: 0.694022\n",
      "Early stopping, best iteration is:\n",
      "[330]\tvalid_0's average_precision: 0.69631\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.656058\n",
      "[100]\tvalid_0's average_precision: 0.643875\n",
      "[150]\tvalid_0's average_precision: 0.642678\n",
      "[200]\tvalid_0's average_precision: 0.640188\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's average_precision: 0.656383\n",
      "[CV-TUNED] Guardados: cv_summary_LGBM_FULL_SMOTENC_TUNED_CV5.csv | oof_LGBM_FULL_SMOTENC_TUNED_CV5.parquet\n",
      "[OK][TUNED] Guardados: \n",
      "  - Fitted HPs : LGBM_FULL_SMOTENC_TUNED_fitted_params.json \n",
      "  - Importancias: LGBM_FULL_SMOTENC_TUNED_feature_importances.csv \n",
      "  - Preds test  : preds_test_LGBM_FULL_SMOTENC_TUNED.parquet \n",
      "  - Baselines   : baselines.csv\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve, roc_auc_score, confusion_matrix\n",
    "\n",
    "def plot_pr_curve(y_true, y_proba, title, out_path):\n",
    "    prec, rec, _ = precision_recall_curve(y_true, y_proba)\n",
    "    ap = average_precision_score(y_true, y_proba)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.step(rec, prec, where='post')\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'{title} (AP={ap:.4f})')\n",
    "    plt.grid(True, linestyle='--', alpha=.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def plot_roc_curve(y_true, y_proba, title, out_path):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "    auc = roc_auc_score(y_true, y_proba)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr, tpr, lw=2)\n",
    "    plt.plot([0,1],[0,1], 'k--', lw=1)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{title} (AUC={auc:.4f})')\n",
    "    plt.grid(True, linestyle='--', alpha=.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def plot_confusion(y_true, y_pred, title, out_path, normalize=False):\n",
    "    norm = 'true' if normalize else None\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize=norm)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    im = plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    ticks = np.arange(2)\n",
    "    plt.xticks(ticks, ['0','1']); plt.yticks(ticks, ['0','1'])\n",
    "    thresh = cm.max()/2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            txt = f'{cm[i,j]:.2f}' if normalize else str(cm[i,j])\n",
    "            plt.text(j, i, txt, ha='center', va='center',\n",
    "                     color='white' if cm[i,j] > thresh else 'black')\n",
    "    plt.ylabel('True label'); plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "base = EXP_NAME\n",
    "\n",
    "# === BASELINE ===\n",
    "proba_val = pred_proba_best(model, X_val_fit)\n",
    "proba_test = pred_proba_best(model, X_test_fit)\n",
    "\n",
    "# CV baseline usando las features y máscara efectivas\n",
    "cv_base = run_oof_cv(seed_params, X_train_fit, y_train, exp_suffix=\"BASELINE\", categorical_mask=CAT_MASK_USED)\n",
    "thr_oof = cv_base[\"thr\"]\n",
    "thr_used = thr_oof\n",
    "\n",
    "y_pred_test = (proba_test >= thr_used).astype(int)\n",
    "test_metrics = compute_all_metrics(y_test, proba_test, thr_used)\n",
    "\n",
    "# Guardar HP baseline\n",
    "params_seed_path = OUT_PARAMS / f\"{base}_BASE_seed_params.json\"\n",
    "with open(params_seed_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(seed_params, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "params_fitted_path = OUT_PARAMS / f\"{base}_BASE_fitted_params.json\"\n",
    "with open(params_fitted_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(model.get_params(), f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Figuras baseline\n",
    "plot_pr_curve(y_val,  proba_val,  f\"{base} — PR (val)\",  OUT_FIGS / f\"{base}_pr_val.png\")\n",
    "plot_pr_curve(y_test, proba_test, f\"{base} — PR (test)\", OUT_FIGS / f\"{base}_pr_test.png\")\n",
    "plot_roc_curve(y_val,  proba_val,  f\"{base} — ROC (val)\",  OUT_FIGS / f\"{base}_roc_val.png\")\n",
    "plot_roc_curve(y_test, proba_test, f\"{base} — ROC (test)\", OUT_FIGS / f\"{base}_roc_test.png\")\n",
    "plot_confusion(y_test, y_pred_test,\n",
    "               f\"{base} — Confusion (test @thr_used={thr_used:.3f})\",\n",
    "               OUT_FIGS / f\"{base}_cm_test.png\")\n",
    "\n",
    "# Importancias baseline\n",
    "try:\n",
    "    imp_gain = model.booster_.feature_importance(importance_type=\"gain\")\n",
    "except Exception:\n",
    "    imp_gain = model.feature_importances_\n",
    "imp_df = pd.DataFrame({\"feature\": feature_names_used[:len(imp_gain)], \"importance_gain\": imp_gain})\\\n",
    "         .sort_values(\"importance_gain\", ascending=False)\n",
    "imp_path = OUT_RESULTS / f\"{base}_feature_importances.csv\"\n",
    "imp_df.to_csv(imp_path, index=False)\n",
    "\n",
    "# Preds test baseline\n",
    "preds_path = OUT_PREDS / f\"preds_test_{base}.parquet\"\n",
    "pd.DataFrame({\"proba\": proba_test, \"y_true\": y_test}).to_parquet(preds_path, index=False)\n",
    "\n",
    "# Registro de resultados baseline\n",
    "row_base = {\n",
    "    \"model\": base,\n",
    "    \"thr_val\": thr_val,\n",
    "    \"thr_oof\": thr_oof,\n",
    "    \"thr_used\": thr_used,\n",
    "    \"val_pr_auc\": val_metrics[\"pr_auc\"],\n",
    "    \"val_roc_auc\": val_metrics[\"roc_auc\"],\n",
    "    \"val_precision\": val_metrics[\"precision\"],\n",
    "    \"val_f1\": val_metrics[\"f1\"],\n",
    "    \"val_recall\": val_metrics[\"recall\"],\n",
    "    \"val_bal_acc\": val_metrics[\"bal_acc\"],\n",
    "    \"test_pr_auc\": test_metrics[\"pr_auc\"],\n",
    "    \"test_roc_auc\": test_metrics[\"roc_auc\"],\n",
    "    \"test_precision\": test_metrics[\"precision\"],\n",
    "    \"test_f1\": test_metrics[\"f1\"],\n",
    "    \"test_recall\": test_metrics[\"recall\"],\n",
    "    \"test_bal_acc\": test_metrics[\"bal_acc\"],\n",
    "    \"best_iteration\": getattr(model, \"best_iteration_\", None)\n",
    "}\n",
    "res_csv = OUT_RESULTS / \"baselines.csv\"\n",
    "pd.DataFrame([row_base]).to_csv(\n",
    "    res_csv,\n",
    "    mode=(\"a\" if res_csv.exists() else \"w\"),\n",
    "    index=False,\n",
    "    header=not res_csv.exists()\n",
    ")\n",
    "\n",
    "print(\"[OK][BASE] Guardados:\",\n",
    "      \"\\n  - Seed HPs   :\", params_seed_path.name,\n",
    "      \"\\n  - Fitted HPs :\", params_fitted_path.name,\n",
    "      \"\\n  - Importancias:\", imp_path.name,\n",
    "      \"\\n  - Preds test  :\", preds_path.name,\n",
    "      \"\\n  - Baselines   :\", res_csv.name)\n",
    "\n",
    "# === TUNED ===\n",
    "if tuned_model is not None:\n",
    "    proba_val_tuned  = pred_proba_best(tuned_model, X_val_fit)\n",
    "    thr_val_tuned, _ = find_best_threshold(y_val, proba_val_tuned, metric=\"f1\")\n",
    "    val_metrics_tuned = compute_all_metrics(y_val, proba_val_tuned, thr_val_tuned)\n",
    "\n",
    "    proba_test_tuned = pred_proba_best(tuned_model, X_test_fit)\n",
    "\n",
    "    # CV para tuned\n",
    "    cv_tuned = run_oof_cv(tuned_model.get_params(), X_train_fit, y_train, exp_suffix=\"TUNED\", categorical_mask=CAT_MASK_USED)\n",
    "    thr_oof_tuned = cv_tuned[\"thr\"]\n",
    "    thr_used_tuned = thr_oof_tuned\n",
    "\n",
    "    y_pred_test_tuned = (proba_test_tuned >= thr_used_tuned).astype(int)\n",
    "    test_metrics_tuned = compute_all_metrics(y_test, proba_test_tuned, thr_used_tuned)\n",
    "\n",
    "    tuned_fitted_path = OUT_PARAMS / f\"{base}_TUNED_fitted_params.json\"\n",
    "    with open(tuned_fitted_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(tuned_model.get_params(), f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    base_t = base + \"_TUNED\"\n",
    "    plot_pr_curve(y_val,  proba_val_tuned,  f\"{base_t} — PR (val)\",  OUT_FIGS / f\"{base_t}_pr_val.png\")\n",
    "    plot_pr_curve(y_test, proba_test_tuned, f\"{base_t} — PR (test)\", OUT_FIGS / f\"{base_t}_pr_test.png\")\n",
    "    plot_roc_curve(y_val,  proba_val_tuned,  f\"{base_t} — ROC (val)\",  OUT_FIGS / f\"{base_t}_roc_val.png\")\n",
    "    plot_roc_curve(y_test, proba_test_tuned, f\"{base_t} — ROC (test)\", OUT_FIGS / f\"{base_t}_roc_test.png\")\n",
    "    plot_confusion(y_test, y_pred_test_tuned,\n",
    "                   f\"{base_t} — Confusion (test @thr_used={thr_used_tuned:.3f})\",\n",
    "                   OUT_FIGS / f\"{base_t}_cm_test.png\")\n",
    "\n",
    "    try:\n",
    "        imp_gain_t = tuned_model.booster_.feature_importance(importance_type=\"gain\")\n",
    "    except Exception:\n",
    "        imp_gain_t = tuned_model.feature_importances_\n",
    "    imp_t_path = OUT_RESULTS / f\"{base_t}_feature_importances.csv\"\n",
    "    pd.DataFrame({\"feature\": feature_names_used[:len(imp_gain_t)], \"importance_gain\": imp_gain_t})\\\n",
    "      .sort_values(\"importance_gain\", ascending=False)\\\n",
    "      .to_csv(imp_t_path, index=False)\n",
    "\n",
    "    preds_t_path = OUT_PREDS / f\"preds_test_{base_t}.parquet\"\n",
    "    pd.DataFrame({\"proba\": proba_test_tuned, \"y_true\": y_test}).to_parquet(preds_t_path, index=False)\n",
    "\n",
    "    row_t = {\n",
    "        \"model\": base_t,\n",
    "        \"thr_val\": thr_val_tuned,\n",
    "        \"thr_oof\": thr_oof_tuned,\n",
    "        \"thr_used\": thr_used_tuned,\n",
    "        \"val_pr_auc\": val_metrics_tuned[\"pr_auc\"],\n",
    "        \"val_roc_auc\": val_metrics_tuned[\"roc_auc\"],\n",
    "        \"val_precision\": val_metrics_tuned[\"precision\"],\n",
    "        \"val_f1\": val_metrics_tuned[\"f1\"],\n",
    "        \"val_recall\": val_metrics_tuned[\"recall\"],\n",
    "        \"val_bal_acc\": val_metrics_tuned[\"bal_acc\"],\n",
    "        \"test_pr_auc\": test_metrics_tuned[\"pr_auc\"],\n",
    "        \"test_roc_auc\": test_metrics_tuned[\"roc_auc\"],\n",
    "        \"test_precision\": test_metrics_tuned[\"precision\"],\n",
    "        \"test_f1\": test_metrics_tuned[\"f1\"],\n",
    "        \"test_recall\": test_metrics_tuned[\"recall\"],\n",
    "        \"test_bal_acc\": test_metrics_tuned[\"bal_acc\"],\n",
    "        \"best_iteration\": getattr(tuned_model, \"best_iteration_\", None)\n",
    "    }\n",
    "    pd.DataFrame([row_t]).to_csv(\n",
    "        res_csv,\n",
    "        mode=(\"a\" if res_csv.exists() else \"w\"),\n",
    "        index=False,\n",
    "        header=not res_csv.exists()\n",
    "    )\n",
    "\n",
    "    print(\"[OK][TUNED] Guardados:\",\n",
    "          \"\\n  - Fitted HPs :\", tuned_fitted_path.name,\n",
    "          \"\\n  - Importancias:\", imp_t_path.name,\n",
    "          \"\\n  - Preds test  :\", preds_t_path.name,\n",
    "          \"\\n  - Baselines   :\", res_csv.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e99a5",
   "metadata": {},
   "source": [
    "10 - Mejores Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "74033154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MEJORES EN TEST (por métrica) ===\n",
      "- test_pr_auc: LGBM_FULL_SMOTENC_TUNED | PR-AUC=0.7037 | ROC-AUC=0.8599 | F1=0.6291 | Recall=0.5897 | Precision=0.6742 | thr_used=0.527 | best_iter=236\n",
      "- test_roc_auc: LGBM_FULL_SMOTENC | PR-AUC=0.6979 | ROC-AUC=0.8617 | F1=0.6235 | Recall=0.5921 | Precision=0.6585 | thr_used=0.525 | best_iter=53\n",
      "- test_recall: LGBM_FULL_SMOTENC | PR-AUC=0.6979 | ROC-AUC=0.8617 | F1=0.6235 | Recall=0.5921 | Precision=0.6585 | thr_used=0.525 | best_iter=53\n",
      "- test_f1: LGBM_FULL_SMOTENC_TUNED | PR-AUC=0.7037 | ROC-AUC=0.8599 | F1=0.6291 | Recall=0.5897 | Precision=0.6742 | thr_used=0.527 | best_iter=236\n",
      "- test_precision: LGBM_FULL_SMOTENC_TUNED | PR-AUC=0.7037 | ROC-AUC=0.8599 | F1=0.6291 | Recall=0.5897 | Precision=0.6742 | thr_used=0.527 | best_iter=236\n",
      "\n",
      "=== RESUMEN CV-OOF (por experimento) ===\n",
      "                           tag   pr_auc  roc_auc       f1   recall  bal_acc   thr\n",
      "   LGBM_FULL_SMOTENC_TUNED_CV5 0.680747 0.851699 0.614302 0.642682 0.763773 0.527\n",
      "LGBM_FULL_SMOTENC_BASELINE_CV5 0.680747 0.851699 0.614302 0.642682 0.763773 0.527\n",
      "\n",
      "=== COMPARACIÓN SOTA vs. MEJOR TEST ===\n",
      "Paper LGBM: AUC=0.914 | Recall=0.881 | Precision=0.948\n",
      "Mejor  : AUC=0.8617 | Recall=0.5921 | Precision=0.6585\n",
      "Deltas    : ΔAUC=-0.052 | ΔRecall=-0.289\n",
      "[OK] Normalizado. Backup: baselines_legacy_backup.csv\n"
     ]
    }
   ],
   "source": [
    "AGGREGATE_ALL_RUNS = False\n",
    "\n",
    "def safe(v, fmt=\".4f\"):\n",
    "    try:\n",
    "        return f\"{float(v):{fmt}}\"\n",
    "    except Exception:\n",
    "        return \"NA\"\n",
    "\n",
    "base_csv = OUT_RESULTS / \"baselines.csv\"\n",
    "if not base_csv.exists():\n",
    "    raise FileNotFoundError(f\"No existe {base_csv}\")\n",
    "\n",
    "df = pd.read_csv(base_csv)\n",
    "\n",
    "# Esquema final \n",
    "needed = [\n",
    "    \"model\",\n",
    "    \"thr_val\", \"thr_oof\", \"thr_used\",\n",
    "    \"val_pr_auc\",\"val_roc_auc\",\"val_precision\",\"val_f1\",\"val_recall\",\"val_bal_acc\",\n",
    "    \"test_pr_auc\",\"test_roc_auc\",\"test_precision\",\"test_f1\",\"test_recall\",\"test_bal_acc\",\n",
    "    \"best_iteration\"\n",
    "]\n",
    "\n",
    "# Columnas faltantes\n",
    "for c in needed:\n",
    "    if c not in df.columns:\n",
    "        df[c] = pd.NA\n",
    "\n",
    "# Ordena\n",
    "df = df[needed].copy()\n",
    "\n",
    "# Convierte numéricas\n",
    "num_cols = [c for c in needed if c not in (\"model\",)]\n",
    "for c in num_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "if AGGREGATE_ALL_RUNS:\n",
    "    root_art = ARTIF_DIR.parent\n",
    "    for p in (root_art).glob(\"LGBM_*/results/baselines.csv\"):\n",
    "        if p == base_csv:\n",
    "            continue\n",
    "        try:\n",
    "            d2 = pd.read_csv(p)\n",
    "            for c in needed:\n",
    "                if c not in d2.columns:\n",
    "                    d2[c] = pd.NA\n",
    "            d2 = d2[needed]\n",
    "            for c in num_cols:\n",
    "                d2[c] = pd.to_numeric(d2[c], errors=\"coerce\")\n",
    "            df = pd.concat([df, d2], ignore_index=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "if df.empty:\n",
    "    raise ValueError(\"El dataframe de resultados está vacío.\")\n",
    "\n",
    "def best_by(metric):\n",
    "    if metric not in df.columns or df[metric].dropna().empty:\n",
    "        return None\n",
    "    r = df.loc[df[metric].idxmax()]\n",
    "    print(\n",
    "        f\"- {metric}: {r['model']} | \"\n",
    "        f\"PR-AUC={safe(r['test_pr_auc'])} | \"\n",
    "        f\"ROC-AUC={safe(r['test_roc_auc'])} | \"\n",
    "        f\"F1={safe(r['test_f1'])} | \"\n",
    "        f\"Recall={safe(r['test_recall'])} | \"\n",
    "        f\"Precision={safe(r['test_precision'])} | \"\n",
    "        f\"thr_used={safe(r['thr_used'], '.3f')} | \"\n",
    "        f\"best_iter={int(r['best_iteration']) if pd.notna(r['best_iteration']) else 'NA'}\"\n",
    "    )\n",
    "    return r\n",
    "\n",
    "print(\"=== MEJORES EN TEST (por métrica) ===\")\n",
    "winners = {}\n",
    "for m in [\"test_pr_auc\",\"test_roc_auc\",\"test_recall\",\"test_f1\",\"test_precision\"]:\n",
    "    w = best_by(m)\n",
    "    if w is not None: winners[m] = w\n",
    "\n",
    "cv_files = list(OUT_RESULTS.glob(\"cv_summary_*_CV*.csv\"))\n",
    "if cv_files:\n",
    "    print(\"\\n=== RESUMEN CV-OOF (por experimento) ===\")\n",
    "    rows = []\n",
    "    for f in cv_files:\n",
    "        tag = re.sub(r\"^cv_summary_|\\.csv$\", \"\", f.name)\n",
    "        cv = pd.read_csv(f)\n",
    "        oof = cv.loc[cv[\"fold\"] == \"OOF\"]\n",
    "        if not oof.empty:\n",
    "            r = oof.iloc[0]\n",
    "            rows.append({\n",
    "                \"tag\": tag,\n",
    "                \"pr_auc\": r.get(\"pr_auc\"),\n",
    "                \"roc_auc\": r.get(\"roc_auc\"),\n",
    "                \"f1\": r.get(\"f1\"),\n",
    "                \"recall\": r.get(\"recall\"),\n",
    "                \"bal_acc\": r.get(\"bal_acc\"),\n",
    "                \"thr\": r.get(\"thr\"),\n",
    "            })\n",
    "    if rows:\n",
    "        print(pd.DataFrame(rows).sort_values([\"pr_auc\",\"roc_auc\"], ascending=False).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n(No se hallaron archivos de CV para este experimento)\")\n",
    "\n",
    "# SOTA\n",
    "SOTA = {\"LGBM\": {\"AUC\": 0.914, \"Recall\": 0.881, \"Precision\": 0.948}}\n",
    "if \"test_roc_auc\" in winners:\n",
    "    bt = winners[\"test_roc_auc\"]\n",
    "    d_auc = float(bt[\"test_roc_auc\"]) - SOTA[\"LGBM\"][\"AUC\"]\n",
    "    d_rec = float(bt[\"test_recall\"])   - SOTA[\"LGBM\"][\"Recall\"]\n",
    "    print(\"\\n=== COMPARACIÓN SOTA vs. MEJOR TEST ===\")\n",
    "    print(f\"Paper LGBM: AUC={SOTA['LGBM']['AUC']:.3f} | Recall={SOTA['LGBM']['Recall']:.3f} | Precision={SOTA['LGBM']['Precision']:.3f}\")\n",
    "    print(f\"Mejor  : AUC={safe(bt['test_roc_auc'])} | Recall={safe(bt['test_recall'])} | Precision={safe(bt['test_precision'])}\")\n",
    "    print(f\"Deltas    : ΔAUC={d_auc:+.3f} | ΔRecall={d_rec:+.3f}\")\n",
    "\n",
    "# Normalización con backup\n",
    "backup = OUT_RESULTS / \"baselines_legacy_backup.csv\"\n",
    "base_csv.replace(backup)\n",
    "df.to_csv(base_csv, index=False)\n",
    "print(\"[OK] Normalizado. Backup:\", backup.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
