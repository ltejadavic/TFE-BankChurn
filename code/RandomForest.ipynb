{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2aec4297-rf",
      "metadata": {},
      "source": [
        "1 — Imports, configuración y rutas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "565a4b55-rf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exp: RF_FULL_SMOTENC\n",
            "DATA_DIR: /Users/luistejada/Downloads/TFE Churn Bancario/preproc_datasets/full\n",
            "ARTIF_DIR: /Users/luistejada/Downloads/TFE Churn Bancario/artifacts/RF_FULL_SMOTENC\n"
          ]
        }
      ],
      "source": [
        "import json, os, warnings, time, re, glob\n",
        "from pathlib import Path\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    average_precision_score, precision_recall_curve, roc_auc_score, roc_curve,\n",
        "    f1_score, recall_score, balanced_accuracy_score, confusion_matrix, precision_score\n",
        ")\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Balanceo (SMOTENC)\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTENC\n",
        "    _HAS_IMBLEARN = True\n",
        "except Exception:\n",
        "    _HAS_IMBLEARN = False\n",
        "\n",
        "# === Toggles de experimento ===\n",
        "USE_REDUCED = False              \n",
        "USE_BALANCED_TRAIN = True        \n",
        "BALANCE_IN_CV = True             \n",
        "RANDOM_STATE = 42\n",
        "DO_TUNE = True\n",
        "DO_CV_BASELINE = True\n",
        "DO_CV_TUNED = True\n",
        "CV_FOLDS = 5\n",
        "MI_TOPK = 30                     \n",
        "\n",
        "# === Nombres y rutas ===\n",
        "ROOT = Path.cwd().parent\n",
        "EXP_NAME = f\"RF_{'REDUCED' if USE_REDUCED else 'FULL'}_{'SMOTENC' if USE_BALANCED_TRAIN else 'IMB'}\"\n",
        "ARTIF_DIR = ROOT / \"artifacts\" / EXP_NAME\n",
        "OUT_RESULTS = ARTIF_DIR / \"results\"\n",
        "OUT_FIGS    = ARTIF_DIR / \"figs\"\n",
        "OUT_PREDS   = ARTIF_DIR / \"preds\"\n",
        "OUT_PARAMS  = ARTIF_DIR / \"best_params\"\n",
        "for p in [OUT_RESULTS, OUT_FIGS, OUT_PREDS, OUT_PARAMS]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Dataset preprocesado\n",
        "DATA_DIR = ROOT / \"preproc_datasets\" / \"full\"\n",
        "\n",
        "print(\"Exp:\", EXP_NAME)\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n",
        "print(\"ARTIF_DIR:\", ARTIF_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cd89f52-rf",
      "metadata": {},
      "source": [
        "2 — Carga de artefactos (X, y, features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "38f0a43f-rf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes: (6000, 15) (2000, 15) (2000, 15)\n",
            "y train/val/test: (6000,) (2000,) (2000,)\n",
            "n features: 15\n"
          ]
        }
      ],
      "source": [
        "def load_xy_full(dir_full: Path):\n",
        "    X_train = np.load(dir_full / \"X_train_full.npy\")\n",
        "    X_val   = np.load(dir_full / \"X_val_full.npy\")\n",
        "    X_test  = np.load(dir_full / \"X_test_full.npy\")\n",
        "\n",
        "    y_train = pd.read_parquet(dir_full / \"y_train.parquet\")[\"Exited\"].to_numpy()\n",
        "    y_val   = pd.read_parquet(dir_full / \"y_val.parquet\")[\"Exited\"].to_numpy()\n",
        "    y_test  = pd.read_parquet(dir_full / \"y_test.parquet\")[\"Exited\"].to_numpy()\n",
        "\n",
        "    feat = pd.read_parquet(dir_full / \"feature_names_full.parquet\")[\"feature\"].tolist()\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test, feat\n",
        "\n",
        "X_train, y_train, X_val, y_val, X_test, y_test, feature_names = load_xy_full(DATA_DIR)\n",
        "print(\"Shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
        "print(\"y train/val/test:\", y_train.shape, y_val.shape, y_test.shape)\n",
        "print(\"n features:\", len(feature_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e693828-rf",
      "metadata": {},
      "source": [
        "3 — Métricas, threshold y utilidades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "650b59ba-rf",
      "metadata": {},
      "outputs": [],
      "source": [
        "def pr_auc(y_true, y_proba): \n",
        "    return float(average_precision_score(y_true, y_proba))\n",
        "\n",
        "def roc_auc(y_true, y_proba): \n",
        "    return float(roc_auc_score(y_true, y_proba))\n",
        "\n",
        "def find_best_threshold(y_true, y_proba, metric=\"f1\"):\n",
        "    thr_grid = np.linspace(0.0, 1.0, 1001)\n",
        "    best_thr, best_score = 0.5, -1.0\n",
        "    for thr in thr_grid:\n",
        "        y_pred = (y_proba >= thr).astype(int)\n",
        "        if metric == \"f1\":\n",
        "            score = f1_score(y_true, y_pred, zero_division=0)\n",
        "        elif metric == \"recall\":\n",
        "            score = recall_score(y_true, y_pred, zero_division=0)\n",
        "        else:\n",
        "            raise ValueError(\"metric no soportada\")\n",
        "        if score > best_score:\n",
        "            best_score, best_thr = score, thr\n",
        "    return float(best_thr), float(best_score)\n",
        "\n",
        "def compute_all_metrics(y_true, y_proba, thr):\n",
        "    y_pred = (y_proba >= thr).astype(int)\n",
        "    return {\n",
        "        \"pr_auc\": pr_auc(y_true, y_proba),\n",
        "        \"roc_auc\": roc_auc(y_true, y_proba),\n",
        "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
        "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
        "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
        "        \"bal_acc\": balanced_accuracy_score(y_true, y_pred)\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7943526-rf",
      "metadata": {},
      "source": [
        "4 — Helpers: MI Top-K (opcional) y balanceo SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "95ecc2fa-rf",
      "metadata": {},
      "outputs": [],
      "source": [
        "def fit_mi_selector(X, y, topk=30, seed=RANDOM_STATE):\n",
        "    mi = mutual_info_classif(X, y, random_state=seed, discrete_features=False)\n",
        "    idx = np.argsort(mi)[::-1][:topk]\n",
        "    return idx, mi\n",
        "\n",
        "def apply_keep_idx(X, keep_idx):\n",
        "    return X[:, keep_idx]\n",
        "\n",
        "def _infer_categorical_idx_from_names(feature_names_in):\n",
        "\n",
        "    cats = []\n",
        "    for i, n in enumerate(map(str, feature_names_in)):\n",
        "        nlow = n.lower()\n",
        "        if nlow.startswith(\"num__\"):\n",
        "            continue\n",
        "        if nlow.startswith((\"cat__\", \"ohe__\", \"bin__\")) or not nlow.startswith(\"num__\"):\n",
        "            cats.append(i)\n",
        "    return cats\n",
        "\n",
        "def _load_categorical_names_from_metadata():\n",
        "\n",
        "    # 1) Parquet\n",
        "    p_parquet = DATA_DIR / \"feature_metadata.parquet\"\n",
        "    if p_parquet.exists():\n",
        "        try:\n",
        "            meta = pd.read_parquet(p_parquet)\n",
        "            cols = {c.lower() for c in meta.columns}\n",
        "    \n",
        "            name_col = \"feature\" if \"feature\" in cols else (\"name\" if \"name\" in cols else None)\n",
        "            flag_col = \"is_categorical\" if \"is_categorical\" in cols else (\"categorical\" if \"categorical\" in cols else None)\n",
        "            if name_col is None or flag_col is None:\n",
        "\n",
        "                if \"dtype\" in cols:\n",
        "                    meta.columns = [c.lower() for c in meta.columns]\n",
        "                    cat_names = set(meta.loc[meta[\"dtype\"].astype(str).str.contains(\"cat\", case=False), \"feature\"])\n",
        "                    return {str(x) for x in cat_names}\n",
        "                return None\n",
        "            # normaliza nombres de columnas\n",
        "            meta.columns = [c.lower() for c in meta.columns]\n",
        "            cat_names = set(meta.loc[meta[flag_col].astype(bool), \"feature\"])\n",
        "            return {str(x) for x in cat_names}\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # 2) JSON\n",
        "    p_json = DATA_DIR / \"feature_metadata.json\"\n",
        "    if p_json.exists():\n",
        "        try:\n",
        "            obj = json.loads(p_json.read_text())\n",
        "            if isinstance(obj, dict):\n",
        "                if \"categorical_features\" in obj and isinstance(obj[\"categorical_features\"], (list, tuple)):\n",
        "                    return {str(x) for x in obj[\"categorical_features\"]}\n",
        "                if \"categorical_mask\" in obj and isinstance(obj[\"categorical_mask\"], (list, tuple)):\n",
        "                    mask = list(map(bool, obj[\"categorical_mask\"]))\n",
        "\n",
        "                    p_full = DATA_DIR / \"feature_names_full.parquet\"\n",
        "                    if p_full.exists():\n",
        "                        full_names = pd.read_parquet(p_full)[\"feature\"].tolist()\n",
        "                        names = [str(n) for n, m in zip(full_names, mask) if m]\n",
        "                        return set(names)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return None\n",
        "\n",
        "def _categorical_idx_for(feature_names_in):\n",
        "    meta_cats = _load_categorical_names_from_metadata()\n",
        "    if meta_cats:\n",
        "\n",
        "        idx = [i for i, n in enumerate(map(str, feature_names_in)) if n in meta_cats]\n",
        "        if idx:\n",
        "            return idx\n",
        "    # Fallback por nombre\n",
        "    return _infer_categorical_idx_from_names(feature_names_in)\n",
        "\n",
        "def maybe_smotenc(X, y, feature_names_in, seed=RANDOM_STATE):\n",
        "    if not _HAS_IMBLEARN or X is None or feature_names_in is None or len(feature_names_in) == 0:\n",
        "        return X, y\n",
        "    try:\n",
        "        cat_idx = _categorical_idx_for(feature_names_in)\n",
        "        if not cat_idx:\n",
        "\n",
        "            return X, y\n",
        "        sm = SMOTENC(categorical_features=cat_idx, random_state=seed)\n",
        "        Xb, yb = sm.fit_resample(X, y)\n",
        "        return Xb, yb\n",
        "    except Exception as e:\n",
        "        print(\"[SMOTENC] Aviso: no se pudo aplicar SMOTENC. Se usa train original.\", e)\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d86df8a-rf",
      "metadata": {},
      "source": [
        "5 — Hiperparámetros persistentes (seed/best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "32cca868-rf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[HP] Cargando mejores hiperparámetros previos: BEST_RF_FULL_SMOTENC.json\n"
          ]
        }
      ],
      "source": [
        "VIEW_TAG = \"REDUCED\" if USE_REDUCED else \"FULL\"\n",
        "BAL_TAG  = \"SMOTENC\" if USE_BALANCED_TRAIN else \"IMB\"\n",
        "BEST_HP_FILE = OUT_PARAMS / f\"BEST_RF_{VIEW_TAG}_{BAL_TAG}.json\"\n",
        "\n",
        "def get_rf_defaults(seed=RANDOM_STATE):\n",
        "    mdl = RandomForestClassifier(\n",
        "        random_state=seed,\n",
        "        n_jobs=-1,\n",
        "        class_weight=None,\n",
        "        criterion=\"gini\",\n",
        "        n_estimators=500,\n",
        "        max_depth=None,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        max_features=\"sqrt\",\n",
        "        bootstrap=True\n",
        "    )\n",
        "    return mdl.get_params()\n",
        "\n",
        "def load_best_or_default():\n",
        "    if BEST_HP_FILE.exists():\n",
        "        try:\n",
        "            best = json.loads(BEST_HP_FILE.read_text())\n",
        "            print(\"[HP] Cargando mejores hiperparámetros previos:\", BEST_HP_FILE.name)\n",
        "            base = get_rf_defaults()\n",
        "            base.update(best)\n",
        "            return base, True\n",
        "        except Exception as e:\n",
        "            print(\"[HP] Aviso: no se pudo leer BEST (uso defaults).\", e)\n",
        "    print(\"[HP] Usando hiperparámetros DEFAULT de RF.\")\n",
        "    return get_rf_defaults(), False\n",
        "\n",
        "seed_params, loaded_best_flag = load_best_or_default()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfed62da-rf",
      "metadata": {},
      "source": [
        "6 — Entrenamiento BASELINE + umbral (val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ea25cb27-rf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[BASELINE] Mejor umbral (val) por F1: 0.538 | F1(val)=0.6357\n",
            "[BASELINE] Métricas val: {'pr_auc': 0.6768, 'roc_auc': 0.8574, 'precision': 0.6022, 'f1': 0.6357, 'recall': 0.6732, 'bal_acc': 0.7798}\n"
          ]
        }
      ],
      "source": [
        "seed_params = dict(seed_params)\n",
        "seed_params.setdefault(\"random_state\", RANDOM_STATE)\n",
        "seed_params.setdefault(\"n_jobs\", -1)\n",
        "\n",
        "keep_idx_global = None\n",
        "feature_names_used = feature_names\n",
        "X_train_fit, X_val_fit, X_test_fit = X_train, X_val, X_test\n",
        "\n",
        "if USE_REDUCED:\n",
        "    keep_idx_global, _mi = fit_mi_selector(X_train, y_train, topk=MI_TOPK, seed=RANDOM_STATE)\n",
        "    X_train_fit = apply_keep_idx(X_train, keep_idx_global)\n",
        "    X_val_fit   = apply_keep_idx(X_val,   keep_idx_global)\n",
        "    X_test_fit  = apply_keep_idx(X_test,  keep_idx_global)\n",
        "    feature_names_used = [feature_names[i] for i in keep_idx_global]\n",
        "\n",
        "# === Balanceo con SMOTENC ===\n",
        "X_train_final, y_train_final = X_train_fit, y_train\n",
        "if USE_BALANCED_TRAIN:\n",
        "    X_train_final, y_train_final = maybe_smotenc(X_train_fit, y_train, feature_names_used, seed=RANDOM_STATE)\n",
        "\n",
        "model = RandomForestClassifier(**seed_params)\n",
        "model.fit(X_train_final, y_train_final)\n",
        "\n",
        "proba_val = model.predict_proba(X_val_fit)[:, 1]\n",
        "thr_val, best_f1_val = find_best_threshold(y_val, proba_val, metric=\"f1\")\n",
        "print(f\"[BASELINE] Mejor umbral (val) por F1: {thr_val:.3f} | F1(val)={best_f1_val:.4f}\")\n",
        "\n",
        "val_metrics = compute_all_metrics(y_val, proba_val, thr_val)\n",
        "print(\"[BASELINE] Métricas val:\", {k: (round(v,4) if isinstance(v,float) else v) for k,v in val_metrics.items()})\n",
        "\n",
        "baseline = model\n",
        "tuned_model = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94d893d5-rf",
      "metadata": {},
      "source": [
        "7 — Optimización incremental (Optuna, objetivo = AP/PR-AUC en val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "03c63f35-rf",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-12 23:18:20,748] A new study created in memory with name: RF_FULL_SMOTENC_AP\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OPTUNA] Enqueuing previous BEST as a trial seed.\n",
            "[OPTUNA] Iniciando estudio 'RF_FULL_SMOTENC_AP' con 40 pruebas...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-12 23:18:25,176] Trial 0 finished with value: 0.6767628484566041 and parameters: {'n_estimators': 1650, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:18:26,887] Trial 1 finished with value: 0.6580992081835771 and parameters: {'n_estimators': 850, 'max_depth': None, 'min_samples_split': 22, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini', 'class_weight': None}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:18:27,994] Trial 2 finished with value: 0.6452514043365771 and parameters: {'n_estimators': 850, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 19, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini', 'class_weight': None}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:18:30,644] Trial 3 finished with value: 0.6661751107079547 and parameters: {'n_estimators': 750, 'max_depth': 12, 'min_samples_split': 28, 'min_samples_leaf': 2, 'max_features': 0.7, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:18:34,978] Trial 4 finished with value: 0.6691145789668477 and parameters: {'n_estimators': 2000, 'max_depth': 12, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy', 'class_weight': 'balanced_subsample'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:18:36,953] Trial 5 finished with value: 0.6478962602093041 and parameters: {'n_estimators': 1600, 'max_depth': 6, 'min_samples_split': 20, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini', 'class_weight': None}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:18:41,299] Trial 6 finished with value: 0.671400346660722 and parameters: {'n_estimators': 1800, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced_subsample'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:18:42,904] Trial 7 finished with value: 0.6725405420045188 and parameters: {'n_estimators': 850, 'max_depth': None, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:18:52,247] Trial 8 finished with value: 0.6325878599541384 and parameters: {'n_estimators': 1350, 'max_depth': 12, 'min_samples_split': 21, 'min_samples_leaf': 1, 'max_features': 0.9, 'bootstrap': False, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:18:54,006] Trial 9 finished with value: 0.6750623747833203 and parameters: {'n_estimators': 650, 'max_depth': 40, 'min_samples_split': 20, 'min_samples_leaf': 7, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:18:58,149] Trial 10 finished with value: 0.6749990729363062 and parameters: {'n_estimators': 1650, 'max_depth': None, 'min_samples_split': 17, 'min_samples_leaf': 14, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:19:00,929] Trial 11 finished with value: 0.6759615268467642 and parameters: {'n_estimators': 1050, 'max_depth': 40, 'min_samples_split': 18, 'min_samples_leaf': 10, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:19:05,322] Trial 12 finished with value: 0.675565670308043 and parameters: {'n_estimators': 1550, 'max_depth': 40, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:19:07,027] Trial 13 finished with value: 0.6725901044486738 and parameters: {'n_estimators': 700, 'max_depth': 40, 'min_samples_split': 12, 'min_samples_leaf': 17, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:19:13,686] Trial 14 finished with value: 0.6718651432109679 and parameters: {'n_estimators': 1950, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 11, 'max_features': 0.7, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:19:17,934] Trial 15 finished with value: 0.6612186425954778 and parameters: {'n_estimators': 1200, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 13, 'max_features': 0.5, 'bootstrap': False, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:19:19,927] Trial 16 finished with value: 0.6672332299326523 and parameters: {'n_estimators': 1250, 'max_depth': 40, 'min_samples_split': 22, 'min_samples_leaf': 15, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:19:23,984] Trial 17 finished with value: 0.6705516563977277 and parameters: {'n_estimators': 1250, 'max_depth': 40, 'min_samples_split': 2, 'min_samples_leaf': 16, 'max_features': 0.7, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:19:30,411] Trial 18 finished with value: 0.6715438455491031 and parameters: {'n_estimators': 1650, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 13, 'max_features': 0.5, 'bootstrap': False, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:19:33,077] Trial 19 finished with value: 0.6720927411987889 and parameters: {'n_estimators': 1450, 'max_depth': 16, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:19:35,235] Trial 20 finished with value: 0.6601083978367592 and parameters: {'n_estimators': 1450, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 13, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:19:44,559] Trial 21 finished with value: 0.6457651039766762 and parameters: {'n_estimators': 1850, 'max_depth': 40, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 0.9, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:19:48,381] Trial 22 finished with value: 0.6673992413140587 and parameters: {'n_estimators': 1600, 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 8, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'gini', 'class_weight': None}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:19:51,255] Trial 23 finished with value: 0.6744916129491333 and parameters: {'n_estimators': 1000, 'max_depth': 40, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:19:54,746] Trial 24 finished with value: 0.6700381260268786 and parameters: {'n_estimators': 1500, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:20:01,915] Trial 25 finished with value: 0.673212213657112 and parameters: {'n_estimators': 1900, 'max_depth': 40, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced_subsample'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:20:07,309] Trial 26 finished with value: 0.6721886742718409 and parameters: {'n_estimators': 1450, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 16, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced_subsample'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:20:10,231] Trial 27 finished with value: 0.668946279370015 and parameters: {'n_estimators': 1200, 'max_depth': None, 'min_samples_split': 21, 'min_samples_leaf': 8, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'gini', 'class_weight': None}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:20:12,431] Trial 28 finished with value: 0.6611928529213394 and parameters: {'n_estimators': 1100, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:20:14,406] Trial 29 finished with value: 0.6475909983451688 and parameters: {'n_estimators': 1500, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:20:19,352] Trial 30 finished with value: 0.6686295608094188 and parameters: {'n_estimators': 1850, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:20:21,351] Trial 31 finished with value: 0.6750245616557428 and parameters: {'n_estimators': 650, 'max_depth': 40, 'min_samples_split': 19, 'min_samples_leaf': 4, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:20:27,110] Trial 32 finished with value: 0.6673101191373602 and parameters: {'n_estimators': 1850, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:20:28,274] Trial 33 finished with value: 0.66940410443081 and parameters: {'n_estimators': 450, 'max_depth': 40, 'min_samples_split': 21, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced_subsample'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:20:30,006] Trial 34 finished with value: 0.6748810226681843 and parameters: {'n_estimators': 650, 'max_depth': 12, 'min_samples_split': 20, 'min_samples_leaf': 12, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:20:30,983] Trial 35 finished with value: 0.6574736711677295 and parameters: {'n_estimators': 300, 'max_depth': 40, 'min_samples_split': 25, 'min_samples_leaf': 8, 'max_features': 0.7, 'bootstrap': True, 'criterion': 'gini', 'class_weight': None}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:20:33,143] Trial 36 finished with value: 0.6482179557407622 and parameters: {'n_estimators': 700, 'max_depth': 6, 'min_samples_split': 24, 'min_samples_leaf': 9, 'max_features': 0.9, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:20:37,081] Trial 37 finished with value: 0.6747811225604626 and parameters: {'n_estimators': 1300, 'max_depth': 40, 'min_samples_split': 20, 'min_samples_leaf': 6, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:20:38,441] Trial 38 finished with value: 0.6701136125732633 and parameters: {'n_estimators': 600, 'max_depth': None, 'min_samples_split': 20, 'min_samples_leaf': 9, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy', 'class_weight': None}. Best is trial 0 with value: 0.6767628484566041.\n",
            "[I 2025-12-12 23:20:40,820] Trial 39 finished with value: 0.6710544039696469 and parameters: {'n_estimators': 650, 'max_depth': 30, 'min_samples_split': 16, 'min_samples_leaf': 11, 'max_features': 0.7, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None}. Best is trial 0 with value: 0.6767628484566041.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OPTUNA] Mejor AP(val): 0.676763\n",
            "[OPTUNA] Params ganadores: {'n_estimators': 1650, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 0.5, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced'}\n",
            "[OPTUNA] Guardado BEST en: BEST_RF_FULL_SMOTENC.json\n",
            "[OPTUNA] Reentreno final completado.\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "tuned_model = None\n",
        "N_TRIALS = 40\n",
        "STUDY_NAME = f\"RF_{VIEW_TAG}_{BAL_TAG}_AP\"\n",
        "SAMPLER = TPESampler(seed=RANDOM_STATE, multivariate=True, group=False)\n",
        "study = optuna.create_study(direction=\"maximize\", study_name=STUDY_NAME, sampler=SAMPLER)\n",
        "\n",
        "SEARCH_KEYS = [\n",
        "    \"n_estimators\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\",\n",
        "    \"max_features\", \"bootstrap\", \"criterion\", \"class_weight\"\n",
        "]\n",
        "\n",
        "def suggest_rf_params(trial):\n",
        "    p = {}\n",
        "    p[\"n_estimators\"]     = trial.suggest_int(\"n_estimators\", 200, 2000, step=50)\n",
        "    p[\"max_depth\"]        = trial.suggest_categorical(\"max_depth\", [None, 6, 8, 12, 16, 20, 30, 40])\n",
        "    p[\"min_samples_split\"] = trial.suggest_int(\"min_samples_split\", 2, 30)\n",
        "    p[\"min_samples_leaf\"]  = trial.suggest_int(\"min_samples_leaf\", 1, 20)\n",
        "    p[\"max_features\"]      = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", 0.5, 0.7, 0.9])\n",
        "    p[\"bootstrap\"]         = trial.suggest_categorical(\"bootstrap\", [True, False])\n",
        "    p[\"criterion\"]         = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])  # amplio y compatible\n",
        "    p[\"class_weight\"]      = trial.suggest_categorical(\"class_weight\", [None, \"balanced\", \"balanced_subsample\"])\n",
        "    p[\"random_state\"]      = RANDOM_STATE\n",
        "    p[\"n_jobs\"]            = -1\n",
        "    return p\n",
        "\n",
        "# Warm-start con BEST previo\n",
        "if BEST_HP_FILE.exists():\n",
        "    try:\n",
        "        prev = json.loads(BEST_HP_FILE.read_text())\n",
        "        warm = {k: prev[k] for k in SEARCH_KEYS if k in prev}\n",
        "        if warm:\n",
        "            print(\"[OPTUNA] Enqueuing previous BEST as a trial seed.\")\n",
        "            study.enqueue_trial(warm)\n",
        "    except Exception as e:\n",
        "        print(\"[OPTUNA] Aviso: no se pudo usar BEST para warm-start:\", e)\n",
        "\n",
        "def objective(trial):\n",
        "    hp = suggest_rf_params(trial)\n",
        "    mdl = RandomForestClassifier(**{**seed_params, **hp})\n",
        "\n",
        "    # Entrenamos con el mismo esquema que el baseline\n",
        "    mdl.fit(X_train_final, y_train_final)\n",
        "    proba_val_t = mdl.predict_proba(X_val_fit)[:, 1]\n",
        "    ap = average_precision_score(y_val, proba_val_t)\n",
        "    return ap\n",
        "\n",
        "print(f\"[OPTUNA] Iniciando estudio '{STUDY_NAME}' con {N_TRIALS} pruebas...\")\n",
        "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=False)\n",
        "\n",
        "best = study.best_trial\n",
        "print(f\"[OPTUNA] Mejor AP(val): {best.value:.6f}\")\n",
        "print(f\"[OPTUNA] Params ganadores:\", best.params)\n",
        "\n",
        "best_params = dict(best.params)\n",
        "best_params.update({\n",
        "    \"random_state\": RANDOM_STATE,\n",
        "    \"n_jobs\": -1\n",
        "})\n",
        "with open(BEST_HP_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(best_params, f, indent=2, ensure_ascii=False)\n",
        "print(\"[OPTUNA] Guardado BEST en:\", BEST_HP_FILE.name)\n",
        "\n",
        "tuned_model = RandomForestClassifier(**best_params)\n",
        "tuned_model.fit(X_train_final, y_train_final)\n",
        "print(\"[OPTUNA] Reentreno final completado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8797a95-rf",
      "metadata": {},
      "source": [
        "8 — Cross-Validation (OOF) para baseline y tuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "efb9478a-rf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV-BASELINE] Guardados: cv_summary_RF_FULL_SMOTENC_BASELINE_CV5.csv | oof_RF_FULL_SMOTENC_BASELINE_CV5.parquet\n",
            "[CV-TUNED] Guardados: cv_summary_RF_FULL_SMOTENC_TUNED_CV5.csv | oof_RF_FULL_SMOTENC_TUNED_CV5.parquet\n"
          ]
        }
      ],
      "source": [
        "def run_oof_cv_rf(model_params, X, y, feature_names_in, k_folds=CV_FOLDS, seed=RANDOM_STATE, exp_suffix=\"BASELINE\"):\n",
        "    skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
        "    oof_proba = np.zeros_like(y, dtype=float)\n",
        "    fold_rows = []\n",
        "\n",
        "    base = dict(model_params)\n",
        "    base.setdefault(\"random_state\", seed)\n",
        "    base.setdefault(\"n_jobs\", -1)\n",
        "    base.setdefault(\"n_estimators\", 500)\n",
        "\n",
        "    for f, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
        "        X_tr0, X_va0 = X[tr_idx], X[va_idx]\n",
        "        y_tr0, y_va0 = y[tr_idx], y[va_idx]\n",
        "\n",
        "        feat_names_fold = list(feature_names_in)\n",
        "        keep_idx = None\n",
        "        if USE_REDUCED:\n",
        "            keep_idx, _ = fit_mi_selector(X_tr0, y_tr0, topk=MI_TOPK, seed=seed)\n",
        "            X_tr0 = apply_keep_idx(X_tr0, keep_idx)\n",
        "            X_va0 = apply_keep_idx(X_va0, keep_idx)\n",
        "            feat_names_fold = [feat_names_fold[i] for i in keep_idx]\n",
        "\n",
        "        # --- Balanceo por fold con SMOTENC ---\n",
        "        if BALANCE_IN_CV and USE_BALANCED_TRAIN:\n",
        "            X_tr, y_tr = maybe_smotenc(X_tr0, y_tr0, feat_names_fold, seed=seed)\n",
        "        else:\n",
        "            X_tr, y_tr = X_tr0, y_tr0\n",
        "\n",
        "        # Sanidad\n",
        "        assert X_tr.shape[1] == len(feat_names_fold), f\"[CV fold={f}] Desalineado tras SMOTENC.\"\n",
        "        assert X_va0.shape[1] == len(feat_names_fold), f\"[CV fold={f}] Desalineado val tras selección.\"\n",
        "\n",
        "        mdl = RandomForestClassifier(**base)\n",
        "        mdl.fit(X_tr, y_tr)\n",
        "        proba_va = mdl.predict_proba(X_va0)[:, 1]\n",
        "        oof_proba[va_idx] = proba_va\n",
        "\n",
        "        fold_rows.append({\n",
        "            \"fold\": f,\n",
        "            \"pr_auc\": average_precision_score(y_va0, proba_va),\n",
        "            \"roc_auc\": roc_auc_score(y_va0, proba_va)\n",
        "        })\n",
        "\n",
        "    oof_pr = average_precision_score(y, oof_proba)\n",
        "    oof_roc = roc_auc_score(y, oof_proba)\n",
        "    thr_oof, _ = find_best_threshold(y, oof_proba, metric=\"f1\")\n",
        "    y_oof_pred = (oof_proba >= thr_oof).astype(int)\n",
        "    oof_f1  = f1_score(y, y_oof_pred, zero_division=0)\n",
        "    oof_rec = recall_score(y, y_oof_pred, zero_division=0)\n",
        "    oof_bal = balanced_accuracy_score(y, y_oof_pred)\n",
        "\n",
        "    cv_tag = f\"{EXP_NAME}_{exp_suffix}_CV{CV_FOLDS}\"\n",
        "    cv_csv = OUT_RESULTS / f\"cv_summary_{cv_tag}.csv\"\n",
        "    folds_df = pd.DataFrame(fold_rows)\n",
        "    agg_row = pd.DataFrame([{\n",
        "        \"fold\": \"OOF\", \"pr_auc\": oof_pr, \"roc_auc\": oof_roc,\n",
        "        \"thr\": thr_oof, \"f1\": oof_f1, \"recall\": oof_rec, \"bal_acc\": oof_bal\n",
        "    }])\n",
        "    pd.concat([folds_df, agg_row], ignore_index=True).to_csv(cv_csv, index=False)\n",
        "\n",
        "    oof_path = OUT_PREDS / f\"oof_{cv_tag}.parquet\"\n",
        "    pd.DataFrame({\"oof_proba\": oof_proba, \"y_true\": y}).to_parquet(oof_path, index=False)\n",
        "\n",
        "    print(f\"[CV-{exp_suffix}] Guardados: {cv_csv.name} | {oof_path.name}\")\n",
        "    return {\"oof_pr_auc\": oof_pr, \"oof_roc_auc\": oof_roc, \"thr\": thr_oof,\n",
        "            \"oof_f1\": oof_f1, \"oof_recall\": oof_rec, \"oof_bal_acc\": oof_bal}\n",
        "\n",
        "cv_baseline = None\n",
        "cv_tuned = None\n",
        "\n",
        "if DO_CV_BASELINE:\n",
        "    cv_baseline = run_oof_cv_rf(seed_params, X_train_fit, y_train, feature_names_used, exp_suffix=\"BASELINE\")\n",
        "\n",
        "if DO_CV_TUNED and tuned_model is not None:\n",
        "    cv_tuned = run_oof_cv_rf(best_params, X_train_fit, y_train, feature_names_used, exp_suffix=\"TUNED\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15dae995-rf",
      "metadata": {},
      "source": [
        "9 — Evaluación en test + guardados (figuras, importancias, preds, baseline.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "983f541f-rf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK][BASE] Guardados: \n",
            "  - Seed HPs   : RF_FULL_SMOTENC_BASE_seed_params.json \n",
            "  - Fitted HPs : RF_FULL_SMOTENC_BASE_fitted_params.json \n",
            "  - Importancias: RF_FULL_SMOTENC_feature_importances.csv \n",
            "  - Preds test  : preds_test_RF_FULL_SMOTENC.parquet \n",
            "  - Baselines   : baselines.csv\n",
            "[OK][TUNED] Guardados: \n",
            "  - Fitted HPs : RF_FULL_SMOTENC_TUNED_fitted_params.json \n",
            "  - Importancias: RF_FULL_SMOTENC_TUNED_feature_importances.csv \n",
            "  - Preds test  : preds_test_RF_FULL_SMOTENC_TUNED.parquet \n",
            "  - Baselines   : baselines.csv\n"
          ]
        }
      ],
      "source": [
        "def plot_pr_curve(y_true, y_proba, title, out_path):\n",
        "    prec, rec, _ = precision_recall_curve(y_true, y_proba)\n",
        "    ap = average_precision_score(y_true, y_proba)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.step(rec, prec, where='post')\n",
        "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
        "    plt.title(f'{title} (AP={ap:.4f})')\n",
        "    plt.grid(True, linestyle='--', alpha=.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path, dpi=150); plt.close()\n",
        "\n",
        "def plot_roc_curve(y_true, y_proba, title, out_path):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
        "    auc = roc_auc_score(y_true, y_proba)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.plot(fpr, tpr, lw=2)\n",
        "    plt.plot([0,1],[0,1], 'k--', lw=1)\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'{title} (AUC={auc:.4f})')\n",
        "    plt.grid(True, linestyle='--', alpha=.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path, dpi=150); plt.close()\n",
        "\n",
        "def plot_confusion(y_true, y_pred, title, out_path, normalize=False):\n",
        "    norm = 'true' if normalize else None\n",
        "    cm = confusion_matrix(y_true, y_pred, normalize=norm)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    im = plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
        "    plt.title(title)\n",
        "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
        "    ticks = np.arange(2)\n",
        "    plt.xticks(ticks, ['0','1']); plt.yticks(ticks, ['0','1'])\n",
        "    thresh = cm.max()/2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            txt = f'{cm[i,j]:.2f}' if normalize else str(cm[i,j])\n",
        "            plt.text(j, i, txt, ha='center', va='center',\n",
        "                     color='white' if cm[i,j] > thresh else 'black')\n",
        "    plt.ylabel('True label'); plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path, dpi=150); plt.close()\n",
        "\n",
        "def rf_importances(model, feature_names):\n",
        "    try:\n",
        "        imp = np.asarray(model.feature_importances_, dtype=float)\n",
        "    except Exception:\n",
        "        imp = np.zeros(len(feature_names), dtype=float)\n",
        "    return pd.DataFrame({\"feature\": feature_names[:len(imp)], \"importance_gain\": imp})\n",
        "\n",
        "# ——— Evaluación y guardados ———\n",
        "base = EXP_NAME\n",
        "\n",
        "# BASELINE\n",
        "preds_val_base_path = OUT_PREDS / f\"preds_val_{base}.parquet\"\n",
        "pd.DataFrame({\"proba\": proba_val, \"y_true\": y_val}).to_parquet(\n",
        "    preds_val_base_path, index=False\n",
        ")\n",
        "\n",
        "# Guardar HP baseline (seed y fitted)\n",
        "params_seed_path = OUT_PARAMS / f\"{base}_BASE_seed_params.json\"\n",
        "with open(params_seed_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(seed_params, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "params_fitted_path = OUT_PARAMS / f\"{base}_BASE_fitted_params.json\"\n",
        "with open(params_fitted_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(model.get_params(), f, indent=2, ensure_ascii=False)\n",
        "\n",
        "# Figuras baseline\n",
        "plot_pr_curve(y_val,  proba_val,  f\"{base} — PR (val)\",  OUT_FIGS / f\"{base}_pr_val.png\")\n",
        "plot_pr_curve(y_test, proba_test, f\"{base} — PR (test)\", OUT_FIGS / f\"{base}_pr_test.png\")\n",
        "plot_roc_curve(y_val,  proba_val,  f\"{base} — ROC (val)\",  OUT_FIGS / f\"{base}_roc_val.png\")\n",
        "plot_roc_curve(y_test, proba_test, f\"{base} — ROC (test)\", OUT_FIGS / f\"{base}_roc_test.png\")\n",
        "plot_confusion(y_test, y_pred_test, f\"{base} — Confusion (test @thr={thr_val:.3f})\", OUT_FIGS / f\"{base}_cm_test.png\")\n",
        "\n",
        "# Importancias baseline\n",
        "imp_df = rf_importances(model, feature_names_used).sort_values(\"importance_gain\", ascending=False)\n",
        "imp_path = OUT_RESULTS / f\"{base}_feature_importances.csv\"\n",
        "imp_df.to_csv(imp_path, index=False)\n",
        "\n",
        "# Preds test baseline\n",
        "preds_path = OUT_PREDS / f\"preds_test_{base}.parquet\"\n",
        "pd.DataFrame({\"proba\": proba_test, \"y_true\": y_test}).to_parquet(preds_path, index=False)\n",
        "\n",
        "# Registro a baselines.csv\n",
        "row_base = {\n",
        "    \"model\": base,\n",
        "    \"thr_val\": thr_val,\n",
        "    \"val_pr_auc\": val_metrics[\"pr_auc\"],\n",
        "    \"val_roc_auc\": val_metrics[\"roc_auc\"],\n",
        "    \"val_precision\": val_metrics[\"precision\"],\n",
        "    \"val_f1\": val_metrics[\"f1\"],\n",
        "    \"val_recall\": val_metrics[\"recall\"],\n",
        "    \"val_bal_acc\": val_metrics[\"bal_acc\"],\n",
        "    \"test_pr_auc\": test_metrics[\"pr_auc\"],\n",
        "    \"test_roc_auc\": test_metrics[\"roc_auc\"],\n",
        "    \"test_precision\": test_metrics[\"precision\"],\n",
        "    \"test_f1\": test_metrics[\"f1\"],\n",
        "    \"test_recall\": test_metrics[\"recall\"],\n",
        "    \"test_bal_acc\": test_metrics[\"bal_acc\"],\n",
        "    \"best_iteration\": np.nan\n",
        "}\n",
        "res_csv = OUT_RESULTS / \"baselines.csv\"\n",
        "pd.DataFrame([row_base]).to_csv(res_csv, mode=(\"a\" if res_csv.exists() else \"w\"),\n",
        "                                index=False, header=not res_csv.exists())\n",
        "\n",
        "print(\"[OK][BASE] Guardados:\",\n",
        "      \"\\n  - Seed HPs   :\", params_seed_path.name,\n",
        "      \"\\n  - Fitted HPs :\", params_fitted_path.name,\n",
        "      \"\\n  - Importancias:\", imp_path.name,\n",
        "      \"\\n  - Preds test  :\", preds_path.name,\n",
        "      \"\\n  - Baselines   :\", res_csv.name)\n",
        "\n",
        "# TUNED\n",
        "if tuned_model is not None:\n",
        "    proba_val_tuned = tuned_model.predict_proba(X_val_fit)[:, 1]\n",
        "    thr_val_tuned, _ = find_best_threshold(y_val, proba_val_tuned, metric=\"f1\")\n",
        "    val_metrics_tuned = compute_all_metrics(y_val, proba_val_tuned, thr_val_tuned)\n",
        "\n",
        "    proba_test_tuned = tuned_model.predict_proba(X_test_fit)[:, 1]\n",
        "    y_pred_test_tuned = (proba_test_tuned >= thr_val_tuned).astype(int)\n",
        "    test_metrics_tuned = compute_all_metrics(y_test, proba_test_tuned, thr_val_tuned)\n",
        "\n",
        "    tuned_fitted_path = OUT_PARAMS / f\"{base}_TUNED_fitted_params.json\"\n",
        "    with open(tuned_fitted_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(tuned_model.get_params(), f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    base_t = base + \"_TUNED\"\n",
        "    preds_val_tuned_path = OUT_PREDS / f\"preds_val_{base_t}.parquet\"\n",
        "    pd.DataFrame({\"proba\": proba_val_tuned, \"y_true\": y_val}).to_parquet(\n",
        "        preds_val_tuned_path, index=False\n",
        "    )\n",
        "\n",
        "    plot_pr_curve(y_val,  proba_val_tuned,  f\"{base_t} — PR (val)\",  OUT_FIGS / f\"{base_t}_pr_val.png\")\n",
        "    plot_pr_curve(y_test, proba_test_tuned, f\"{base_t} — PR (test)\", OUT_FIGS / f\"{base_t}_pr_test.png\")\n",
        "    plot_roc_curve(y_val,  proba_val_tuned,  f\"{base_t} — ROC (val)\",  OUT_FIGS / f\"{base_t}_roc_val.png\")\n",
        "    plot_roc_curve(y_test, proba_test_tuned, f\"{base_t} — ROC (test)\", OUT_FIGS / f\"{base_t}_roc_test.png\")\n",
        "    plot_confusion(y_test, y_pred_test_tuned, f\"{base_t} — Confusion (test @thr={thr_val_tuned:.3f})\", OUT_FIGS / f\"{base_t}_cm_test.png\")\n",
        "\n",
        "    imp_t_path = OUT_RESULTS / f\"{base_t}_feature_importances.csv\"\n",
        "    rf_importances(tuned_model, feature_names_used).sort_values(\"importance_gain\", ascending=False).to_csv(imp_t_path, index=False)\n",
        "    preds_t_path = OUT_PREDS / f\"preds_test_{base_t}.parquet\"\n",
        "    pd.DataFrame({\"proba\": proba_test_tuned, \"y_true\": y_test}).to_parquet(preds_t_path, index=False)\n",
        "\n",
        "    row_t = {\n",
        "        \"model\": base_t,\n",
        "        \"thr_val\": thr_val_tuned,\n",
        "        \"val_pr_auc\": val_metrics_tuned[\"pr_auc\"],\n",
        "        \"val_roc_auc\": val_metrics_tuned[\"roc_auc\"],\n",
        "        \"val_precision\": val_metrics_tuned[\"precision\"],\n",
        "        \"val_f1\": val_metrics_tuned[\"f1\"],\n",
        "        \"val_recall\": val_metrics_tuned[\"recall\"],\n",
        "        \"val_bal_acc\": val_metrics_tuned[\"bal_acc\"],\n",
        "        \"test_pr_auc\": test_metrics_tuned[\"pr_auc\"],\n",
        "        \"test_roc_auc\": test_metrics_tuned[\"roc_auc\"],\n",
        "        \"test_precision\": test_metrics_tuned[\"precision\"],\n",
        "        \"test_f1\": test_metrics_tuned[\"f1\"],\n",
        "        \"test_recall\": test_metrics_tuned[\"recall\"],\n",
        "        \"test_bal_acc\": test_metrics_tuned[\"bal_acc\"],\n",
        "        \"best_iteration\": np.nan\n",
        "    }\n",
        "    pd.DataFrame([row_t]).to_csv(res_csv, mode=\"a\", index=False, header=False)\n",
        "\n",
        "    print(\"[OK][TUNED] Guardados:\",\n",
        "          \"\\n  - Fitted HPs :\", tuned_fitted_path.name,\n",
        "          \"\\n  - Importancias:\", imp_t_path.name,\n",
        "          \"\\n  - Preds test  :\", preds_t_path.name,\n",
        "          \"\\n  - Baselines   :\", res_csv.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "928335ce-rf",
      "metadata": {},
      "source": [
        "10 — Mejores resultados + resumen CV (y comparación SOTA RF de la literatura)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "a837bea0-rf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== MEJORES EN TEST (por métrica) ===\n",
            "- test_pr_auc: RF_FULL_SMOTENC_TUNED | PR-AUC=0.6909 | ROC-AUC=0.8579 | F1=0.6150 | Recall=0.6437 | Precision=0.5888 | thr(val)=0.538 | best_iter=NA\n",
            "- test_roc_auc: RF_FULL_SMOTENC_TUNED | PR-AUC=0.6909 | ROC-AUC=0.8579 | F1=0.6150 | Recall=0.6437 | Precision=0.5888 | thr(val)=0.538 | best_iter=NA\n",
            "- test_recall: RF_FULL_SMOTENC_TUNED | PR-AUC=0.6909 | ROC-AUC=0.8579 | F1=0.6150 | Recall=0.6437 | Precision=0.5888 | thr(val)=0.538 | best_iter=NA\n",
            "- test_f1: RF_FULL_SMOTENC_TUNED | PR-AUC=0.6909 | ROC-AUC=0.8579 | F1=0.6150 | Recall=0.6437 | Precision=0.5888 | thr(val)=0.538 | best_iter=NA\n",
            "- test_precision: RF_FULL_SMOTENC_TUNED | PR-AUC=0.6909 | ROC-AUC=0.8579 | F1=0.6150 | Recall=0.6437 | Precision=0.5888 | thr(val)=0.538 | best_iter=NA\n",
            "=== RESUMEN CV-OOF (por experimento) ===\n",
            "                         tag   pr_auc  roc_auc       f1   recall  bal_acc   thr\n",
            "RF_FULL_SMOTENC_BASELINE_CV5 0.667272 0.846711 0.604311 0.607522  0.75216 0.579\n",
            "   RF_FULL_SMOTENC_TUNED_CV5 0.667272 0.846711 0.604311 0.607522  0.75216 0.579\n",
            "=== COMPARACIÓN SOTA RF vs. MEJOR TEST ===\n",
            "Paper RF: F1=0.8600\n",
            "Tu mejor: F1=0.6150\n",
            "Deltas  : ΔF1=-0.2450\n",
            "Fuente  : Tékouabou et al. (2022) — Mathematics: RF + SMOTE en Kaggle Bank Churn\n",
            "[OK] Normalizado. Backup: baselines_legacy_backup.csv\n"
          ]
        }
      ],
      "source": [
        "AGGREGATE_ALL_RUNS = False\n",
        "\n",
        "def safe(v, fmt=\".4f\"):\n",
        "    try:\n",
        "        return f\"{float(v):{fmt}}\"\n",
        "    except Exception:\n",
        "        return \"NA\"\n",
        "\n",
        "base_csv = OUT_RESULTS / \"baselines.csv\"\n",
        "if not base_csv.exists():\n",
        "    raise FileNotFoundError(f\"No existe {base_csv}\")\n",
        "\n",
        "df = pd.read_csv(base_csv)\n",
        "\n",
        "needed = [\n",
        "    \"model\",\"thr_val\",\n",
        "    \"val_pr_auc\",\"val_roc_auc\",\"val_precision\",\"val_f1\",\"val_recall\",\"val_bal_acc\",\n",
        "    \"test_pr_auc\",\"test_roc_auc\",\"test_precision\",\"test_f1\",\"test_recall\",\"test_bal_acc\",\n",
        "    \"best_iteration\"\n",
        "]\n",
        "for c in needed:\n",
        "    if c not in df.columns:\n",
        "        df[c] = pd.NA\n",
        "\n",
        "df = df[needed].copy()\n",
        "num_cols = [c for c in needed if c not in (\"model\",)]\n",
        "for c in num_cols:\n",
        "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "if AGGREGATE_ALL_RUNS:\n",
        "    root_art = ARTIF_DIR.parent\n",
        "    for p in (root_art).glob(\"RF_*/results/baselines.csv\"):\n",
        "        if p == base_csv:\n",
        "            continue\n",
        "        try:\n",
        "            d2 = pd.read_csv(p)\n",
        "            for c in needed:\n",
        "                if c not in d2.columns:\n",
        "                    d2[c] = pd.NA\n",
        "            d2 = d2[needed]\n",
        "            for c in num_cols:\n",
        "                d2[c] = pd.to_numeric(d2[c], errors=\"coerce\")\n",
        "            df = pd.concat([df, d2], ignore_index=True)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "if df.empty:\n",
        "    raise ValueError(\"El dataframe de resultados está vacío.\")\n",
        "\n",
        "df = df.drop_duplicates(subset=[\"model\"], keep=\"last\").copy()\n",
        "\n",
        "def best_by(metric):\n",
        "    if metric not in df.columns or df[metric].dropna().empty:\n",
        "        return None\n",
        "    r = df.loc[df[metric].idxmax()]\n",
        "    print(\n",
        "        f\"- {metric}: {r['model']} | \"\n",
        "        f\"PR-AUC={safe(r['test_pr_auc'])} | \"\n",
        "        f\"ROC-AUC={safe(r['test_roc_auc'])} | \"\n",
        "        f\"F1={safe(r['test_f1'])} | \"\n",
        "        f\"Recall={safe(r['test_recall'])} | \"\n",
        "        f\"Precision={safe(r['test_precision'])} | \"\n",
        "        f\"thr(val)={safe(r['thr_val'], '.3f')} | \"\n",
        "        f\"best_iter={int(r['best_iteration']) if pd.notna(r['best_iteration']) else 'NA'}\"\n",
        "    )\n",
        "    return r\n",
        "\n",
        "print(\"=== MEJORES EN TEST (por métrica) ===\")\n",
        "winners = {}\n",
        "for m in [\"test_pr_auc\",\"test_roc_auc\",\"test_recall\",\"test_f1\",\"test_precision\"]:\n",
        "    w = best_by(m)\n",
        "    if w is not None:\n",
        "        winners[m] = w\n",
        "\n",
        "cv_files = list(OUT_RESULTS.glob(\"cv_summary_*_CV*.csv\"))\n",
        "if cv_files:\n",
        "    print(\"=== RESUMEN CV-OOF (por experimento) ===\")\n",
        "    rows = []\n",
        "    for f in cv_files:\n",
        "        tag = re.sub(r\"^cv_summary_|\\.csv$\", \"\", f.name)\n",
        "        cv = pd.read_csv(f)\n",
        "        oof = cv.loc[cv[\"fold\"] == \"OOF\"]\n",
        "        if not oof.empty:\n",
        "            r = oof.iloc[0]\n",
        "            rows.append({\n",
        "                \"tag\": tag,\n",
        "                \"pr_auc\": r.get(\"pr_auc\"),\n",
        "                \"roc_auc\": r.get(\"roc_auc\"),\n",
        "                \"f1\": r.get(\"f1\"),\n",
        "                \"recall\": r.get(\"recall\"),\n",
        "                \"bal_acc\": r.get(\"bal_acc\"),\n",
        "                \"thr\": r.get(\"thr\"),\n",
        "            })\n",
        "    if rows:\n",
        "        print(pd.DataFrame(rows).sort_values([\"pr_auc\",\"roc_auc\"], ascending=False).to_string(index=False))\n",
        "else:\n",
        "    print(\"(No se hallaron archivos de CV para este experimento)\")\n",
        "\n",
        "# Comparación rápida con un reporte de RF en la literatura (Tekouabou et al., 2022): F1≈0.86 con RF+SMOTE en Kaggle Bank Churn\n",
        "SOTA_RF = {\n",
        "    \"F1\": 0.86,\n",
        "    \"source\": \"Tékouabou et al. (2022) — Mathematics: RF + SMOTE en Kaggle Bank Churn\"\n",
        "}\n",
        "\n",
        "if \"test_f1\" in winners and winners[\"test_f1\"] is not None:\n",
        "    bt = winners[\"test_f1\"]\n",
        "    d_f1 = float(bt[\"test_f1\"]) - SOTA_RF[\"F1\"]\n",
        "    print(\"=== COMPARACIÓN SOTA RF vs. MEJOR TEST ===\")\n",
        "    print(f\"Paper RF: F1={SOTA_RF['F1']:.4f}\")\n",
        "    print(f\"Tu mejor: F1={safe(bt['test_f1'])}\")\n",
        "    print(f\"Deltas  : ΔF1={d_f1:+.4f}\")\n",
        "    print(f\"Fuente  : {SOTA_RF['source']}\")\n",
        "else:\n",
        "    print(\"No se pudo localizar el ganador por F1 para comparar contra SOTA RF.\")\n",
        "\n",
        "backup = OUT_RESULTS / \"baselines_legacy_backup.csv\"\n",
        "base_csv.replace(backup)\n",
        "df.to_csv(base_csv, index=False)\n",
        "print(\"[OK] Normalizado. Backup:\", backup.name)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
