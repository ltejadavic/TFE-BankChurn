{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2aec4297-rf",
      "metadata": {},
      "source": [
        "1 — Imports, configuración y rutas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "565a4b55-rf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exp: RF_REDUCED_SMOTENC\n",
            "DATA_DIR: /Users/luistejada/Downloads/TFE Churn Bancario/preproc_datasets/full\n",
            "ARTIF_DIR: /Users/luistejada/Downloads/TFE Churn Bancario/artifacts/RF_REDUCED_SMOTENC\n"
          ]
        }
      ],
      "source": [
        "import json, os, warnings, time, re, glob\n",
        "from pathlib import Path\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    average_precision_score, precision_recall_curve, roc_auc_score, roc_curve,\n",
        "    f1_score, recall_score, balanced_accuracy_score, confusion_matrix, precision_score\n",
        ")\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Balanceo (SMOTENC)\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTENC\n",
        "    _HAS_IMBLEARN = True\n",
        "except Exception:\n",
        "    _HAS_IMBLEARN = False\n",
        "\n",
        "# === Toggles de experimento ===\n",
        "USE_REDUCED = True                 \n",
        "SELECTION_MODE = \"L1\"              \n",
        "USE_BALANCED_TRAIN = True          \n",
        "BALANCE_IN_CV = True               \n",
        "RANDOM_STATE = 42\n",
        "DO_TUNE = True\n",
        "DO_CV_BASELINE = True\n",
        "DO_CV_TUNED = True\n",
        "CV_FOLDS = 5\n",
        "\n",
        "# Para MI\n",
        "MI_TOPK = 30\n",
        "\n",
        "# Hiperparámetros L1 \n",
        "L1_C_GRID  = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10]\n",
        "L1_KFOLDS  = 5\n",
        "L1_P_KEEP  = 0.8               \n",
        "L1_GROUP_COHERENCE = False     \n",
        "\n",
        "# Calcular máscara L1\n",
        "FORCE_REFIT_L1 = True\n",
        "\n",
        "# === Nombres y rutas ===\n",
        "ROOT = Path.cwd().parent\n",
        "EXP_NAME = f\"RF_{'REDUCED' if (USE_REDUCED and SELECTION_MODE!='NONE') else 'FULL'}_{'SMOTENC' if USE_BALANCED_TRAIN else 'IMB'}\"\n",
        "ARTIF_DIR = ROOT / \"artifacts\" / EXP_NAME\n",
        "OUT_RESULTS = ARTIF_DIR / \"results\"\n",
        "OUT_FIGS    = ARTIF_DIR / \"figs\"\n",
        "OUT_PREDS   = ARTIF_DIR / \"preds\"\n",
        "OUT_PARAMS  = ARTIF_DIR / \"best_params\"\n",
        "for p in [OUT_RESULTS, OUT_FIGS, OUT_PREDS, OUT_PARAMS]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Carpeta para artefactos de selección de features\n",
        "SEL_DIR = OUT_PARAMS / \"feature_selection\"\n",
        "SEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Dataset preprocesado\n",
        "DATA_DIR = ROOT / \"preproc_datasets\" / \"full\"\n",
        "\n",
        "print(\"Exp:\", EXP_NAME)\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n",
        "print(\"ARTIF_DIR:\", ARTIF_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cd89f52-rf",
      "metadata": {},
      "source": [
        "2 — Carga de artefactos (X, y, features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "38f0a43f-rf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes: (6000, 15) (2000, 15) (2000, 15)\n",
            "y train/val/test: (6000,) (2000,) (2000,)\n",
            "n features: 15\n"
          ]
        }
      ],
      "source": [
        "def load_xy_full(dir_full: Path):\n",
        "    X_train = np.load(dir_full / \"X_train_full.npy\")\n",
        "    X_val   = np.load(dir_full / \"X_val_full.npy\")\n",
        "    X_test  = np.load(dir_full / \"X_test_full.npy\")\n",
        "\n",
        "    y_train = pd.read_parquet(dir_full / \"y_train.parquet\")[\"Exited\"].to_numpy()\n",
        "    y_val   = pd.read_parquet(dir_full / \"y_val.parquet\")[\"Exited\"].to_numpy()\n",
        "    y_test  = pd.read_parquet(dir_full / \"y_test.parquet\")[\"Exited\"].to_numpy()\n",
        "\n",
        "    feat = pd.read_parquet(dir_full / \"feature_names_full.parquet\")[\"feature\"].tolist()\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test, feat\n",
        "\n",
        "X_train, y_train, X_val, y_val, X_test, y_test, feature_names = load_xy_full(DATA_DIR)\n",
        "print(\"Shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
        "print(\"y train/val/test:\", y_train.shape, y_val.shape, y_test.shape)\n",
        "print(\"n features:\", len(feature_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e693828-rf",
      "metadata": {},
      "source": [
        "3 — Métricas, threshold y utilidades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "650b59ba-rf",
      "metadata": {},
      "outputs": [],
      "source": [
        "def pr_auc(y_true, y_proba): \n",
        "    return float(average_precision_score(y_true, y_proba))\n",
        "\n",
        "def roc_auc(y_true, y_proba): \n",
        "    return float(roc_auc_score(y_true, y_proba))\n",
        "\n",
        "def find_best_threshold(y_true, y_proba, metric=\"f1\"):\n",
        "    thr_grid = np.linspace(0.0, 1.0, 1001)\n",
        "    best_thr, best_score = 0.5, -1.0\n",
        "    for thr in thr_grid:\n",
        "        y_pred = (y_proba >= thr).astype(int)\n",
        "        if metric == \"f1\":\n",
        "            score = f1_score(y_true, y_pred, zero_division=0)\n",
        "        elif metric == \"recall\":\n",
        "            score = recall_score(y_true, y_pred, zero_division=0)\n",
        "        else:\n",
        "            raise ValueError(\"metric no soportada\")\n",
        "        if score > best_score:\n",
        "            best_score, best_thr = score, thr\n",
        "    return float(best_thr), float(best_score)\n",
        "\n",
        "def compute_all_metrics(y_true, y_proba, thr):\n",
        "    y_pred = (y_proba >= thr).astype(int)\n",
        "    return {\n",
        "        \"pr_auc\": pr_auc(y_true, y_proba),\n",
        "        \"roc_auc\": roc_auc(y_true, y_proba),\n",
        "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
        "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
        "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
        "        \"bal_acc\": balanced_accuracy_score(y_true, y_pred)\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7943526-rf",
      "metadata": {},
      "source": [
        "4 — Helpers: MI Top-K (opcional) y balanceo SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "95ecc2fa-rf",
      "metadata": {},
      "outputs": [],
      "source": [
        "def assert_X_names_aligned(X, names, context=\"\"):\n",
        "    if X.shape[1] != len(names):\n",
        "        raise ValueError(\n",
        "            f\"[{context}] Desalineado: X.shape[1]={X.shape[1]} vs len(feature_names)={len(names)}. \"\n",
        "            f\"Asegura pasar los nombres que correspondan a las columnas actuales de X.\"\n",
        "        )\n",
        "\n",
        "def apply_keep_idx(X, keep_idx):\n",
        "    return X[:, np.array(keep_idx, dtype=int)]\n",
        "\n",
        "def _group_from_name(feat_name: str) -> str:\n",
        "    if feat_name.startswith(\"num__\"):\n",
        "        return feat_name\n",
        "    if \"_\" in feat_name:\n",
        "        return feat_name.rsplit(\"_\", 1)[0]\n",
        "    return feat_name\n",
        "\n",
        "def _groups_indices(feature_names):\n",
        "    groups = {}\n",
        "    for i, f in enumerate(feature_names):\n",
        "        g = _group_from_name(f)\n",
        "        groups.setdefault(g, []).append(i)\n",
        "    return groups\n",
        "\n",
        "def fit_mi_selector(X, y, topk=MI_TOPK, seed=42):\n",
        "    mi = mutual_info_classif(X, y, random_state=seed)\n",
        "    idx = np.argsort(mi)[::-1][:int(topk)]\n",
        "    report = pd.DataFrame({\"feature\": feature_names, \"mi\": mi}).sort_values(\"mi\", ascending=False)\n",
        "    folds_log = pd.DataFrame({\"note\": [\"MI_topk\"], \"topk\": [int(topk)]})\n",
        "    return sorted(idx.tolist()), report, folds_log\n",
        "\n",
        "def fit_l1_selector(\n",
        "    X, y, feature_names, C_grid=L1_C_GRID, kfolds=L1_KFOLDS,\n",
        "    p_keep=L1_P_KEEP, group_coherence=L1_GROUP_COHERENCE, seed=42\n",
        "):\n",
        "    assert_X_names_aligned(X, feature_names, context=\"fit_l1_selector(INPUT)\")\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=kfolds, shuffle=True, random_state=seed)\n",
        "    n = X.shape[1]\n",
        "    select_counts = np.zeros(n, dtype=int)\n",
        "    rows = []\n",
        "\n",
        "    for f, (tr_idx, va_idx) in enumerate(kf.split(X, y), 1):\n",
        "        X_tr, X_va = X[tr_idx], X[va_idx]\n",
        "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "\n",
        "        best_c, best_ap, best_coef = None, -1.0, None\n",
        "        for C in C_grid:\n",
        "            mdl = LogisticRegression(\n",
        "                penalty=\"l1\", solver=\"liblinear\", class_weight=\"balanced\",\n",
        "                max_iter=5000, C=C, random_state=seed\n",
        "            )\n",
        "            mdl.fit(X_tr, y_tr)\n",
        "            proba = mdl.predict_proba(X_va)[:, 1]\n",
        "            ap = average_precision_score(y_va, proba)\n",
        "            if ap > best_ap:\n",
        "                best_ap, best_c, best_coef = ap, C, mdl.coef_.ravel()\n",
        "\n",
        "        mask = (np.abs(best_coef) > 1e-12)\n",
        "        select_counts += mask.astype(int)\n",
        "        rows.append({\"fold\": f, \"best_C\": best_c, \"ap_val\": best_ap, \"n_selected\": int(mask.sum())})\n",
        "\n",
        "    thr = int(np.ceil(kfolds * p_keep))\n",
        "    keep_idx = np.where(select_counts >= thr)[0].tolist()\n",
        "\n",
        "    if group_coherence and keep_idx:\n",
        "        groups = _groups_indices(feature_names)\n",
        "        keep_set = set(keep_idx)\n",
        "        for g, idxs in groups.items():\n",
        "            if keep_set.intersection(idxs):\n",
        "                keep_set.update(idxs)\n",
        "        keep_idx = sorted(list(keep_set))\n",
        "\n",
        "    if len(keep_idx) == 0:\n",
        "        N = max(1, min(10, max(1, n // 3)))\n",
        "        order = np.argsort(select_counts)[::-1]\n",
        "        prelim = order[:N].tolist()\n",
        "        if select_counts[prelim[0]] == 0:\n",
        "            try:\n",
        "                mi = mutual_info_classif(X, y, random_state=seed)\n",
        "                prelim = np.argsort(mi)[::-1][:N].tolist()\n",
        "            except Exception:\n",
        "                prelim = list(range(N))\n",
        "        keep_idx = sorted(prelim)\n",
        "        if group_coherence and keep_idx:\n",
        "            groups = _groups_indices(feature_names)\n",
        "            keep_set = set(keep_idx)\n",
        "            for g, idxs in groups.items():\n",
        "                if keep_set.intersection(idxs):\n",
        "                    keep_set.update(idxs)\n",
        "            keep_idx = sorted(list(keep_set))\n",
        "\n",
        "    report = pd.DataFrame({\n",
        "        \"feature\": feature_names,\n",
        "        \"selected_in_folds\": select_counts,\n",
        "        \"p_keep\": select_counts / kfolds\n",
        "    }).sort_values([\"p_keep\",\"feature\"], ascending=[False, True])\n",
        "\n",
        "    folds_log = pd.DataFrame(rows)\n",
        "    return keep_idx, report, folds_log\n",
        "\n",
        "def save_selection_artifacts(mode_tag: str, keep_idx: list, feature_names: list, report_df: pd.DataFrame, folds_df: pd.DataFrame):\n",
        "    np.save(SEL_DIR / f\"keep_idx_{mode_tag}.npy\", np.array(keep_idx, dtype=int))\n",
        "    pd.DataFrame({\"feature\": [feature_names[i] for i in keep_idx]}).to_csv(SEL_DIR / f\"kept_features_{mode_tag}.csv\", index=False)\n",
        "    report_df.to_csv(SEL_DIR / f\"{mode_tag}_report_features.csv\", index=False)\n",
        "    folds_df.to_csv(SEL_DIR / f\"{mode_tag}_cv_log.csv\", index=False)\n",
        "\n",
        "def load_keep_idx_if_exists(mode_tag: str):\n",
        "    path = SEL_DIR / f\"keep_idx_{mode_tag}.npy\"\n",
        "    return np.load(path) if path.exists() else None\n",
        "\n",
        "\n",
        "def _try_load_cat_idx_from_metadata(dir_full: Path, feature_names_in: list):\n",
        "\n",
        "    # .npy por índices\n",
        "    for name in [\"categorical_indices_full.npy\", \"cat_idx_full.npy\", \"categorical_indices.npy\"]:\n",
        "        p = dir_full / name\n",
        "        if p.exists():\n",
        "            arr = np.load(p)\n",
        "            return sorted([int(i) for i in arr.tolist()])\n",
        "\n",
        "    # .npy por máscara\n",
        "    for name in [\"categorical_mask_full.npy\", \"categorical_mask.npy\"]:\n",
        "        p = dir_full / name\n",
        "        if p.exists():\n",
        "            m = np.load(p).astype(bool).tolist()\n",
        "            if len(m) == len(feature_names_in):\n",
        "                return [i for i, b in enumerate(m) if b]\n",
        "    \n",
        "    # parquet con tipos\n",
        "    for name in [\"feature_types_full.parquet\", \"feature_types.parquet\"]:\n",
        "        p = dir_full / name\n",
        "        if p.exists():\n",
        "            df = pd.read_parquet(p)\n",
        "            cols = [c.lower() for c in df.columns]\n",
        "            if \"feature\" in df.columns and (\"is_categorical\" in df.columns or \"type\" in df.columns):\n",
        "                if \"is_categorical\" in df.columns:\n",
        "                    cat_names = set(df.loc[df[\"is_categorical\"]==True, \"feature\"].tolist())\n",
        "                else:\n",
        "                    cat_names = set(df.loc[df[\"type\"].astype(str).str.lower().str.contains(\"cat\"), \"feature\"].tolist())\n",
        "                return sorted([i for i, f in enumerate(feature_names_in) if f in cat_names])\n",
        "\n",
        "    # json\n",
        "    for name in [\"preproc_meta.json\", \"metadata.json\", \"meta_preproc.json\"]:\n",
        "        p = dir_full / name\n",
        "        if p.exists():\n",
        "            try:\n",
        "                meta = json.loads(p.read_text())\n",
        "                if \"categorical_indices\" in meta:\n",
        "                    return sorted([int(i) for i in meta[\"categorical_indices\"]])\n",
        "                if \"categorical_features\" in meta:\n",
        "                    cat_names = set(meta[\"categorical_features\"])\n",
        "                    return sorted([i for i, f in enumerate(feature_names_in) if f in cat_names])\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    return None\n",
        "\n",
        "def get_categorical_indices(feature_names_in: list, prefer_metadata: bool = True):\n",
        "    if prefer_metadata:\n",
        "        try:\n",
        "            idx = _try_load_cat_idx_from_metadata(DATA_DIR, feature_names_in)\n",
        "            if idx is not None:\n",
        "                return idx\n",
        "        except Exception:\n",
        "            pass\n",
        "    # Fallback por nombres (convención: 'num__' -> numérica; resto -> categórica/OHE)\n",
        "    return [i for i, f in enumerate(feature_names_in) if not str(f).startswith(\"num__\")]\n",
        "\n",
        "def maybe_smote(X, y, feature_names_in: list, debug: bool = False):\n",
        "    if not _HAS_IMBLEARN:\n",
        "        if debug:\n",
        "            print(\"[SMOTENC] imblearn no disponible; se omite balanceo.\")\n",
        "        return X, y\n",
        "\n",
        "    cat_idx = get_categorical_indices(feature_names_in, prefer_metadata=True)\n",
        "    if len(cat_idx) == 0:\n",
        "        if debug:\n",
        "            print(\"[SMOTENC] No se encontraron categóricas; fallback a SMOTE.\")\n",
        "        try:\n",
        "            from imblearn.over_sampling import SMOTE\n",
        "            binc = np.bincount(y.astype(int))\n",
        "            mn = int(binc.min()) if len(binc) > 1 else 1\n",
        "            k = max(1, min(5, mn - 1))\n",
        "            return SMOTE(random_state=RANDOM_STATE, k_neighbors=k).fit_resample(X, y)\n",
        "        except Exception as e:\n",
        "            if debug:\n",
        "                print(\"[SMOTE] Fallback falló:\", e)\n",
        "            return X, y\n",
        "\n",
        "    binc = np.bincount(y.astype(int))\n",
        "    mn = int(binc.min()) if len(binc) > 1 else 1\n",
        "    k = max(1, min(5, mn - 1))\n",
        "\n",
        "    if debug:\n",
        "        print(f\"[SMOTENC] Categóricas detectadas: {len(cat_idx)} | k_neighbors={k}\")\n",
        "\n",
        "    sm = SMOTENC(\n",
        "        categorical_features=cat_idx,\n",
        "        random_state=RANDOM_STATE,\n",
        "        k_neighbors=k\n",
        "    )\n",
        "    try:\n",
        "        return sm.fit_resample(X, y)\n",
        "    except Exception as e:\n",
        "        if debug:\n",
        "            print(\"[SMOTENC] Aviso: no se pudo aplicar SMOTENC ->\", e)\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d86df8a-rf",
      "metadata": {},
      "source": [
        "5 — Hiperparámetros persistentes (seed/best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "32cca868-rf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[HP] Cargando mejores hiperparámetros previos: BEST_RF_REDUCED_SMOTENC.json\n"
          ]
        }
      ],
      "source": [
        "VIEW_TAG = \"REDUCED\" if USE_REDUCED else \"FULL\"\n",
        "BAL_TAG  = \"SMOTENC\" if USE_BALANCED_TRAIN else \"IMB\"\n",
        "BEST_HP_FILE = OUT_PARAMS / f\"BEST_RF_{VIEW_TAG}_{BAL_TAG}.json\"\n",
        "\n",
        "def get_rf_defaults(seed=RANDOM_STATE):\n",
        "    mdl = RandomForestClassifier(\n",
        "        random_state=seed,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "    params = mdl.get_params()\n",
        "    return params\n",
        "\n",
        "def load_best_or_default():\n",
        "    if BEST_HP_FILE.exists():\n",
        "        try:\n",
        "            best = json.loads(BEST_HP_FILE.read_text())\n",
        "            print(\"[HP] Cargando mejores hiperparámetros previos:\", BEST_HP_FILE.name)\n",
        "            base = get_rf_defaults()\n",
        "            base.update(best)\n",
        "            return base, True\n",
        "        except Exception as e:\n",
        "            print(\"[HP] Aviso: no se pudo leer BEST (uso defaults).\", e)\n",
        "    print(\"[HP] Usando hiperparámetros DEFAULT de RF.\")\n",
        "    return get_rf_defaults(), False\n",
        "\n",
        "seed_params, loaded_best_flag = load_best_or_default()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfed62da-rf",
      "metadata": {},
      "source": [
        "6 — Entrenamiento BASELINE + umbral (val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ea25cb27-rf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SELECCIÓN L1] Kept=12 | Dropped=3\n",
            "[Kept]: ['num__CreditScore', 'num__Age', 'num__Tenure', 'num__Balance', 'num__EstimatedSalary', 'Geography_1', 'Gender_1', 'HasCrCard_1', 'IsActiveMember_1', 'NumOfProducts_1', 'NumOfProducts_2', 'NumOfProducts_3']\n",
            "[Dropped]: ['Geography_0', 'Geography_2', 'NumOfProducts_0']\n",
            "\n",
            "[SELECCIÓN L1] Top por p_keep:\n",
            "             feature  selected_in_folds  p_keep\n",
            "            Gender_1                  5     1.0\n",
            "         Geography_1                  5     1.0\n",
            "         HasCrCard_1                  5     1.0\n",
            "    IsActiveMember_1                  5     1.0\n",
            "     NumOfProducts_1                  5     1.0\n",
            "     NumOfProducts_2                  5     1.0\n",
            "     NumOfProducts_3                  5     1.0\n",
            "            num__Age                  5     1.0\n",
            "        num__Balance                  5     1.0\n",
            "    num__CreditScore                  5     1.0\n",
            "num__EstimatedSalary                  5     1.0\n",
            "         num__Tenure                  5     1.0\n",
            "         Geography_2                  3     0.6\n",
            "         Geography_0                  2     0.4\n",
            "     NumOfProducts_0                  0     0.0\n",
            "[SMOTENC] Categóricas detectadas: 7 | k_neighbors=5\n",
            "[BASELINE] Mejor umbral (val) por F1: 0.537 | F1(val)=0.6092\n",
            "[BASELINE] Métricas val: {'pr_auc': 0.651, 'roc_auc': 0.8523, 'precision': 0.5864, 'f1': 0.6092, 'recall': 0.6339, 'bal_acc': 0.7598}\n",
            "[DEBUG] X_train shape: (6000, 15)\n",
            "\n",
            "num__CreditScore: numérica (nunique=417)\n",
            "count    6000.000\n",
            "mean       -0.005\n",
            "std         0.723\n",
            "min        -1.654\n",
            "5%         -1.226\n",
            "25%        -0.511\n",
            "50%         0.000\n",
            "75%         0.489\n",
            "95%         1.203\n",
            "max         1.489\n",
            "\n",
            "num__Age: numérica (nunique=52)\n",
            "count    6000.000\n",
            "mean        0.161\n",
            "std         0.858\n",
            "min        -1.333\n",
            "5%         -1.000\n",
            "25%        -0.417\n",
            "50%         0.000\n",
            "75%         0.583\n",
            "95%         1.917\n",
            "max         2.917\n",
            "\n",
            "num__Tenure: numérica (nunique=11)\n",
            "count    6000.000\n",
            "mean        0.006\n",
            "std         0.582\n",
            "min        -1.000\n",
            "5%         -0.800\n",
            "25%        -0.400\n",
            "50%         0.000\n",
            "75%         0.600\n",
            "95%         0.800\n",
            "max         1.000\n",
            "\n",
            "num__Balance: numérica (nunique=3809)\n",
            "count    6000.000\n",
            "mean       -0.161\n",
            "std         0.484\n",
            "min        -0.762\n",
            "5%         -0.762\n",
            "25%        -0.762\n",
            "50%         0.000\n",
            "75%         0.238\n",
            "95%         0.506\n",
            "max         0.687\n",
            "\n",
            "num__EstimatedSalary: numérica (nunique=5882)\n",
            "count    6000.000\n",
            "mean        0.004\n",
            "std         0.589\n",
            "min        -0.999\n",
            "5%         -0.921\n",
            "25%        -0.498\n",
            "50%         0.000\n",
            "75%         0.502\n",
            "95%         0.934\n",
            "max         1.018\n",
            "\n",
            "Geography_0: binaria/low-card (nunique=2)\n",
            "Geography_0\n",
            "0.0    3020\n",
            "1.0    2980\n",
            "  -> tasa de Exited cuando Geography_0=1: 0.1634\n",
            "\n",
            "Geography_1: binaria/low-card (nunique=2)\n",
            "Geography_1\n",
            "0.0    4496\n",
            "1.0    1504\n",
            "  -> tasa de Exited cuando Geography_1=1: 0.3251\n",
            "\n",
            "Geography_2: binaria/low-card (nunique=2)\n",
            "Geography_2\n",
            "0.0    4484\n",
            "1.0    1516\n",
            "  -> tasa de Exited cuando Geography_2=1: 0.1629\n",
            "\n",
            "Gender_1: binaria/low-card (nunique=2)\n",
            "Gender_1\n",
            "0.0    2724\n",
            "1.0    3276\n",
            "  -> tasa de Exited cuando Gender_1=1: 0.1618\n",
            "\n",
            "HasCrCard_1: binaria/low-card (nunique=2)\n",
            "HasCrCard_1\n",
            "0.0    1742\n",
            "1.0    4258\n",
            "  -> tasa de Exited cuando HasCrCard_1=1: 0.1984\n",
            "\n",
            "IsActiveMember_1: binaria/low-card (nunique=2)\n",
            "IsActiveMember_1\n",
            "0.0    2907\n",
            "1.0    3093\n",
            "  -> tasa de Exited cuando IsActiveMember_1=1: 0.1416\n",
            "\n",
            "NumOfProducts_0: binaria/low-card (nunique=2)\n",
            "NumOfProducts_0\n",
            "0.0    2963\n",
            "1.0    3037\n",
            "  -> tasa de Exited cuando NumOfProducts_0=1: 0.2786\n",
            "\n",
            "NumOfProducts_1: binaria/low-card (nunique=2)\n",
            "NumOfProducts_1\n",
            "0.0    3238\n",
            "1.0    2762\n",
            "  -> tasa de Exited cuando NumOfProducts_1=1: 0.0731\n",
            "\n",
            "NumOfProducts_2: binaria/low-card (nunique=2)\n",
            "NumOfProducts_2\n",
            "0.0    5838\n",
            "1.0     162\n",
            "  -> tasa de Exited cuando NumOfProducts_2=1: 0.8395\n",
            "\n",
            "NumOfProducts_3: binaria/low-card (nunique=2)\n",
            "NumOfProducts_3\n",
            "0.0    5961\n",
            "1.0      39\n",
            "  -> tasa de Exited cuando NumOfProducts_3=1: 1.0000\n"
          ]
        }
      ],
      "source": [
        "keep_idx_global = None\n",
        "feature_names_used = feature_names\n",
        "X_train_fit, X_val_fit, X_test_fit = X_train, X_val, X_test\n",
        "\n",
        "if USE_REDUCED and SELECTION_MODE != \"NONE\":\n",
        "    if SELECTION_MODE == \"MI\":\n",
        "        keep_idx_global, mi_report, mi_folds = fit_mi_selector(X_train, y_train, topk=MI_TOPK, seed=RANDOM_STATE)\n",
        "        mode_tag = f\"MI_top{MI_TOPK}\"\n",
        "        save_selection_artifacts(mode_tag, keep_idx_global, feature_names, mi_report, mi_folds)\n",
        "    elif SELECTION_MODE == \"L1\":\n",
        "        mode_tag = \"L1\"\n",
        "        prev = None if FORCE_REFIT_L1 else load_keep_idx_if_exists(mode_tag)\n",
        "        if prev is not None and prev.size > 0:\n",
        "            keep_idx_global = prev.astype(int).tolist()\n",
        "            l1_report = pd.DataFrame({\"note\":[\"loaded_existing_mask\"]})\n",
        "            l1_folds  = pd.DataFrame({\"note\":[\"loaded_existing_mask\"]})\n",
        "        else:\n",
        "            keep_idx_global, l1_report, l1_folds = fit_l1_selector(\n",
        "                X_train, y_train, feature_names, seed=RANDOM_STATE\n",
        "            )\n",
        "            save_selection_artifacts(mode_tag, keep_idx_global, feature_names, l1_report, l1_folds)\n",
        "        kept_tmp = [feature_names[i] for i in keep_idx_global]\n",
        "        dropped_tmp = [feature_names[i] for i in sorted(set(range(len(feature_names))) - set(keep_idx_global))]\n",
        "        print(f\"[SELECCIÓN {SELECTION_MODE}] Kept={len(kept_tmp)} | Dropped={len(dropped_tmp)}\")\n",
        "        print(\"[Kept]:\", kept_tmp)\n",
        "        print(\"[Dropped]:\", dropped_tmp)\n",
        "        try:\n",
        "            print(\"\\n[SELECCIÓN L1] Top por p_keep:\")\n",
        "            print(l1_report.sort_values(\"p_keep\", ascending=False).head(15).to_string(index=False))\n",
        "        except Exception:\n",
        "            pass\n",
        "    else:\n",
        "        raise ValueError(\"SELECTION_MODE inválido\")\n",
        "\n",
        "    X_train_fit = apply_keep_idx(X_train, keep_idx_global)\n",
        "    X_val_fit   = apply_keep_idx(X_val,   keep_idx_global)\n",
        "    X_test_fit  = apply_keep_idx(X_test,  keep_idx_global)\n",
        "    feature_names_used = [feature_names[i] for i in keep_idx_global]\n",
        "\n",
        "# Checks de alineación\n",
        "assert_X_names_aligned(X_train_fit, feature_names_used, \"BASELINE(train)\")\n",
        "assert_X_names_aligned(X_val_fit,   feature_names_used, \"BASELINE(val)\")\n",
        "assert_X_names_aligned(X_test_fit,  feature_names_used, \"BASELINE(test)\")\n",
        "\n",
        "# --- Balanceo con SMOTENC ---\n",
        "X_train_final, y_train_final = X_train_fit, y_train\n",
        "if USE_BALANCED_TRAIN:\n",
        "    X_train_final, y_train_final = maybe_smote(X_train_fit, y_train, feature_names_used, debug=True)\n",
        "\n",
        "# --- Entrenamiento RF baseline ---\n",
        "base_params = dict(seed_params)\n",
        "base_params.setdefault(\"random_state\", RANDOM_STATE)\n",
        "base_params.setdefault(\"n_jobs\", -1)\n",
        "if base_params.get(\"n_estimators\") is None:\n",
        "    base_params[\"n_estimators\"] = 1000\n",
        "\n",
        "model = RandomForestClassifier(**base_params)\n",
        "model.fit(X_train_final, y_train_final)\n",
        "\n",
        "# --- Umbral óptimo por F1 en val ---\n",
        "proba_val = model.predict_proba(X_val_fit)[:, 1]\n",
        "thr_val, best_f1_val = find_best_threshold(y_val, proba_val, metric=\"f1\")\n",
        "print(f\"[BASELINE] Mejor umbral (val) por F1: {thr_val:.3f} | F1(val)={best_f1_val:.4f}\")\n",
        "\n",
        "val_metrics = compute_all_metrics(y_val, proba_val, thr_val)\n",
        "print(\"[BASELINE] Métricas val:\", {k: (round(v,4) if isinstance(v,float) else v) for k,v in val_metrics.items()})\n",
        "\n",
        "# DEBUG — Resumen simple\n",
        "df_tr = pd.DataFrame(X_train, columns=feature_names)\n",
        "y_ser = pd.Series(y_train, name=\"Exited\")\n",
        "print(f\"[DEBUG] X_train shape: {df_tr.shape}\")\n",
        "for col in df_tr.columns:\n",
        "    vc = df_tr[col].nunique()\n",
        "    if vc <= 3 or set(np.unique(df_tr[col])).issubset({0,1}):\n",
        "        counts = df_tr[col].value_counts(dropna=False).sort_index()\n",
        "        pos_rate = y_ser[df_tr[col] == 1].mean() if 1 in df_tr[col].unique() else np.nan\n",
        "        print(f\"\\n{col}: binaria/low-card (nunique={vc})\")\n",
        "        print(counts.to_string())\n",
        "        print(f\"  -> tasa de Exited cuando {col}=1: {pos_rate:.4f}\" if not np.isnan(pos_rate) else \"  -> sin 1s\")\n",
        "    else:\n",
        "        print(f\"\\n{col}: numérica (nunique={vc})\")\n",
        "        desc = df_tr[col].describe(percentiles=[.05,.25,.5,.75,.95]).round(3)\n",
        "        print(desc.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94d893d5-rf",
      "metadata": {},
      "source": [
        "7 — Optimización incremental (Optuna, objetivo = AP/PR-AUC en val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "03c63f35-rf",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-12 23:30:26,548] A new study created in memory with name: RF_REDUCED_SMOTENC_AP\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OPTUNA] Enqueuing previous BEST as a trial seed.\n",
            "[OPTUNA] Iniciando estudio 'RF_REDUCED_SMOTENC_AP' con 40 pruebas...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-12 23:30:28,023] Trial 0 finished with value: 0.6510031693454986 and parameters: {'n_estimators': 700, 'use_max_depth': False, 'min_samples_split': 24, 'min_samples_leaf': 1, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None, 'max_samples': 0.8480205218347934}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[I 2025-12-12 23:30:35,168] Trial 1 finished with value: 0.6331847710671494 and parameters: {'n_estimators': 1800, 'use_max_depth': False, 'min_samples_split': 3, 'min_samples_leaf': 25, 'max_features_mode': 'cat', 'max_features_cat': None, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced', 'max_samples': 0.728034992108518}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[I 2025-12-12 23:30:40,886] Trial 2 finished with value: 0.6389353456072674 and parameters: {'n_estimators': 1650, 'use_max_depth': False, 'min_samples_split': 31, 'min_samples_leaf': 2, 'max_features_mode': 'cat', 'max_features_cat': None, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced', 'max_samples': 0.5171942605576092}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[I 2025-12-12 23:30:43,843] Trial 3 finished with value: 0.6344972679247638 and parameters: {'n_estimators': 1850, 'use_max_depth': False, 'min_samples_split': 17, 'min_samples_leaf': 14, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': True, 'criterion': 'gini', 'class_weight': 'balanced', 'max_samples': 0.6943386448447411}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[I 2025-12-12 23:30:45,952] Trial 4 finished with value: 0.64058882133237 and parameters: {'n_estimators': 700, 'use_max_depth': True, 'max_depth': 10, 'min_samples_split': 28, 'min_samples_leaf': 4, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': False, 'criterion': 'log_loss', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[I 2025-12-12 23:30:47,249] Trial 5 finished with value: 0.6385672317061487 and parameters: {'n_estimators': 400, 'use_max_depth': True, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 8, 'max_features_mode': 'frac', 'max_features_frac': 0.7462902299486491, 'bootstrap': True, 'criterion': 'log_loss', 'class_weight': 'balanced', 'max_samples': 0.7468977981821954}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[I 2025-12-12 23:30:51,964] Trial 6 finished with value: 0.6047491978974119 and parameters: {'n_estimators': 1150, 'use_max_depth': True, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 16, 'max_features_mode': 'frac', 'max_features_frac': 0.9352965317482651, 'bootstrap': False, 'criterion': 'gini', 'class_weight': None}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[I 2025-12-12 23:30:57,056] Trial 7 finished with value: 0.6427383733018752 and parameters: {'n_estimators': 1900, 'use_max_depth': True, 'max_depth': 27, 'min_samples_split': 41, 'min_samples_leaf': 5, 'max_features_mode': 'cat', 'max_features_cat': 'log2', 'bootstrap': False, 'criterion': 'log_loss', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[I 2025-12-12 23:30:59,341] Trial 8 finished with value: 0.6430850980652685 and parameters: {'n_estimators': 950, 'use_max_depth': True, 'max_depth': 12, 'min_samples_split': 48, 'min_samples_leaf': 9, 'max_features_mode': 'frac', 'max_features_frac': 0.5545407216655058, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None, 'max_samples': 0.8047821669899484}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[I 2025-12-12 23:31:06,944] Trial 9 finished with value: 0.5845546904358287 and parameters: {'n_estimators': 1100, 'use_max_depth': False, 'min_samples_split': 46, 'min_samples_leaf': 6, 'max_features_mode': 'frac', 'max_features_frac': 0.9899553178774205, 'bootstrap': False, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:06,948] The parameter `max_features_cat` in Trial#10 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:06,949] The parameter `max_samples` in Trial#10 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:07,944] Trial 10 finished with value: 0.6458529505934731 and parameters: {'n_estimators': 500, 'use_max_depth': False, 'min_samples_split': 42, 'min_samples_leaf': 3, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None, 'max_samples': 0.9881409036417592}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:07,947] The parameter `max_features_cat` in Trial#11 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:07,947] The parameter `max_samples` in Trial#11 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:08,365] Trial 11 finished with value: 0.6509265735105563 and parameters: {'n_estimators': 200, 'use_max_depth': False, 'min_samples_split': 37, 'min_samples_leaf': 3, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None, 'max_samples': 0.9866499223732758}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:08,368] The parameter `max_features_cat` in Trial#12 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:08,368] The parameter `max_samples` in Trial#12 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:08,747] Trial 12 finished with value: 0.6345640226167774 and parameters: {'n_estimators': 200, 'use_max_depth': False, 'min_samples_split': 11, 'min_samples_leaf': 2, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': True, 'criterion': 'gini', 'class_weight': None, 'max_samples': 0.9157260452872891}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:08,749] The parameter `max_features_cat` in Trial#13 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:08,750] The parameter `max_samples` in Trial#13 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:10,699] Trial 13 finished with value: 0.6466366963745694 and parameters: {'n_estimators': 1000, 'use_max_depth': False, 'min_samples_split': 21, 'min_samples_leaf': 4, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None, 'max_samples': 0.8843449380234663}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:10,702] The parameter `max_features_cat` in Trial#14 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:11,961] Trial 14 finished with value: 0.6444709874859185 and parameters: {'n_estimators': 450, 'use_max_depth': False, 'min_samples_split': 24, 'min_samples_leaf': 3, 'max_features_mode': 'cat', 'max_features_cat': 'log2', 'bootstrap': False, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:11,964] The parameter `max_features_frac` in Trial#15 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:11,965] The parameter `max_samples` in Trial#15 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:12,528] Trial 15 finished with value: 0.6430352147390322 and parameters: {'n_estimators': 300, 'use_max_depth': False, 'min_samples_split': 25, 'min_samples_leaf': 13, 'max_features_mode': 'frac', 'max_features_frac': 0.3091982210024658, 'bootstrap': True, 'criterion': 'log_loss', 'class_weight': None, 'max_samples': 0.9826689730327275}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:12,531] The parameter `max_features_cat` in Trial#16 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:12,532] The parameter `max_samples` in Trial#16 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:13,224] Trial 16 finished with value: 0.6402335580251493 and parameters: {'n_estimators': 400, 'use_max_depth': False, 'min_samples_split': 46, 'min_samples_leaf': 11, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': True, 'criterion': 'log_loss', 'class_weight': 'balanced', 'max_samples': 0.868335998456562}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:13,227] The parameter `max_depth` in Trial#17 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:13,228] The parameter `max_features_cat` in Trial#17 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:13,228] The parameter `max_samples` in Trial#17 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:13,606] Trial 17 finished with value: 0.6368785713169364 and parameters: {'n_estimators': 200, 'use_max_depth': True, 'max_depth': 20, 'min_samples_split': 33, 'min_samples_leaf': 1, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': True, 'criterion': 'gini', 'class_weight': None, 'max_samples': 0.9904638940160335}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:13,610] The parameter `max_features_cat` in Trial#18 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:13,611] The parameter `max_samples` in Trial#18 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:15,569] Trial 18 finished with value: 0.6396119031714306 and parameters: {'n_estimators': 1150, 'use_max_depth': False, 'min_samples_split': 39, 'min_samples_leaf': 15, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None, 'max_samples': 0.836828482346553}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:15,572] The parameter `max_features_frac` in Trial#19 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:15,573] The parameter `max_samples` in Trial#19 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:16,141] Trial 19 finished with value: 0.646751197675367 and parameters: {'n_estimators': 250, 'use_max_depth': False, 'min_samples_split': 45, 'min_samples_leaf': 3, 'max_features_mode': 'frac', 'max_features_frac': 0.5129296914725726, 'bootstrap': True, 'criterion': 'log_loss', 'class_weight': None, 'max_samples': 0.6111731784505638}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:16,145] The parameter `max_depth` in Trial#20 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:16,146] The parameter `max_features_cat` in Trial#20 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:16,146] The parameter `max_samples` in Trial#20 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:18,839] Trial 20 finished with value: 0.6356164849778245 and parameters: {'n_estimators': 500, 'use_max_depth': True, 'max_depth': 29, 'min_samples_split': 30, 'min_samples_leaf': 10, 'max_features_mode': 'cat', 'max_features_cat': None, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None, 'max_samples': 0.885592124026027}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:18,856] The parameter `max_features_frac` in Trial#21 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:18,863] The parameter `max_samples` in Trial#21 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:19,591] Trial 21 finished with value: 0.6486453476186808 and parameters: {'n_estimators': 250, 'use_max_depth': False, 'min_samples_split': 50, 'min_samples_leaf': 3, 'max_features_mode': 'frac', 'max_features_frac': 0.5354732473690489, 'bootstrap': True, 'criterion': 'log_loss', 'class_weight': None, 'max_samples': 0.6383279280466854}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:19,594] The parameter `max_features_cat` in Trial#22 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:20,685] Trial 22 finished with value: 0.6430787842598785 and parameters: {'n_estimators': 350, 'use_max_depth': False, 'min_samples_split': 29, 'min_samples_leaf': 1, 'max_features_mode': 'cat', 'max_features_cat': 'log2', 'bootstrap': False, 'criterion': 'log_loss', 'class_weight': None}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:20,688] The parameter `max_depth` in Trial#23 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:20,689] The parameter `max_features_cat` in Trial#23 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:20,690] The parameter `max_samples` in Trial#23 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:21,760] Trial 23 finished with value: 0.6502005486037685 and parameters: {'n_estimators': 600, 'use_max_depth': True, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None, 'max_samples': 0.6159710916658789}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:21,763] The parameter `max_depth` in Trial#24 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:21,764] The parameter `max_features_cat` in Trial#24 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:21,765] The parameter `max_samples` in Trial#24 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:22,704] Trial 24 finished with value: 0.6506149015945055 and parameters: {'n_estimators': 500, 'use_max_depth': True, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced', 'max_samples': 0.5750176536835518}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:22,707] The parameter `max_depth` in Trial#25 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:22,708] The parameter `max_features_cat` in Trial#25 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:22,709] The parameter `max_samples` in Trial#25 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:23,349] Trial 25 finished with value: 0.6458082694206186 and parameters: {'n_estimators': 400, 'use_max_depth': True, 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced', 'max_samples': 0.5086792017528844}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:23,352] The parameter `max_features_cat` in Trial#26 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:23,352] The parameter `max_samples` in Trial#26 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:25,323] Trial 26 finished with value: 0.6435886774032638 and parameters: {'n_estimators': 900, 'use_max_depth': False, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced', 'max_samples': 0.9934922074348855}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:25,326] The parameter `max_features_frac` in Trial#27 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:25,327] The parameter `max_samples` in Trial#27 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:26,837] Trial 27 finished with value: 0.6440414310311707 and parameters: {'n_estimators': 500, 'use_max_depth': False, 'min_samples_split': 20, 'min_samples_leaf': 3, 'max_features_mode': 'frac', 'max_features_frac': 0.7483710933559411, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None, 'max_samples': 0.5899252318394997}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:26,840] The parameter `max_depth` in Trial#28 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:26,841] The parameter `max_features_cat` in Trial#28 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:29,574] Trial 28 finished with value: 0.6400415123445887 and parameters: {'n_estimators': 1000, 'use_max_depth': True, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': False, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:29,577] The parameter `max_features_cat` in Trial#29 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:29,577] The parameter `max_samples` in Trial#29 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:30,120] Trial 29 finished with value: 0.6497609426382102 and parameters: {'n_estimators': 300, 'use_max_depth': False, 'min_samples_split': 25, 'min_samples_leaf': 6, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None, 'max_samples': 0.8294464571822495}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:30,123] The parameter `max_features_cat` in Trial#30 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:31,422] Trial 30 finished with value: 0.6364432643469468 and parameters: {'n_estimators': 650, 'use_max_depth': False, 'min_samples_split': 44, 'min_samples_leaf': 12, 'max_features_mode': 'cat', 'max_features_cat': 'log2', 'bootstrap': False, 'criterion': 'gini', 'class_weight': None}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:31,425] The parameter `max_depth` in Trial#31 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:31,426] The parameter `max_features_cat` in Trial#31 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:31,427] The parameter `max_samples` in Trial#31 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:33,198] Trial 31 finished with value: 0.6473282450536024 and parameters: {'n_estimators': 1050, 'use_max_depth': True, 'max_depth': 18, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': True, 'criterion': 'log_loss', 'class_weight': None, 'max_samples': 0.6087236083942362}. Best is trial 0 with value: 0.6510031693454986.\n",
            "[W 2025-12-12 23:31:33,201] The parameter `max_depth` in Trial#32 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:33,202] The parameter `max_features_cat` in Trial#32 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:33,203] The parameter `max_samples` in Trial#32 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:33,944] Trial 32 finished with value: 0.6526847318474135 and parameters: {'n_estimators': 450, 'use_max_depth': True, 'max_depth': 17, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None, 'max_samples': 0.6016017483922569}. Best is trial 32 with value: 0.6526847318474135.\n",
            "[W 2025-12-12 23:31:33,947] The parameter `max_depth` in Trial#33 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:33,949] The parameter `max_features_frac` in Trial#33 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:33,949] The parameter `max_samples` in Trial#33 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:35,307] Trial 33 finished with value: 0.6477646266515495 and parameters: {'n_estimators': 850, 'use_max_depth': True, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features_mode': 'frac', 'max_features_frac': 0.3289145361844019, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced', 'max_samples': 0.5415411006090546}. Best is trial 32 with value: 0.6526847318474135.\n",
            "[W 2025-12-12 23:31:35,309] The parameter `max_depth` in Trial#34 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:35,310] The parameter `max_features_cat` in Trial#34 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:35,311] The parameter `max_samples` in Trial#34 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:36,421] Trial 34 finished with value: 0.6413517410125917 and parameters: {'n_estimators': 750, 'use_max_depth': True, 'max_depth': 16, 'min_samples_split': 9, 'min_samples_leaf': 9, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': True, 'criterion': 'gini', 'class_weight': 'balanced', 'max_samples': 0.6295643511271519}. Best is trial 32 with value: 0.6526847318474135.\n",
            "[W 2025-12-12 23:31:36,424] The parameter `max_depth` in Trial#35 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:36,425] The parameter `max_features_cat` in Trial#35 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:37,315] Trial 35 finished with value: 0.6063110925996937 and parameters: {'n_estimators': 750, 'use_max_depth': True, 'max_depth': 4, 'min_samples_split': 16, 'min_samples_leaf': 1, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': False, 'criterion': 'gini', 'class_weight': None}. Best is trial 32 with value: 0.6526847318474135.\n",
            "[W 2025-12-12 23:31:37,318] The parameter `max_features_frac` in Trial#36 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:37,319] The parameter `max_samples` in Trial#36 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:38,316] Trial 36 finished with value: 0.6393625666529362 and parameters: {'n_estimators': 400, 'use_max_depth': False, 'min_samples_split': 31, 'min_samples_leaf': 1, 'max_features_mode': 'frac', 'max_features_frac': 0.7064049554014991, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': 'balanced', 'max_samples': 0.5640305055271893}. Best is trial 32 with value: 0.6526847318474135.\n",
            "[W 2025-12-12 23:31:38,319] The parameter `max_depth` in Trial#37 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:38,320] The parameter `max_features_frac` in Trial#37 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:38,321] The parameter `max_samples` in Trial#37 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:41,729] Trial 37 finished with value: 0.6338906228350945 and parameters: {'n_estimators': 800, 'use_max_depth': True, 'max_depth': 24, 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_features_mode': 'frac', 'max_features_frac': 0.8635205170479258, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None, 'max_samples': 0.9226221738975879}. Best is trial 32 with value: 0.6526847318474135.\n",
            "[W 2025-12-12 23:31:41,732] The parameter `max_features_cat` in Trial#38 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:43,247] Trial 38 finished with value: 0.5261258541832238 and parameters: {'n_estimators': 200, 'use_max_depth': False, 'min_samples_split': 42, 'min_samples_leaf': 4, 'max_features_mode': 'cat', 'max_features_cat': None, 'bootstrap': False, 'criterion': 'entropy', 'class_weight': None}. Best is trial 32 with value: 0.6526847318474135.\n",
            "[W 2025-12-12 23:31:43,250] The parameter `max_depth` in Trial#39 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:43,252] The parameter `max_features_cat` in Trial#39 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[W 2025-12-12 23:31:43,252] The parameter `max_samples` in Trial#39 is sampled independently using `RandomSampler` instead of `TPESampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported for `multivariate=True`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler` if this independent sampling is intended behavior.\n",
            "[I 2025-12-12 23:31:43,634] Trial 39 finished with value: 0.6422363077723088 and parameters: {'n_estimators': 200, 'use_max_depth': True, 'max_depth': 15, 'min_samples_split': 19, 'min_samples_leaf': 2, 'max_features_mode': 'cat', 'max_features_cat': 'sqrt', 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None, 'max_samples': 0.6820006886385138}. Best is trial 32 with value: 0.6526847318474135.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OPTUNA] Mejor AP(val): 0.652685\n",
            "[OPTUNA] Params ganadores: {'n_estimators': 450, 'max_depth': 17, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy', 'class_weight': None, 'max_samples': 0.6016017483922569, 'random_state': 42, 'n_jobs': -1}\n",
            "[OPTUNA] Guardado BEST en: BEST_RF_REDUCED_SMOTENC.json\n",
            "[OPTUNA] Reentreno final completado.\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "tuned_model = None\n",
        "N_TRIALS = 40\n",
        "STUDY_NAME = f\"RF_{VIEW_TAG}_{BAL_TAG}_AP\"\n",
        "SAMPLER = TPESampler(seed=RANDOM_STATE, multivariate=True, group=False)\n",
        "study = optuna.create_study(direction=\"maximize\", study_name=STUDY_NAME, sampler=SAMPLER)\n",
        "\n",
        "SEARCH_KEYS = [\n",
        "    \"n_estimators\",\"max_depth\",\"min_samples_split\",\"min_samples_leaf\",\n",
        "    \"max_features\",\"bootstrap\",\"max_samples\",\"criterion\",\"class_weight\"\n",
        "]\n",
        "\n",
        "def suggest_rf_params(trial):\n",
        "    p = {}\n",
        "    p[\"n_estimators\"]      = trial.suggest_int(\"n_estimators\", 200, 2000, step=50)\n",
        "\n",
        "    if trial.suggest_categorical(\"use_max_depth\", [True, False]):\n",
        "        p[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 30)\n",
        "    else:\n",
        "        p[\"max_depth\"] = None\n",
        "    p[\"min_samples_split\"] = trial.suggest_int(\"min_samples_split\", 2, 50)\n",
        "    p[\"min_samples_leaf\"]  = trial.suggest_int(\"min_samples_leaf\", 1, 25)\n",
        "\n",
        "    if trial.suggest_categorical(\"max_features_mode\", [\"cat\",\"frac\"]) == \"cat\":\n",
        "        p[\"max_features\"] = trial.suggest_categorical(\"max_features_cat\", [\"sqrt\",\"log2\", None])\n",
        "    else:\n",
        "        p[\"max_features\"] = trial.suggest_float(\"max_features_frac\", 0.3, 1.0)\n",
        "    p[\"bootstrap\"]        = trial.suggest_categorical(\"bootstrap\", [True, False])\n",
        "    p[\"criterion\"]        = trial.suggest_categorical(\"criterion\", [\"gini\",\"entropy\",\"log_loss\"])\n",
        "    p[\"class_weight\"]     = trial.suggest_categorical(\"class_weight\", [None, \"balanced\"])\n",
        "    if p[\"bootstrap\"]:\n",
        "        p[\"max_samples\"] = trial.suggest_float(\"max_samples\", 0.5, 1.0)\n",
        "    else:\n",
        "        p[\"max_samples\"] = None\n",
        "    # fijos\n",
        "    p[\"random_state\"]     = RANDOM_STATE\n",
        "    p[\"n_jobs\"]           = -1\n",
        "    return p\n",
        "\n",
        "# Warm-start\n",
        "if BEST_HP_FILE.exists():\n",
        "    try:\n",
        "        prev = json.loads(BEST_HP_FILE.read_text())\n",
        "        warm = {k: prev[k] for k in SEARCH_KEYS if k in prev}\n",
        "        if warm:\n",
        "            print(\"[OPTUNA] Enqueuing previous BEST as a trial seed.\")\n",
        "            study.enqueue_trial(warm)\n",
        "    except Exception as e:\n",
        "        print(\"[OPTUNA] Aviso: no se pudo usar BEST para warm-start:\", e)\n",
        "\n",
        "def objective(trial):\n",
        "    hp = suggest_rf_params(trial)\n",
        "    mdl = RandomForestClassifier(**hp)\n",
        "\n",
        "    mdl.fit(X_train_final, y_train_final)\n",
        "    proba_val_t = mdl.predict_proba(X_val_fit)[:, 1]\n",
        "    ap = average_precision_score(y_val, proba_val_t)\n",
        "    return ap\n",
        "\n",
        "print(f\"[OPTUNA] Iniciando estudio '{STUDY_NAME}' con {N_TRIALS} pruebas...\")\n",
        "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=False)\n",
        "\n",
        "best = study.best_trial\n",
        "print(f\"[OPTUNA] Mejor AP(val): {best.value:.6f}\")\n",
        "\n",
        "def rebuild_best_params(best_trial):\n",
        "    bp = dict(best.params)\n",
        "    out = {}\n",
        "    out[\"n_estimators\"]      = int(bp[\"n_estimators\"])\n",
        "    out[\"max_depth\"]         = int(bp[\"max_depth\"]) if bp.get(\"use_max_depth\", True) and bp.get(\"max_depth\", None) is not None else None\n",
        "    out[\"min_samples_split\"] = int(bp[\"min_samples_split\"])\n",
        "    out[\"min_samples_leaf\"]  = int(bp[\"min_samples_leaf\"])\n",
        "    if bp.get(\"max_features_mode\") == \"cat\":\n",
        "        out[\"max_features\"] = bp.get(\"max_features_cat\")\n",
        "    else:\n",
        "        out[\"max_features\"] = float(bp.get(\"max_features_frac\", 0.7))\n",
        "    out[\"bootstrap\"]        = bool(bp[\"bootstrap\"])\n",
        "    out[\"criterion\"]        = bp[\"criterion\"]\n",
        "    out[\"class_weight\"]     = bp[\"class_weight\"]\n",
        "    out[\"max_samples\"]      = float(bp[\"max_samples\"]) if out[\"bootstrap\"] and (\"max_samples\" in bp) else None\n",
        "    out[\"random_state\"]     = RANDOM_STATE\n",
        "    out[\"n_jobs\"]           = -1\n",
        "    return out\n",
        "\n",
        "best_params = rebuild_best_params(best)\n",
        "print(\"[OPTUNA] Params ganadores:\", best_params)\n",
        "\n",
        "with open(BEST_HP_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(best_params, f, indent=2, ensure_ascii=False)\n",
        "print(\"[OPTUNA] Guardado BEST en:\", BEST_HP_FILE.name)\n",
        "\n",
        "tuned_model = RandomForestClassifier(**best_params)\n",
        "tuned_model.fit(X_train_final, y_train_final)\n",
        "print(\"[OPTUNA] Reentreno final completado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8797a95-rf",
      "metadata": {},
      "source": [
        "8 — Cross-Validation (OOF) para baseline y tuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "efb9478a-rf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV-BASELINE] Guardados: cv_summary_RF_REDUCED_SMOTENC_BASELINE_CV5.csv | oof_RF_REDUCED_SMOTENC_BASELINE_CV5.parquet\n",
            "[CV-TUNED] Guardados: cv_summary_RF_REDUCED_SMOTENC_TUNED_CV5.csv | oof_RF_REDUCED_SMOTENC_TUNED_CV5.parquet\n"
          ]
        }
      ],
      "source": [
        "def run_oof_cv_rf(model_params, X, y, feature_names_in, k_folds=CV_FOLDS, seed=RANDOM_STATE, exp_suffix=\"BASELINE\"):\n",
        "   \n",
        "    assert_X_names_aligned(X, feature_names_in, f\"CV(INPUT)-{exp_suffix}\")\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
        "    oof_proba = np.zeros_like(y, dtype=float)\n",
        "    fold_rows = []\n",
        "\n",
        "    base = dict(model_params)\n",
        "    base.setdefault(\"random_state\", seed)\n",
        "    base.setdefault(\"n_jobs\", -1)\n",
        "    if base.get(\"n_estimators\") is None:\n",
        "        base[\"n_estimators\"] = 1000\n",
        "\n",
        "    for f, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
        "        X_tr0, X_va0 = X[tr_idx], X[va_idx]\n",
        "        y_tr0, y_va0 = y[tr_idx], y[va_idx]\n",
        "\n",
        "        feat_names_fold = list(feature_names_in)\n",
        "\n",
        "        # Reducción por fold\n",
        "        if USE_REDUCED and SELECTION_MODE != \"NONE\":\n",
        "            if SELECTION_MODE == \"MI\":\n",
        "                keep_idx, _, _ = fit_mi_selector(X_tr0, y_tr0, topk=MI_TOPK, seed=seed)\n",
        "            elif SELECTION_MODE == \"L1\":\n",
        "                keep_idx, _rep, _log = fit_l1_selector(X_tr0, y_tr0, feat_names_fold, seed=seed)\n",
        "            else:\n",
        "                raise ValueError(\"SELECTION_MODE inválido\")\n",
        "\n",
        "            X_tr0 = apply_keep_idx(X_tr0, keep_idx)\n",
        "            X_va0 = apply_keep_idx(X_va0, keep_idx)\n",
        "            feat_names_fold = [feat_names_fold[i] for i in keep_idx]\n",
        "\n",
        "        # Balanceo en CV con SMOTENC\n",
        "        if BALANCE_IN_CV and USE_BALANCED_TRAIN:\n",
        "            X_tr, y_tr = maybe_smote(X_tr0, y_tr0, feat_names_fold, debug=False)\n",
        "        else:\n",
        "            X_tr, y_tr = X_tr0, y_tr0\n",
        "\n",
        "        assert_X_names_aligned(X_tr,  feat_names_fold, f\"CV(fold={f})-train\")\n",
        "        assert_X_names_aligned(X_va0, feat_names_fold, f\"CV(fold={f})-val\")\n",
        "\n",
        "        mdl = RandomForestClassifier(**base)\n",
        "        mdl.fit(X_tr, y_tr)\n",
        "\n",
        "        proba_va = mdl.predict_proba(X_va0)[:, 1]\n",
        "        oof_proba[va_idx] = proba_va\n",
        "\n",
        "        fold_rows.append({\n",
        "            \"fold\": f,\n",
        "            \"pr_auc\": average_precision_score(y_va0, proba_va),\n",
        "            \"roc_auc\": roc_auc_score(y_va0, proba_va),\n",
        "            \"best_iteration\": np.nan\n",
        "        })\n",
        "\n",
        "    oof_pr = average_precision_score(y, oof_proba)\n",
        "    oof_roc = roc_auc_score(y, oof_proba)\n",
        "    thr_oof, _ = find_best_threshold(y, oof_proba, metric=\"f1\")\n",
        "    y_oof_pred = (oof_proba >= thr_oof).astype(int)\n",
        "    oof_f1  = f1_score(y, y_oof_pred, zero_division=0)\n",
        "    oof_rec = recall_score(y, y_oof_pred, zero_division=0)\n",
        "    oof_bal = balanced_accuracy_score(y, y_oof_pred)\n",
        "\n",
        "    cv_tag = f\"{EXP_NAME}_{exp_suffix}_CV{CV_FOLDS}\"\n",
        "    cv_csv = OUT_RESULTS / f\"cv_summary_{cv_tag}.csv\"\n",
        "    folds_df = pd.DataFrame(fold_rows)\n",
        "    agg_row = pd.DataFrame([{\n",
        "        \"fold\": \"OOF\", \"pr_auc\": oof_pr, \"roc_auc\": oof_roc,\n",
        "        \"thr\": thr_oof, \"f1\": oof_f1, \"recall\": oof_rec, \"bal_acc\": oof_bal\n",
        "    }])\n",
        "    pd.concat([folds_df, agg_row], ignore_index=True).to_csv(cv_csv, index=False)\n",
        "\n",
        "    oof_path = OUT_PREDS / f\"oof_{cv_tag}.parquet\"\n",
        "    pd.DataFrame({\"oof_proba\": oof_proba, \"y_true\": y}).to_parquet(oof_path, index=False)\n",
        "\n",
        "    print(f\"[CV-{exp_suffix}] Guardados: {cv_csv.name} | {oof_path.name}\")\n",
        "    return {\"oof_pr_auc\": oof_pr, \"oof_roc_auc\": oof_roc, \"thr\": thr_oof,\n",
        "            \"oof_f1\": oof_f1, \"oof_recall\": oof_rec, \"oof_bal_acc\": oof_bal}\n",
        "\n",
        "cv_baseline = None\n",
        "cv_tuned = None\n",
        "\n",
        "if DO_CV_BASELINE:\n",
        "    cv_baseline = run_oof_cv_rf(base_params, X_train_fit, y_train, feature_names_used, exp_suffix=\"BASELINE\")\n",
        "\n",
        "if DO_CV_TUNED and 'best_params' in globals():\n",
        "    cv_tuned = run_oof_cv_rf(best_params, X_train_fit, y_train, feature_names_used, exp_suffix=\"TUNED\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15dae995-rf",
      "metadata": {},
      "source": [
        "9 — Evaluación en test + guardados (figuras, importancias, preds, baseline.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "983f541f-rf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK][BASE] Guardados: \n",
            "  - Seed HPs   : RF_REDUCED_SMOTENC_BASE_seed_params.json \n",
            "  - Fitted HPs : RF_REDUCED_SMOTENC_BASE_fitted_params.json \n",
            "  - Importancias: RF_REDUCED_SMOTENC_feature_importances.csv \n",
            "  - Preds val   : preds_val_RF_REDUCED_SMOTENC.parquet \n",
            "  - Preds test  : preds_test_RF_REDUCED_SMOTENC.parquet \n",
            "  - Baselines   : baselines.csv\n",
            "[OK][TUNED] Guardados: \n",
            "  - Fitted HPs : RF_REDUCED_SMOTENC_TUNED_fitted_params.json \n",
            "  - Importancias: RF_REDUCED_SMOTENC_TUNED_feature_importances.csv \n",
            "  - Preds val   : preds_val_RF_REDUCED_SMOTENC_TUNED.parquet \n",
            "  - Preds test  : preds_test_RF_REDUCED_SMOTENC_TUNED.parquet \n",
            "  - Baselines   : baselines.csv\n"
          ]
        }
      ],
      "source": [
        "def plot_pr_curve(y_true, y_proba, title, out_path):\n",
        "    prec, rec, _ = precision_recall_curve(y_true, y_proba)\n",
        "    ap = average_precision_score(y_true, y_proba)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.step(rec, prec, where='post')\n",
        "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
        "    plt.title(f'{title} (AP={ap:.4f})')\n",
        "    plt.grid(True, linestyle='--', alpha=.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path, dpi=150); plt.close()\n",
        "\n",
        "def plot_roc_curve(y_true, y_proba, title, out_path):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
        "    auc = roc_auc_score(y_true, y_proba)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.plot(fpr, tpr, lw=2)\n",
        "    plt.plot([0,1],[0,1], 'k--', lw=1)\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'{title} (AUC={auc:.4f})')\n",
        "    plt.grid(True, linestyle='--', alpha=.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path, dpi=150); plt.close()\n",
        "\n",
        "def plot_confusion(y_true, y_pred, title, out_path, normalize=False):\n",
        "    norm = 'true' if normalize else None\n",
        "    cm = confusion_matrix(y_true, y_pred, normalize=norm)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    im = plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
        "    plt.title(title)\n",
        "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
        "    ticks = np.arange(2)\n",
        "    plt.xticks(ticks, ['0','1']); plt.yticks(ticks, ['0','1'])\n",
        "    thresh = cm.max()/2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            txt = f'{cm[i,j]:.2f}' if normalize else str(cm[i,j])\n",
        "            plt.text(j, i, txt, ha='center', va='center',\n",
        "                     color='white' if cm[i,j] > thresh else 'black')\n",
        "    plt.ylabel('True label'); plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path, dpi=150); plt.close()\n",
        "\n",
        "# ——— Evaluación y guardados ———\n",
        "base = EXP_NAME\n",
        "\n",
        "# BASELINE\n",
        "proba_test = model.predict_proba(X_test_fit)[:, 1]\n",
        "y_pred_test = (proba_test >= thr_val).astype(int)\n",
        "test_metrics = compute_all_metrics(y_test, proba_test, thr_val)\n",
        "\n",
        "# Guardar HP baseline\n",
        "params_seed_path = OUT_PARAMS / f\"{base}_BASE_seed_params.json\"\n",
        "with open(params_seed_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(base_params, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "params_fitted_path = OUT_PARAMS / f\"{base}_BASE_fitted_params.json\"\n",
        "with open(params_fitted_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(model.get_params(), f, indent=2, ensure_ascii=False)\n",
        "\n",
        "# Figuras baseline\n",
        "plot_pr_curve(y_val,  proba_val,  f\"{base} — PR (val)\",  OUT_FIGS / f\"{base}_pr_val.png\")\n",
        "plot_pr_curve(y_test, proba_test, f\"{base} — PR (test)\", OUT_FIGS / f\"{base}_pr_test.png\")\n",
        "plot_roc_curve(y_val,  proba_val,  f\"{base} — ROC (val)\",  OUT_FIGS / f\"{base}_roc_val.png\")\n",
        "plot_roc_curve(y_test, proba_test, f\"{base} — ROC (test)\", OUT_FIGS / f\"{base}_roc_test.png\")\n",
        "plot_confusion(y_test, y_pred_test, f\"{base} — Confusion (test @thr={thr_val:.3f})\", OUT_FIGS / f\"{base}_cm_test.png\")\n",
        "\n",
        "# Importancias baseline\n",
        "try:\n",
        "    imp_gain = model.feature_importances_\n",
        "except Exception:\n",
        "    imp_gain = np.zeros(len(feature_names_used))\n",
        "\n",
        "imp_df = pd.DataFrame({\n",
        "    \"feature\": feature_names_used[:len(imp_gain)],\n",
        "    \"importance\": imp_gain\n",
        "}).sort_values(\"importance\", ascending=False)\n",
        "imp_path = OUT_RESULTS / f\"{base}_feature_importances.csv\"\n",
        "imp_df.to_csv(imp_path, index=False)\n",
        "\n",
        "# Preds test baseline\n",
        "preds_path = OUT_PREDS / f\"preds_test_{base}.parquet\"\n",
        "pd.DataFrame({\"proba\": proba_test, \"y_true\": y_test}).to_parquet(preds_path, index=False)\n",
        "preds_val_path = OUT_PREDS / f\"preds_val_{base}.parquet\"\n",
        "pd.DataFrame({\"proba\": proba_val, \"y_true\": y_val}).to_parquet(preds_val_path, index=False)\n",
        "\n",
        "row_base = {\n",
        "    \"model\": base,\n",
        "    \"thr_val\": thr_val,\n",
        "    \"val_pr_auc\": val_metrics[\"pr_auc\"],\n",
        "    \"val_roc_auc\": val_metrics[\"roc_auc\"],\n",
        "    \"val_precision\": val_metrics[\"precision\"],\n",
        "    \"val_f1\": val_metrics[\"f1\"],\n",
        "    \"val_recall\": val_metrics[\"recall\"],\n",
        "    \"val_bal_acc\": val_metrics[\"bal_acc\"],\n",
        "    \"test_pr_auc\": test_metrics[\"pr_auc\"],\n",
        "    \"test_roc_auc\": test_metrics[\"roc_auc\"],\n",
        "    \"test_precision\": test_metrics[\"precision\"],\n",
        "    \"test_f1\": test_metrics[\"f1\"],\n",
        "    \"test_recall\": test_metrics[\"recall\"],\n",
        "    \"test_bal_acc\": test_metrics[\"bal_acc\"],\n",
        "    \"best_iteration\": np.nan \n",
        "}\n",
        "res_csv = OUT_RESULTS / \"baselines.csv\"\n",
        "pd.DataFrame([row_base]).to_csv(res_csv, mode=(\"a\" if res_csv.exists() else \"w\"),\n",
        "                                index=False, header=not res_csv.exists())\n",
        "\n",
        "print(\"[OK][BASE] Guardados:\",\n",
        "      \"\\n  - Seed HPs   :\", params_seed_path.name,\n",
        "      \"\\n  - Fitted HPs :\", params_fitted_path.name,\n",
        "      \"\\n  - Importancias:\", imp_path.name,\n",
        "      \"\\n  - Preds val   :\", preds_val_path.name,\n",
        "      \"\\n  - Preds test  :\", preds_path.name,\n",
        "      \"\\n  - Baselines   :\", res_csv.name)\n",
        "\n",
        "# TUNED\n",
        "if tuned_model is not None:\n",
        "    proba_val_tuned = tuned_model.predict_proba(X_val_fit)[:, 1]\n",
        "    thr_val_tuned, _ = find_best_threshold(y_val, proba_val_tuned, metric=\"f1\")\n",
        "    val_metrics_tuned = compute_all_metrics(y_val, proba_val_tuned, thr_val_tuned)\n",
        "\n",
        "    proba_test_tuned = tuned_model.predict_proba(X_test_fit)[:, 1]\n",
        "    y_pred_test_tuned = (proba_test_tuned >= thr_val_tuned).astype(int)\n",
        "    test_metrics_tuned = compute_all_metrics(y_test, proba_test_tuned, thr_val_tuned)\n",
        "\n",
        "    tuned_fitted_path = OUT_PARAMS / f\"{base}_TUNED_fitted_params.json\"\n",
        "    with open(tuned_fitted_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(tuned_model.get_params(), f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    base_t = base + \"_TUNED\"\n",
        "    plot_pr_curve(y_val,  proba_val_tuned,  f\"{base_t} — PR (val)\",  OUT_FIGS / f\"{base_t}_pr_val.png\")\n",
        "    plot_pr_curve(y_test, proba_test_tuned, f\"{base_t} — PR (test)\", OUT_FIGS / f\"{base_t}_pr_test.png\")\n",
        "    plot_roc_curve(y_val,  proba_val_tuned,  f\"{base_t} — ROC (val)\",  OUT_FIGS / f\"{base_t}_roc_val.png\")\n",
        "    plot_roc_curve(y_test, proba_test_tuned, f\"{base_t} — ROC (test)\", OUT_FIGS / f\"{base_t}_roc_test.png\")\n",
        "    plot_confusion(y_test, y_pred_test_tuned, f\"{base_t} — Confusion (test @thr={thr_val_tuned:.3f})\", OUT_FIGS / f\"{base_t}_cm_test.png\")\n",
        "\n",
        "    try:\n",
        "        imp_gain_t = tuned_model.feature_importances_\n",
        "    except Exception:\n",
        "        imp_gain_t = np.zeros(len(feature_names_used))\n",
        "\n",
        "    imp_t_path = OUT_RESULTS / f\"{base_t}_feature_importances.csv\"\n",
        "    pd.DataFrame({\n",
        "        \"feature\": feature_names_used[:len(imp_gain_t)],\n",
        "        \"importance\": imp_gain_t\n",
        "    }).sort_values(\"importance\", ascending=False).to_csv(imp_t_path, index=False)\n",
        "\n",
        "    preds_t_path = OUT_PREDS / f\"preds_test_{base_t}.parquet\"\n",
        "    pd.DataFrame({\"proba\": proba_test_tuned, \"y_true\": y_test}).to_parquet(preds_t_path, index=False)\n",
        "    preds_val_t_path = OUT_PREDS / f\"preds_val_{base_t}.parquet\"\n",
        "    pd.DataFrame({\"proba\": proba_val_tuned, \"y_true\": y_val}).to_parquet(preds_val_t_path, index=False)\n",
        "\n",
        "    row_t = {\n",
        "        \"model\": base_t,\n",
        "        \"thr_val\": thr_val_tuned,\n",
        "        \"val_pr_auc\": val_metrics_tuned[\"pr_auc\"],\n",
        "        \"val_roc_auc\": val_metrics_tuned[\"roc_auc\"],\n",
        "        \"val_precision\": val_metrics_tuned[\"precision\"],\n",
        "        \"val_f1\": val_metrics_tuned[\"f1\"],\n",
        "        \"val_recall\": val_metrics_tuned[\"recall\"],\n",
        "        \"val_bal_acc\": val_metrics_tuned[\"bal_acc\"],\n",
        "        \"test_pr_auc\": test_metrics_tuned[\"pr_auc\"],\n",
        "        \"test_roc_auc\": test_metrics_tuned[\"roc_auc\"],\n",
        "        \"test_precision\": test_metrics_tuned[\"precision\"],\n",
        "        \"test_f1\": test_metrics_tuned[\"f1\"],\n",
        "        \"test_recall\": test_metrics_tuned[\"recall\"],\n",
        "        \"test_bal_acc\": test_metrics_tuned[\"bal_acc\"],\n",
        "        \"best_iteration\": np.nan\n",
        "    }\n",
        "    pd.DataFrame([row_t]).to_csv(res_csv, mode=\"a\", index=False, header=False)\n",
        "\n",
        "    print(\"[OK][TUNED] Guardados:\",\n",
        "      \"\\n  - Fitted HPs :\", tuned_fitted_path.name,\n",
        "      \"\\n  - Importancias:\", imp_t_path.name,\n",
        "      \"\\n  - Preds val   :\", preds_val_t_path.name,\n",
        "      \"\\n  - Preds test  :\", preds_t_path.name,\n",
        "      \"\\n  - Baselines   :\", res_csv.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "928335ce-rf",
      "metadata": {},
      "source": [
        "10 — Mejores resultados + resumen CV (y comparación SOTA RF de la literatura)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a837bea0-rf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== MEJORES EN TEST (por métrica) ===\n",
            "- test_pr_auc: RF_REDUCED_SMOTENC_TUNED | PR-AUC=0.6664 | ROC-AUC=0.8523 | F1=0.5881 | Recall=0.5209 | Precision=0.6752 | thr(val)=0.645 | best_iter=NA\n",
            "- test_roc_auc: RF_REDUCED_SMOTENC | PR-AUC=0.6650 | ROC-AUC=0.8532 | F1=0.6163 | Recall=0.6511 | Precision=0.5850 | thr(val)=0.537 | best_iter=NA\n",
            "- test_recall: RF_REDUCED_SMOTENC | PR-AUC=0.6650 | ROC-AUC=0.8532 | F1=0.6163 | Recall=0.6511 | Precision=0.5850 | thr(val)=0.537 | best_iter=NA\n",
            "- test_f1: RF_REDUCED_SMOTENC | PR-AUC=0.6650 | ROC-AUC=0.8532 | F1=0.6163 | Recall=0.6511 | Precision=0.5850 | thr(val)=0.537 | best_iter=NA\n",
            "- test_precision: RF_REDUCED_SMOTENC_TUNED | PR-AUC=0.6664 | ROC-AUC=0.8523 | F1=0.5881 | Recall=0.5209 | Precision=0.6752 | thr(val)=0.645 | best_iter=NA\n",
            "=== RESUMEN CV-OOF (por experimento) ===\n",
            "                            tag   pr_auc  roc_auc       f1   recall  bal_acc   thr\n",
            "   RF_REDUCED_SMOTENC_TUNED_CV5 0.643009 0.844839 0.593968 0.627964 0.751704 0.541\n",
            "RF_REDUCED_SMOTENC_BASELINE_CV5 0.642054 0.845193 0.591122 0.669665 0.758529 0.487\n",
            "[OK] Normalizado. Backup: baselines_legacy_backup.csv\n"
          ]
        }
      ],
      "source": [
        "AGGREGATE_ALL_RUNS = False\n",
        "\n",
        "def safe(v, fmt=\".4f\"):\n",
        "    try:\n",
        "        return f\"{float(v):{fmt}}\"\n",
        "    except Exception:\n",
        "        return \"NA\"\n",
        "\n",
        "base_csv = OUT_RESULTS / \"baselines.csv\"\n",
        "if not base_csv.exists():\n",
        "    raise FileNotFoundError(f\"No existe {base_csv}\")\n",
        "\n",
        "df = pd.read_csv(base_csv)\n",
        "\n",
        "needed = [\n",
        "    \"model\",\"thr_val\",\n",
        "    \"val_pr_auc\",\"val_roc_auc\",\"val_precision\",\"val_f1\",\"val_recall\",\"val_bal_acc\",\n",
        "    \"test_pr_auc\",\"test_roc_auc\",\"test_precision\",\"test_f1\",\"test_recall\",\"test_bal_acc\",\n",
        "    \"best_iteration\"\n",
        "]\n",
        "for c in needed:\n",
        "    if c not in df.columns:\n",
        "        df[c] = pd.NA \n",
        "\n",
        "df = df[needed].copy()\n",
        "\n",
        "num_cols = [c for c in needed if c not in (\"model\",)]\n",
        "for c in num_cols:\n",
        "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "if AGGREGATE_ALL_RUNS:\n",
        "    root_art = ARTIF_DIR.parent\n",
        "    for p in (root_art).glob(\"RF_*/results/baselines.csv\"):\n",
        "        if p == base_csv:\n",
        "            continue\n",
        "        try:\n",
        "            d2 = pd.read_csv(p)\n",
        "            for c in needed:\n",
        "                if c not in d2.columns:\n",
        "                    d2[c] = pd.NA\n",
        "            d2 = d2[needed]\n",
        "            for c in num_cols:\n",
        "                d2[c] = pd.to_numeric(d2[c], errors=\"coerce\")\n",
        "            df = pd.concat([df, d2], ignore_index=True)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "if df.empty:\n",
        "    raise ValueError(\"El dataframe de resultados está vacío.\")\n",
        "\n",
        "df = df.drop_duplicates(subset=[\"model\"], keep=\"last\").copy()\n",
        "\n",
        "def best_by(metric):\n",
        "    if metric not in df.columns or df[metric].dropna().empty:\n",
        "        return None\n",
        "    r = df.loc[df[metric].idxmax()]\n",
        "    print(\n",
        "        f\"- {metric}: {r['model']} | \"\n",
        "        f\"PR-AUC={safe(r['test_pr_auc'])} | \"\n",
        "        f\"ROC-AUC={safe(r['test_roc_auc'])} | \"\n",
        "        f\"F1={safe(r['test_f1'])} | \"\n",
        "        f\"Recall={safe(r['test_recall'])} | \"\n",
        "        f\"Precision={safe(r['test_precision'])} | \"\n",
        "        f\"thr(val)={safe(r['thr_val'], '.3f')} | \"\n",
        "        f\"best_iter={'NA'}\"\n",
        "    )\n",
        "    return r\n",
        "\n",
        "print(\"=== MEJORES EN TEST (por métrica) ===\")\n",
        "winners = {}\n",
        "for m in [\"test_pr_auc\",\"test_roc_auc\",\"test_recall\",\"test_f1\",\"test_precision\"]:\n",
        "    w = best_by(m)\n",
        "    if w is not None:\n",
        "        winners[m] = w\n",
        "\n",
        "cv_files = list(OUT_RESULTS.glob(\"cv_summary_*_CV*.csv\"))\n",
        "if cv_files:\n",
        "    print(\"=== RESUMEN CV-OOF (por experimento) ===\")\n",
        "    rows = []\n",
        "    for fcsv in cv_files:\n",
        "        tag = re.sub(r\"^cv_summary_|\\.csv$\", \"\", fcsv.name)\n",
        "        cv = pd.read_csv(fcsv)\n",
        "        oof = cv.loc[cv[\"fold\"] == \"OOF\"]\n",
        "        if not oof.empty:\n",
        "            r = oof.iloc[0]\n",
        "            rows.append({\n",
        "                \"tag\": tag,\n",
        "                \"pr_auc\": r.get(\"pr_auc\"),\n",
        "                \"roc_auc\": r.get(\"roc_auc\"),\n",
        "                \"f1\": r.get(\"f1\"),\n",
        "                \"recall\": r.get(\"recall\"),\n",
        "                \"bal_acc\": r.get(\"bal_acc\"),\n",
        "                \"thr\": r.get(\"thr\"),\n",
        "            })\n",
        "    if rows:\n",
        "        print(pd.DataFrame(rows).sort_values([\"pr_auc\",\"roc_auc\"], ascending=False).to_string(index=False))\n",
        "else:\n",
        "    print(\"(No se hallaron archivos de CV para este experimento)\")\n",
        "\n",
        "\n",
        "SOTA_RF = {\n",
        "    \"AUC\": None,       \n",
        "    \"Recall\": None,\n",
        "    \"Precision\": None,\n",
        "    \"source\": \"N/R\"\n",
        "}\n",
        "if SOTA_RF[\"AUC\"] is not None and \"test_roc_auc\" in winners and winners[\"test_roc_auc\"] is not None:\n",
        "    bt = winners[\"test_roc_auc\"]\n",
        "    d_auc = float(bt[\"test_roc_auc\"]) - SOTA_RF[\"AUC\"]\n",
        "    print(\"=== COMPARACIÓN SOTA RANDOM FOREST vs. MEJOR TEST ===\")\n",
        "    print(f\"Paper RF  : AUC={SOTA_RF['AUC']:.4f} | Recall={SOTA_RF['Recall'] or 'N/R'} | Precision={SOTA_RF['Precision'] or 'N/R'}\")\n",
        "    print(f\"Tu mejor  : AUC={safe(bt['test_roc_auc'])} | Recall={safe(bt['test_recall'])} | Precision={safe(bt['test_precision'])}\")\n",
        "    print(f\"Deltas    : ΔAUC={d_auc:+.4f}\")\n",
        "    print(f\"Fuente SOTA: {SOTA_RF['source']}\")\n",
        "\n",
        "backup = OUT_RESULTS / \"baselines_legacy_backup.csv\"\n",
        "if base_csv.exists():\n",
        "    base_csv.replace(backup)\n",
        "df.to_csv(base_csv, index=False)\n",
        "print(\"[OK] Normalizado. Backup:\", backup.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45ae37e3",
      "metadata": {},
      "source": [
        "11 — REPORTE FINAL DE SELECCIÓN DE FEATURES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "21eed5f4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== REPORTE FINAL DE SELECCIÓN DE FEATURES ===\n",
            "[L1] Total features originales: 15\n",
            "[L1] Features conservadas: 12\n",
            "[L1] Features eliminadas: 3\n",
            "\n",
            "Conservadas:\n",
            "['num__CreditScore', 'num__Age', 'num__Tenure', 'num__Balance', 'num__EstimatedSalary', 'Geography_1', 'Gender_1', 'HasCrCard_1', 'IsActiveMember_1', 'NumOfProducts_1', 'NumOfProducts_2', 'NumOfProducts_3']\n",
            "\n",
            "Eliminadas:\n",
            "['Geography_0', 'Geography_2', 'NumOfProducts_0']\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n=== REPORTE FINAL DE SELECCIÓN DE FEATURES ===\")\n",
        "if not USE_REDUCED or SELECTION_MODE == \"NONE\":\n",
        "    print(\"Selección: DESACTIVADA (se usaron todas las features).\")\n",
        "else:\n",
        "    mode_tag = (\"MI_top\" + str(MI_TOPK)) if SELECTION_MODE==\"MI\" else \"L1\"\n",
        "    mask_path = SEL_DIR / f\"keep_idx_{mode_tag}.npy\"\n",
        "    if not mask_path.exists():\n",
        "        print(f\"Aviso: no se encontró máscara en {mask_path}. ¿Ejecutaste la sección de selección?\")\n",
        "    else:\n",
        "        keep_idx = np.load(mask_path).astype(int).tolist()\n",
        "        kept_features = [feature_names[i] for i in keep_idx]\n",
        "        dropped_idx = sorted(set(range(len(feature_names))) - set(keep_idx))\n",
        "        dropped_features = [feature_names[i] for i in dropped_idx]\n",
        "\n",
        "        # Guardados\n",
        "        pd.DataFrame({\"feature\": kept_features}).to_csv(SEL_DIR / f\"final_kept_{mode_tag}.csv\", index=False)\n",
        "        pd.DataFrame({\"feature\": dropped_features}).to_csv(SEL_DIR / f\"final_dropped_{mode_tag}.csv\", index=False)\n",
        "\n",
        "        print(f\"[{mode_tag}] Total features originales: {len(feature_names)}\")\n",
        "        print(f\"[{mode_tag}] Features conservadas: {len(kept_features)}\")\n",
        "        print(f\"[{mode_tag}] Features eliminadas: {len(dropped_features)}\")\n",
        "        print(\"\\nConservadas:\")\n",
        "        print(kept_features)\n",
        "        print(\"\\nEliminadas:\")\n",
        "        print(dropped_features)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
