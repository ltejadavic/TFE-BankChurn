{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02112c0c",
   "metadata": {},
   "source": [
    "1) Importaciones, config y rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a8d045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] CWD: /Users/luistejada/Downloads/TFE Churn Bancario/Code\n",
      "[OK] DATA: /Users/luistejada/Downloads/TFE Churn Bancario/DataBase/Churn_Modelling.csv\n",
      "[OK] OUT : /Users/luistejada/Downloads/TFE Churn Bancario/preproc_datasets\n"
     ]
    }
   ],
   "source": [
    "import os, json, warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, OrdinalEncoder\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "# --- Config ---\n",
    "RANDOM_STATE = 42\n",
    "TARGET = \"Exited\"\n",
    "ID_COLS = [\"RowNumber\", \"CustomerId\", \"Surname\"]\n",
    "\n",
    "# Opciones del preprocesamiento\n",
    "Q_LOW, Q_HIGH = 0.01, 0.99                # winsorización por cuantiles\n",
    "TREAT_NUM_PRODUCTS_AS_CAT = True          # mover NumOfProducts a categórica\n",
    "K_TOP_INIT = 40                           # K inicial; se ajustará dinámicamente\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "DATA_CANDIDATES = [\n",
    "    ROOT / \"DataBase\" / \"Churn_Modelling.csv\",\n",
    "    Path.cwd() / \"Churn_Modelling.csv\",\n",
    "    ROOT / \"Churn_Modelling.csv\",\n",
    "]\n",
    "DATA_PATH = next((p for p in DATA_CANDIDATES if p.exists()), None)\n",
    "assert DATA_PATH is not None, \"No se encontró Churn_Modelling.csv en ../DataBase/ ni en Code/ ni en la raíz.\"\n",
    "\n",
    "OUT_DIR = ROOT / \"preproc_datasets\"\n",
    "(OUT_DIR / \"full\").mkdir(parents=True, exist_ok=True)\n",
    "(OUT_DIR / \"reduced\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"[OK] CWD: {Path.cwd()}\")\n",
    "print(f\"[OK] DATA: {DATA_PATH}\")\n",
    "print(f\"[OK] OUT : {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa584f00",
   "metadata": {},
   "source": [
    "2) Carga, saneo mínimo y descarte de IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a18ff4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>n_total</th>\n",
       "      <th>n_neg_0</th>\n",
       "      <th>n_pos_1</th>\n",
       "      <th>pos_ratio_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raw_full</td>\n",
       "      <td>10000</td>\n",
       "      <td>7963</td>\n",
       "      <td>2037</td>\n",
       "      <td>20.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>after_drop_ids</td>\n",
       "      <td>10000</td>\n",
       "      <td>7963</td>\n",
       "      <td>2037</td>\n",
       "      <td>20.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             step  n_total  n_neg_0  n_pos_1  pos_ratio_%\n",
       "0        raw_full    10000     7963     2037        20.37\n",
       "1  after_drop_ids    10000     7963     2037        20.37"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "assert TARGET in df.columns, f\"No existe la columna objetivo '{TARGET}'\"\n",
    "\n",
    "# row_id para poder mapear splits luego\n",
    "df = df.reset_index(drop=False).rename(columns={\"index\": \"row_id\"})\n",
    "\n",
    "def count_summary(name, y):\n",
    "    y = pd.Series(y)\n",
    "    tot = len(y); pos = int((y==1).sum()); neg = int((y==0).sum())\n",
    "    return {\"step\": name, \"n_total\": tot, \"n_neg_0\": neg, \"n_pos_1\": pos, \"pos_ratio_%\": round((pos/tot)*100, 2)}\n",
    "\n",
    "summaries = [count_summary(\"raw_full\", df[TARGET])]\n",
    "\n",
    "# Duplicados\n",
    "before = len(df)\n",
    "df = df.drop_duplicates()\n",
    "if len(df) != before:\n",
    "    summaries.append(count_summary(\"after_drop_duplicates\", df[TARGET]))\n",
    "\n",
    "# Eliminar IDs no informativos\n",
    "df = df.drop(columns=ID_COLS)\n",
    "summaries.append(count_summary(\"after_drop_ids\", df[TARGET]))\n",
    "\n",
    "pd.DataFrame(summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fc0b5b",
   "metadata": {},
   "source": [
    "3) Split estratificado 60/20/20 (train/val/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaae9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET].astype(int)\n",
    "\n",
    "# guardamos los index de row_id y eliminamos la columna\n",
    "row_id = df[\"row_id\"].copy()\n",
    "X = X.drop(columns=[\"row_id\"])\n",
    "\n",
    "X_temp, X_test, y_temp, y_test, rid_temp, rid_test = train_test_split(\n",
    "    X, y, row_id, test_size=0.20, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "X_train, X_val, y_train, y_val, rid_train, rid_val = train_test_split(\n",
    "    X_temp, y_temp, rid_temp, test_size=0.25, stratify=y_temp, random_state=RANDOM_STATE\n",
    ")  # 0.25 de 0.8 = 0.20\n",
    "\n",
    "summaries += [\n",
    "    count_summary(\"split_train\", y_train),\n",
    "    count_summary(\"split_val\",   y_val),\n",
    "    count_summary(\"split_test\",  y_test),\n",
    "]\n",
    "pd.DataFrame(summaries)\n",
    "\n",
    "# Guardar índices de split\n",
    "split_df = pd.concat([\n",
    "    pd.DataFrame({\"row_id\": rid_train, \"split\": \"train\"}),\n",
    "    pd.DataFrame({\"row_id\": rid_val,   \"split\": \"val\"}),\n",
    "    pd.DataFrame({\"row_id\": rid_test,  \"split\": \"test\"}),\n",
    "], ignore_index=True)\n",
    "split_df.to_csv(OUT_DIR / \"split_indices.csv\", index=False)\n",
    "\n",
    "# Guardar conteos por step\n",
    "pd.DataFrame(summaries).to_csv(OUT_DIR / \"class_counts_by_step.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20dc37b",
   "metadata": {},
   "source": [
    "4) Definir columnas num/cat y winsorizar solo con train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa502f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SELECTOR = make_column_selector(dtype_include=np.number)\n",
    "\n",
    "num_cols = list(NUM_SELECTOR(X_train))\n",
    "cat_cols = [c for c in X_train.columns if c not in num_cols]\n",
    "\n",
    "# Mover binarias a categóricas\n",
    "for b in [\"HasCrCard\", \"IsActiveMember\"]:\n",
    "    if b in num_cols:\n",
    "        num_cols.remove(b)\n",
    "    if b not in cat_cols and b in X_train.columns:\n",
    "        cat_cols.append(b)\n",
    "\n",
    "# Tratar NumOfProducts como categórica\n",
    "if TREAT_NUM_PRODUCTS_AS_CAT and \"NumOfProducts\" in num_cols:\n",
    "    num_cols.remove(\"NumOfProducts\")\n",
    "    if \"NumOfProducts\" not in cat_cols:\n",
    "        cat_cols.append(\"NumOfProducts\")\n",
    "\n",
    "# Winsorización por cuantiles (solo numéricas, calculado para train)\n",
    "q_bounds = {}\n",
    "for c in num_cols:\n",
    "    ql, qh = X_train[c].quantile(Q_LOW), X_train[c].quantile(Q_HIGH)\n",
    "    q_bounds[c] = (float(ql), float(qh))\n",
    "\n",
    "def clip_with_bounds(df_part, bounds):\n",
    "    df_part = df_part.copy()\n",
    "    for c, (ql, qh) in bounds.items():\n",
    "        df_part[c] = df_part[c].clip(lower=ql, upper=qh)\n",
    "    return df_part\n",
    "\n",
    "X_train_num = clip_with_bounds(X_train[num_cols], q_bounds)\n",
    "X_val_num   = clip_with_bounds(X_val[num_cols],   q_bounds)\n",
    "X_test_num  = clip_with_bounds(X_test[num_cols],  q_bounds)\n",
    "\n",
    "# Guardar límites de winsorización\n",
    "with open(OUT_DIR / \"winsor_bounds.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"q_low\": Q_LOW, \"q_high\": Q_HIGH, \"bounds\": q_bounds}, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb89976",
   "metadata": {},
   "source": [
    "5) OrdinalEncoder para variables categóricas (mapeo estable para SMOTENC) y construir DataFrames encodificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "549414f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OrdinalEncoder para categóricas (mapeo para SMOTENC)\n",
    "X_train_cat = X_train[cat_cols].astype(\"category\").copy()\n",
    "X_val_cat   = X_val[cat_cols].astype(\"category\").copy()\n",
    "X_test_cat  = X_test[cat_cols].astype(\"category\").copy()\n",
    "\n",
    "oenc = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "X_train_cat_enc = pd.DataFrame(oenc.fit_transform(X_train_cat), columns=cat_cols, index=X_train.index).astype(int)\n",
    "X_val_cat_enc   = pd.DataFrame(oenc.transform(X_val_cat),   columns=cat_cols, index=X_val.index).astype(int)\n",
    "X_test_cat_enc  = pd.DataFrame(oenc.transform(X_test_cat),  columns=cat_cols, index=X_test.index).astype(int)\n",
    "\n",
    "# DF finales encodificados combinando num y cat\n",
    "X_train_enc = pd.concat([X_train_num, X_train_cat_enc], axis=1)\n",
    "X_val_enc   = pd.concat([X_val_num,   X_val_cat_enc],   axis=1)\n",
    "X_test_enc  = pd.concat([X_test_num,  X_test_cat_enc],  axis=1)\n",
    "\n",
    "# Índices de columnas categóricas para SMOTENC\n",
    "cat_idx = list(range(len(num_cols), len(num_cols) + len(cat_cols)))\n",
    "\n",
    "# Guardar categorías del OrdinalEncoder\n",
    "ord_meta = {\n",
    "    \"ordinal_input_cols\": cat_cols,\n",
    "    \"ordinal_categories\": {col: [str(x) for x in cats] for col, cats in zip(cat_cols, oenc.categories_)}\n",
    "}\n",
    "with open(OUT_DIR / \"ordinal_encoder_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(ord_meta, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce490ff7",
   "metadata": {},
   "source": [
    "6) Conjunto Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c472533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (original): {'n': 6000, 'neg_0': 4777, 'pos_1': 1223, 'pos_%': 20.38}\n"
     ]
    }
   ],
   "source": [
    "def cls_counts(y):\n",
    "    y = pd.Series(y)\n",
    "    return {\"n\": len(y), \"neg_0\": int((y==0).sum()), \"pos_1\": int((y==1).sum()), \"pos_%\": round((y.mean())*100,2)}\n",
    "\n",
    "print(\"Train (original):\", cls_counts(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67845b0",
   "metadata": {},
   "source": [
    "7) RobustScaler (variables numéricas) + OneHotEncoder (cat, drop=\"if_binary\") y transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69bde434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes FULL: (6000, 15) (2000, 15) (2000, 15)\n",
      "N features: 15\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ohe = OneHotEncoder(drop=\"if_binary\", handle_unknown=\"ignore\", sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(drop=\"if_binary\", handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", RobustScaler(), list(num_cols)),\n",
    "        (\"cat\", ohe,            list(cat_cols)),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Ajustar SIEMPRE con train para evitar sesgos de categorías\n",
    "preprocessor.fit(X_train_enc)\n",
    "\n",
    "# Transformaciones sin reducción (FULL)\n",
    "X_train_full = preprocessor.transform(X_train_enc)\n",
    "X_val_full   = preprocessor.transform(X_val_enc)\n",
    "X_test_full  = preprocessor.transform(X_test_enc)\n",
    "\n",
    "# Nombres de columnas FULL\n",
    "feature_names = []\n",
    "if num_cols:\n",
    "    feature_names += [f\"num__{c}\" for c in num_cols]\n",
    "if cat_cols:\n",
    "    feature_names += list(preprocessor.named_transformers_[\"cat\"].get_feature_names_out(cat_cols))\n",
    "\n",
    "print(\"Shapes FULL:\", X_train_full.shape, X_val_full.shape, X_test_full.shape)\n",
    "print(\"N features:\", len(feature_names))\n",
    "\n",
    "# Metadatos OHE\n",
    "ohe_meta = {\n",
    "    \"ohe_input_cols\": list(cat_cols),\n",
    "    \"ohe_categories\": {col: [int(x) if isinstance(x, (np.integer, int)) else str(x)\n",
    "                             for x in cats]\n",
    "                       for col, cats in zip(cat_cols, preprocessor.named_transformers_[\"cat\"].categories_)}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aca1cd",
   "metadata": {},
   "source": [
    "8) Guardado versión FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28aebd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Exportada versión FULL\n"
     ]
    }
   ],
   "source": [
    "full_dir = OUT_DIR / \"full\"\n",
    "full_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Matrices FULL\n",
    "np.save(full_dir / \"X_train_full.npy\", X_train_full)\n",
    "np.save(full_dir / \"X_val_full.npy\",   X_val_full)\n",
    "np.save(full_dir / \"X_test_full.npy\",  X_test_full)\n",
    "\n",
    "# Etiquetas\n",
    "pd.DataFrame({\"Exited\": y_train}).to_parquet(full_dir / \"y_train.parquet\", index=False)\n",
    "pd.DataFrame({\"Exited\": y_val}).to_parquet(full_dir / \"y_val.parquet\",   index=False)\n",
    "pd.DataFrame({\"Exited\": y_test}).to_parquet(full_dir / \"y_test.parquet\",  index=False)\n",
    "\n",
    "# Nombres de features\n",
    "pd.DataFrame({\"feature\": feature_names}).to_parquet(full_dir / \"feature_names_full.parquet\", index=False)\n",
    "\n",
    "# Metadatos del preprocesador\n",
    "preproc_meta = {\n",
    "    \"num_cols\": list(num_cols),\n",
    "    \"cat_cols\": list(cat_cols),\n",
    "    \"n_features_full\": int(len(feature_names)),\n",
    "    \"winsor_bounds_path\": str(OUT_DIR / \"winsor_bounds.json\"),\n",
    "    \"split_indices_path\": str(OUT_DIR / \"split_indices.csv\"),\n",
    "    \"treat_num_products_as_cat\": bool(TREAT_NUM_PRODUCTS_AS_CAT),\n",
    "    \"ordinal_encoder_meta_path\": str(OUT_DIR / \"ordinal_encoder_meta.json\"),\n",
    "    \"ohe_meta\": ohe_meta,\n",
    "}\n",
    "with open(full_dir / \"preprocessor_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(preproc_meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"[OK] Exportada versión FULL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e244e774",
   "metadata": {},
   "source": [
    "9) Chequeo rápido de conteos finales para el reporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bac2c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>n</th>\n",
       "      <th>pos_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>6000</td>\n",
       "      <td>20.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val</td>\n",
       "      <td>2000</td>\n",
       "      <td>20.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>2000</td>\n",
       "      <td>20.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     set     n  pos_%\n",
       "0  train  6000  20.38\n",
       "1    val  2000  20.35\n",
       "2   test  2000  20.35"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quick_counts_df():\n",
    "    return pd.DataFrame([\n",
    "        {\"set\": \"train\", \"n\": len(y_train), \"pos_%\": round(y_train.mean()*100,2)},\n",
    "        {\"set\": \"val\",   \"n\": len(y_val),   \"pos_%\": round(y_val.mean()*100,2)},\n",
    "        {\"set\": \"test\",  \"n\": len(y_test),  \"pos_%\": round(y_test.mean()*100,2)},\n",
    "    ])\n",
    "\n",
    "quick_counts_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb043577",
   "metadata": {},
   "source": [
    "10 -  χ² por dummy OHE (solo TRAIN) con FDR-BH y guardado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ed0fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] χ² guardado en /Users/luistejada/Downloads/TFE Churn Bancario/preproc_datasets/feature_tests/chi2_train_dummies.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_dummy</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p_value</th>\n",
       "      <th>p_adj_fdr_bh</th>\n",
       "      <th>significant_fdr_bh</th>\n",
       "      <th>orig_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NumOfProducts_2</td>\n",
       "      <td>403.369566</td>\n",
       "      <td>1.017255e-89</td>\n",
       "      <td>1.017255e-88</td>\n",
       "      <td>True</td>\n",
       "      <td>NumOfProducts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumOfProducts_1</td>\n",
       "      <td>290.724650</td>\n",
       "      <td>3.456704e-65</td>\n",
       "      <td>1.728352e-64</td>\n",
       "      <td>True</td>\n",
       "      <td>NumOfProducts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NumOfProducts_3</td>\n",
       "      <td>152.332788</td>\n",
       "      <td>5.359115e-35</td>\n",
       "      <td>1.786372e-34</td>\n",
       "      <td>True</td>\n",
       "      <td>NumOfProducts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geography_1</td>\n",
       "      <td>136.360222</td>\n",
       "      <td>1.664262e-31</td>\n",
       "      <td>4.160654e-31</td>\n",
       "      <td>True</td>\n",
       "      <td>Geography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NumOfProducts_0</td>\n",
       "      <td>104.512356</td>\n",
       "      <td>1.562162e-24</td>\n",
       "      <td>3.124323e-24</td>\n",
       "      <td>True</td>\n",
       "      <td>NumOfProducts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IsActiveMember_1</td>\n",
       "      <td>73.791451</td>\n",
       "      <td>8.682181e-18</td>\n",
       "      <td>1.447030e-17</td>\n",
       "      <td>True</td>\n",
       "      <td>IsActiveMember</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gender_1</td>\n",
       "      <td>35.695261</td>\n",
       "      <td>2.307245e-09</td>\n",
       "      <td>3.296065e-09</td>\n",
       "      <td>True</td>\n",
       "      <td>Gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geography_0</td>\n",
       "      <td>29.986503</td>\n",
       "      <td>4.350640e-08</td>\n",
       "      <td>5.438300e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>Geography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geography_2</td>\n",
       "      <td>15.630171</td>\n",
       "      <td>7.701589e-05</td>\n",
       "      <td>8.557321e-05</td>\n",
       "      <td>True</td>\n",
       "      <td>Geography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HasCrCard_1</td>\n",
       "      <td>0.760384</td>\n",
       "      <td>3.832085e-01</td>\n",
       "      <td>3.832085e-01</td>\n",
       "      <td>False</td>\n",
       "      <td>HasCrCard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_dummy        chi2       p_value  p_adj_fdr_bh  \\\n",
       "8   NumOfProducts_2  403.369566  1.017255e-89  1.017255e-88   \n",
       "7   NumOfProducts_1  290.724650  3.456704e-65  1.728352e-64   \n",
       "9   NumOfProducts_3  152.332788  5.359115e-35  1.786372e-34   \n",
       "1       Geography_1  136.360222  1.664262e-31  4.160654e-31   \n",
       "6   NumOfProducts_0  104.512356  1.562162e-24  3.124323e-24   \n",
       "5  IsActiveMember_1   73.791451  8.682181e-18  1.447030e-17   \n",
       "3          Gender_1   35.695261  2.307245e-09  3.296065e-09   \n",
       "0       Geography_0   29.986503  4.350640e-08  5.438300e-08   \n",
       "2       Geography_2   15.630171  7.701589e-05  8.557321e-05   \n",
       "4       HasCrCard_1    0.760384  3.832085e-01  3.832085e-01   \n",
       "\n",
       "   significant_fdr_bh    orig_feature  \n",
       "8                True   NumOfProducts  \n",
       "7                True   NumOfProducts  \n",
       "9                True   NumOfProducts  \n",
       "1                True       Geography  \n",
       "6                True   NumOfProducts  \n",
       "5                True  IsActiveMember  \n",
       "3                True          Gender  \n",
       "0                True       Geography  \n",
       "2                True       Geography  \n",
       "4               False       HasCrCard  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === χ² sobre dummies OHE ===\n",
    "import numpy as np, pandas as pd, json, os\n",
    "from pathlib import Path\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "try:\n",
    "    OUT_DIR \n",
    "    full_dir = OUT_DIR / \"full\"\n",
    "except NameError:\n",
    "    ROOT = Path.cwd().parent\n",
    "    OUT_DIR = ROOT / \"preproc_datasets\"\n",
    "    full_dir = OUT_DIR / \"full\"\n",
    "\n",
    "assert full_dir.exists(), f\"No se encontró {full_dir}. Revisa la ruta.\"\n",
    "\n",
    "# Cargar matrices/labels/feature names guardados\n",
    "X_train_full = np.load(full_dir / \"X_train_full.npy\")\n",
    "y_train = pd.read_parquet(full_dir / \"y_train.parquet\")[\"Exited\"].astype(int)\n",
    "feature_names = pd.read_parquet(full_dir / \"feature_names_full.parquet\")[\"feature\"].tolist()\n",
    "\n",
    "Xtr_full_df = pd.DataFrame(X_train_full, columns=feature_names)\n",
    "\n",
    "# Dummies OHE = todas las columnas que NO son numéricas escaladas (que empiezan con 'num__')\n",
    "cat_like = [c for c in Xtr_full_df.columns if not c.startswith(\"num__\")]\n",
    "\n",
    "# Asegurar binariedad para χ² (0/1). Si alguna no es estrictamente 0/1, la redondeamos.\n",
    "def is_binary(col):\n",
    "    vals = pd.unique(Xtr_full_df[col])\n",
    "    return len(vals) <= 2 and set(np.round(vals, 6)).issubset({0.0, 1.0})\n",
    "\n",
    "dummy_cols = []\n",
    "for c in cat_like:\n",
    "    if not is_binary(c):\n",
    "        # redondeo defensivo por si hay valores 0/1 en float\n",
    "        Xtr_full_df[c] = np.round(Xtr_full_df[c]).clip(0,1)\n",
    "    if is_binary(c):\n",
    "        dummy_cols.append(c)\n",
    "\n",
    "Xtr_dum = Xtr_full_df[dummy_cols].astype(float)\n",
    "\n",
    "# --- Benjamini–Hochberg (FDR) ---\n",
    "def fdr_bh(pvals, alpha=0.05):\n",
    "    p = np.asarray(pvals, dtype=float)\n",
    "    m = p.size\n",
    "    order = np.argsort(p)\n",
    "    p_sorted = p[order]\n",
    "    p_adj_sorted = p_sorted * m / np.arange(1, m+1)\n",
    "    p_adj_sorted = np.minimum.accumulate(p_adj_sorted[::-1])[::-1]\n",
    "    p_adj = np.empty_like(p_adj_sorted)\n",
    "    p_adj[order] = p_adj_sorted\n",
    "    rej = p_adj <= alpha\n",
    "    return p_adj, rej\n",
    "\n",
    "# χ²\n",
    "chi2_stats, pvals = chi2(Xtr_dum, y_train.to_numpy())\n",
    "p_adj, rej = fdr_bh(pvals, alpha=0.05)\n",
    "\n",
    "chi_df = (pd.DataFrame({\n",
    "    \"feature_dummy\": dummy_cols,\n",
    "    \"chi2\": chi2_stats,\n",
    "    \"p_value\": pvals,\n",
    "    \"p_adj_fdr_bh\": p_adj,\n",
    "    \"significant_fdr_bh\": rej\n",
    "}))\n",
    "\n",
    "# Variable original\n",
    "def orig_var(name):\n",
    "    return name.split(\"_\", 1)[0] if \"_\" in name else name\n",
    "\n",
    "chi_df[\"orig_feature\"] = chi_df[\"feature_dummy\"].map(orig_var)\n",
    "chi_df = chi_df.sort_values([\"p_adj_fdr_bh\",\"feature_dummy\"])\n",
    "\n",
    "# Guardado\n",
    "out_dir = OUT_DIR / \"feature_tests\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "chi_path = out_dir / \"chi2_train_dummies.csv\"\n",
    "chi_df.to_csv(chi_path, index=False)\n",
    "print(f\"[OK] χ² guardado en {chi_path}\")\n",
    "display(chi_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87817157",
   "metadata": {},
   "source": [
    "11 - Cramér’s V por variable categórica + resumen por variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "022f159d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Cramér’s V -> /Users/luistejada/Downloads/TFE Churn Bancario/preproc_datasets/feature_tests/cramers_v_train.csv\n",
      "[OK] Resumen por variable -> /Users/luistejada/Downloads/TFE Churn Bancario/preproc_datasets/feature_tests/summary_chi2_per_variable.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_feature</th>\n",
       "      <th>min_q</th>\n",
       "      <th>n_sig</th>\n",
       "      <th>n_dummies</th>\n",
       "      <th>cramers_v</th>\n",
       "      <th>n_levels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NumOfProducts</td>\n",
       "      <td>1.017255e-88</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.397512</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geography</td>\n",
       "      <td>4.160654e-31</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.173208</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IsActiveMember</td>\n",
       "      <td>1.447030e-17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.158813</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gender</td>\n",
       "      <td>3.296065e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.113752</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HasCrCard</td>\n",
       "      <td>3.832085e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016427</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     orig_feature         min_q  n_sig  n_dummies  cramers_v  n_levels\n",
       "4   NumOfProducts  1.017255e-88      4          4   0.397512         4\n",
       "1       Geography  4.160654e-31      3          3   0.173208         3\n",
       "3  IsActiveMember  1.447030e-17      1          1   0.158813         2\n",
       "0          Gender  3.296065e-09      1          1   0.113752         2\n",
       "2       HasCrCard  3.832085e-01      0          1   0.016427         2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "groups = defaultdict(list)\n",
    "for col in Xtr_full_df.columns:\n",
    "    if col.startswith(\"num__\"):\n",
    "        continue\n",
    "    base = col.split(\"_\", 1)[0] if \"_\" in col else col\n",
    "    groups[base].append(col)\n",
    "\n",
    "# Cramér’s V corregido\n",
    "def cramers_v_corrected(contingency_df):\n",
    "    chi2_stat, _, _, _ = chi2_contingency(contingency_df, correction=False)\n",
    "    n = contingency_df.to_numpy().sum()\n",
    "    r, k = contingency_df.shape\n",
    "    if n <= 1:\n",
    "        return 0.0\n",
    "    phi2 = chi2_stat / n\n",
    "    # corrección de bias\n",
    "    phi2_corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    r_corr = r - ((r-1)**2)/(n-1)\n",
    "    k_corr = k - ((k-1)**2)/(n-1)\n",
    "    denom = min((k_corr-1), (r_corr-1))\n",
    "    return 0.0 if denom <= 0 else np.sqrt(phi2_corr / denom)\n",
    "\n",
    "rows = []\n",
    "reconstructed = {}\n",
    "\n",
    "for var, cols in groups.items():\n",
    "    mat = Xtr_full_df[cols].to_numpy()\n",
    "    if mat.shape[1] > 1:\n",
    "        idx = mat.argmax(axis=1)\n",
    "        levels = [c.split(\"_\",1)[1] if \"_\" in c else c for c in cols]\n",
    "        labels = pd.Categorical([levels[i] for i in idx], categories=levels)\n",
    "    else:\n",
    "        col = cols[0]\n",
    "        level = col.split(\"_\",1)[1] if \"_\" in col else \"1\"\n",
    "        labels = pd.Categorical(np.where(Xtr_full_df[col] >= 0.5, level, f\"not_{level}\"))\n",
    "\n",
    "    reconstructed[var] = pd.Series(labels, index=Xtr_full_df.index, name=var)\n",
    "    tab = pd.crosstab(reconstructed[var], y_train)\n",
    "    v = cramers_v_corrected(tab)\n",
    "    rows.append({\"orig_feature\": var, \"cramers_v\": v, \"n_levels\": tab.shape[0]})\n",
    "\n",
    "cramer_df = pd.DataFrame(rows).sort_values(\"cramers_v\", ascending=False)\n",
    "\n",
    "# Resumen por variable combinando χ²\n",
    "out_dir = OUT_DIR / \"feature_tests\"\n",
    "chi_df = pd.read_csv(out_dir / \"chi2_train_dummies.csv\")\n",
    "\n",
    "sum_df = (chi_df.groupby(\"orig_feature\", as_index=False)\n",
    "                .agg(min_q=(\"p_adj_fdr_bh\",\"min\"),\n",
    "                     n_sig=(\"significant_fdr_bh\",\"sum\"),\n",
    "                     n_dummies=(\"feature_dummy\",\"count\"))\n",
    "         ).merge(cramer_df, on=\"orig_feature\", how=\"left\") \\\n",
    "          .sort_values([\"min_q\",\"cramers_v\"])\n",
    "\n",
    "# Guardar\n",
    "cramer_path = out_dir / \"cramers_v_train.csv\"\n",
    "summary_path = out_dir / \"summary_chi2_per_variable.csv\"\n",
    "cramer_df.to_csv(cramer_path, index=False)\n",
    "sum_df.to_csv(summary_path, index=False)\n",
    "print(f\"[OK] Cramér’s V -> {cramer_path}\")\n",
    "print(f\"[OK] Resumen por variable -> {summary_path}\")\n",
    "\n",
    "display(sum_df.head(15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
