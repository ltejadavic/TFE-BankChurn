{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# LGBM — Dataset Reducido con Selección de Características (CV Permutation Importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec1",
   "metadata": {},
   "source": [
    "## 1 — Imports, configuración y rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp: LGBM_REDUCED_PERMcv_thr_SMOTENC\n",
      "DATA_DIR: /Users/luistejada/Downloads/TFE Churn Bancario/preproc_datasets/full\n",
      "ARTIF_DIR: /Users/luistejada/Downloads/TFE Churn Bancario/artifacts/LGBM_REDUCED_PERMcv_thr_SMOTENC\n"
     ]
    }
   ],
   "source": [
    "import json, os, warnings, re\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score, precision_recall_curve, roc_auc_score, roc_curve,\n",
    "    f1_score, recall_score, balanced_accuracy_score, confusion_matrix, precision_score\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Balanceo\n",
    "from imblearn.over_sampling import SMOTENC, SMOTE\n",
    "\n",
    "# LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "try:\n",
    "    from lightgbm import early_stopping, log_evaluation\n",
    "    _LGBM_CB_OK = True\n",
    "except Exception:\n",
    "    _LGBM_CB_OK = False\n",
    "\n",
    "# === Toggles de experimento ===\n",
    "USE_MI_REDUCED     = False\n",
    "USE_PCA_REDUCED    = False\n",
    "USE_PERM_REDUCED   = True\n",
    "PERM_N_REPEATS     = 20\n",
    "PERM_TOPK          = None\n",
    "PERM_MIN_DELTA     = 0.0\n",
    "\n",
    "# --- Vista de reducción por L1 ---\n",
    "USE_L1_REDUCED     = False\n",
    "L1_C               = 0.8\n",
    "L1_TOPK            = None\n",
    "L1_MIN_ABS_COEF    = 1e-6\n",
    "L1_STANDARDIZE     = True\n",
    "\n",
    "MI_TOPK            = 30\n",
    "PCA_NCOMP          = 50\n",
    "USE_BALANCED_TRAIN = True\n",
    "BALANCE_IN_CV      = True\n",
    "RANDOM_STATE       = 42\n",
    "DO_TUNE            = True\n",
    "DO_CV_BASELINE     = True\n",
    "DO_CV_TUNED        = True\n",
    "CV_FOLDS           = 5\n",
    "\n",
    "# === Nombres y rutas ===\n",
    "ROOT = Path.cwd().parent\n",
    "\n",
    "red_tag = \"FULL\"\n",
    "if USE_MI_REDUCED:\n",
    "    red_tag = f\"REDUCED_MI{MI_TOPK}\"\n",
    "elif USE_PCA_REDUCED:\n",
    "    red_tag = f\"REDUCED_PCA{PCA_NCOMP}\"\n",
    "elif USE_PERM_REDUCED:\n",
    "    red_tag = f\"REDUCED_PERMcv_{PERM_TOPK if PERM_TOPK else 'thr'}\"\n",
    "elif USE_L1_REDUCED:\n",
    "    red_tag = f\"REDUCED_L1_{('top'+str(L1_TOPK)) if L1_TOPK is not None else 'thr'}\"\n",
    "\n",
    "bal_tag = \"SMOTENC\" if USE_BALANCED_TRAIN else \"IMB\"\n",
    "\n",
    "EXP_NAME   = f\"LGBM_{red_tag}_{bal_tag}\"\n",
    "ARTIF_DIR  = ROOT / \"artifacts\" / EXP_NAME\n",
    "OUT_RESULTS = ARTIF_DIR / \"results\"\n",
    "OUT_FIGS    = ARTIF_DIR / \"figs\"\n",
    "OUT_PREDS   = ARTIF_DIR / \"preds\"\n",
    "OUT_PARAMS  = ARTIF_DIR / \"best_params\"\n",
    "for p in [OUT_RESULTS, OUT_FIGS, OUT_PREDS, OUT_PARAMS]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Dataset preprocesado\n",
    "DATA_DIR = ROOT / \"preproc_datasets\" / \"full\"\n",
    "\n",
    "# === Helpers para SMOTENC con metadatos de features ===\n",
    "def cat_indices_from_feature_names(names):\n",
    "    \"\"\"\n",
    "    Devuelve los índices de columnas categóricas según convención de nombres.\n",
    "    Se asume OHE con prefijo 'cat__' para variables categóricas.\n",
    "    \"\"\"\n",
    "    return np.array([i for i, n in enumerate(names) if isinstance(n, str) and n.startswith(\"cat__\")], dtype=int)\n",
    "\n",
    "def resample_smote_nc(X, y, feat_names, seed=RANDOM_STATE):\n",
    "    \"\"\"\n",
    "    Aplica SMOTENC usando índices categóricos derivados de feat_names.\n",
    "    Si no hay columnas categóricas (p.ej., tras PCA), cae a SMOTE estándar.\n",
    "    \"\"\"\n",
    "    cats = cat_indices_from_feature_names(feat_names)\n",
    "    if cats.size > 0:\n",
    "        sampler = SMOTENC(categorical_features=cats, random_state=seed)\n",
    "    else:\n",
    "        sampler = SMOTE(random_state=seed)\n",
    "    return sampler.fit_resample(X, y)\n",
    "\n",
    "print(\"Exp:\", EXP_NAME)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"ARTIF_DIR:\", ARTIF_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec2",
   "metadata": {},
   "source": [
    "## 2 — Carga de artefactos (X, y, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "loadxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (6000, 15) (2000, 15) (2000, 15)\n",
      "y train/val/test: (6000,) (2000,) (2000,)\n",
      "n features: 15\n"
     ]
    }
   ],
   "source": [
    "def load_xy_full(dir_full: Path):\n",
    "    X_train = np.load(dir_full / \"X_train_full.npy\")\n",
    "    X_val   = np.load(dir_full / \"X_val_full.npy\")\n",
    "    X_test  = np.load(dir_full / \"X_test_full.npy\")\n",
    "\n",
    "    y_train = pd.read_parquet(dir_full / \"y_train.parquet\")[\"Exited\"].to_numpy()\n",
    "    y_val   = pd.read_parquet(dir_full / \"y_val.parquet\")[\"Exited\"].to_numpy()\n",
    "    y_test  = pd.read_parquet(dir_full / \"y_test.parquet\")[\"Exited\"].to_numpy()\n",
    "\n",
    "    feat = pd.read_parquet(dir_full / \"feature_names_full.parquet\")[\"feature\"].tolist()\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, feat\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, feature_names_all = load_xy_full(DATA_DIR)\n",
    "print(\"Shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "print(\"y train/val/test:\", y_train.shape, y_val.shape, y_test.shape)\n",
    "print(\"n features:\", len(feature_names_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec3",
   "metadata": {},
   "source": [
    "## 3 — Métricas y selección de umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_auc(y_true, y_proba): \n",
    "    return float(average_precision_score(y_true, y_proba))\n",
    "\n",
    "def roc_auc(y_true, y_proba): \n",
    "    return float(roc_auc_score(y_true, y_proba))\n",
    "\n",
    "def find_best_threshold(y_true, y_proba, metric=\"f1\"):\n",
    "    thr_grid = np.linspace(0.0, 1.0, 1001)\n",
    "    best_thr, best_score = 0.5, -1.0\n",
    "    for thr in thr_grid:\n",
    "        y_pred = (y_proba >= thr).astype(int)\n",
    "        if metric == \"f1\":\n",
    "            score = f1_score(y_true, y_pred, zero_division=0)\n",
    "        elif metric == \"recall\":\n",
    "            score = recall_score(y_true, y_pred, zero_division=0)\n",
    "        else:\n",
    "            raise ValueError(\"metric no soportada\")\n",
    "        if score > best_score:\n",
    "            best_score, best_thr = score, thr\n",
    "    return float(best_thr), float(best_score)\n",
    "\n",
    "def compute_all_metrics(y_true, y_proba, thr):\n",
    "    y_pred = (y_proba >= thr).astype(int)\n",
    "    return {\n",
    "        \"pr_auc\": pr_auc(y_true, y_proba),\n",
    "        \"roc_auc\": roc_auc(y_true, y_proba),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"bal_acc\": balanced_accuracy_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "def sanitize_params(p, use_balanced_train=True):\n",
    "    p = dict(p)\n",
    "    p.pop(\"verbose\", None)\n",
    "    p.setdefault(\"verbosity\", -1)\n",
    "    p[\"metric\"] = \"average_precision\"\n",
    "    if use_balanced_train:\n",
    "        p[\"class_weight\"] = None\n",
    "    return p\n",
    "\n",
    "def pred_proba_best(mdl, X):\n",
    "    it = getattr(mdl, \"best_iteration_\", None)\n",
    "    if it is not None:\n",
    "        return mdl.predict_proba(X, num_iteration=it)[:, 1]\n",
    "    return mdl.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec4",
   "metadata": {},
   "source": [
    "## 4 — Reducción por MI Top-K y Permutation CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_mi_selector(X_tr, y_tr, topk=MI_TOPK, seed=RANDOM_STATE):\n",
    "    mi = mutual_info_classif(X_tr, y_tr, random_state=seed)\n",
    "    order = np.argsort(mi)[::-1][:min(topk, X_tr.shape[1])]\n",
    "    return order, mi\n",
    "\n",
    "def apply_keep_idx(X, keep_idx):\n",
    "    return X[:, keep_idx] if keep_idx is not None else X\n",
    "\n",
    "# --- Selección L1 (Lasso) con LogisticRegression ---\n",
    "def fit_l1_selector(\n",
    "    X, y, feat_names,\n",
    "    C=L1_C,\n",
    "    standardize=L1_STANDARDIZE,\n",
    "    topk=L1_TOPK,\n",
    "    min_abs_coef=L1_MIN_ABS_COEF,\n",
    "    seed=RANDOM_STATE\n",
    "):\n",
    "\n",
    "    X = np.asarray(X); y = np.asarray(y).ravel()\n",
    "\n",
    "    X_fit = X\n",
    "    scaler = None\n",
    "    if standardize:\n",
    "        scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "        X_fit = scaler.fit_transform(X)\n",
    "\n",
    "    logreg = LogisticRegression(\n",
    "        penalty=\"l1\", solver=\"liblinear\", C=C,\n",
    "        max_iter=2000, random_state=seed\n",
    "    )\n",
    "    logreg.fit(X_fit, y)\n",
    "    coefs = logreg.coef_.ravel()\n",
    "    abs_coefs = np.abs(coefs)\n",
    "\n",
    "    if topk is not None:\n",
    "        order = np.argsort(abs_coefs)[::-1]\n",
    "        order = [i for i in order if abs_coefs[i] > min_abs_coef][:min(topk, X.shape[1])]\n",
    "        keep_idx = np.array(order, dtype=int)\n",
    "    else:\n",
    "        keep_idx = np.where(abs_coefs > float(min_abs_coef))[0].astype(int)\n",
    "\n",
    "    kept_names    = [feat_names[i] for i in keep_idx]\n",
    "    dropped_idx   = np.array([i for i in range(len(feat_names)) if i not in set(keep_idx)], dtype=int)\n",
    "    dropped_names = [feat_names[i] for i in dropped_idx]\n",
    "\n",
    "    df_coef = (\n",
    "        pd.DataFrame({\"feature\": feat_names, \"coef\": coefs, \"abs_coef\": abs_coefs})\n",
    "        .sort_values(\"abs_coef\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    df_coef[\"kept\"] = df_coef[\"feature\"].isin(kept_names)\n",
    "\n",
    "    stats = {\n",
    "        \"kept_names\": kept_names,\n",
    "        \"dropped_names\": dropped_names,\n",
    "        \"df\": df_coef,\n",
    "        \"C\": C,\n",
    "        \"standardize\": bool(standardize),\n",
    "        \"topk\": topk,\n",
    "        \"min_abs_coef\": float(min_abs_coef),\n",
    "    }\n",
    "    return keep_idx, stats\n",
    "\n",
    "def fit_perm_selector_cv(\n",
    "    X, y, feat_names,\n",
    "    k_folds=CV_FOLDS,\n",
    "    n_repeats=PERM_N_REPEATS,\n",
    "    seed=RANDOM_STATE,\n",
    "    topk=PERM_TOPK,\n",
    "    min_delta=PERM_MIN_DELTA\n",
    "):\n",
    "\n",
    "    X = np.asarray(X); y = np.asarray(y).ravel()\n",
    "    skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    base_params = dict(\n",
    "        random_state=seed, n_estimators=1200, learning_rate=0.05,\n",
    "        num_leaves=63, n_jobs=-1, metric=\"average_precision\", verbosity=-1\n",
    "    )\n",
    "\n",
    "    _fit_kwargs_local = {}\n",
    "    _callbacks_local = []\n",
    "    if _LGBM_CB_OK:\n",
    "        _callbacks_local = [early_stopping(stopping_rounds=200), log_evaluation(period=50)]\n",
    "    else:\n",
    "        _fit_kwargs_local[\"early_stopping_rounds\"] = 200\n",
    "\n",
    "    imps = []\n",
    "\n",
    "    for f, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
    "        X_tr, X_va = X[tr_idx], X[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "        # === Balanceo con SMOTENC ===\n",
    "        if USE_BALANCED_TRAIN and BALANCE_IN_CV:\n",
    "            X_tr, y_tr = resample_smote_nc(X_tr, y_tr, feat_names, seed=seed)\n",
    "\n",
    "        mdl = LGBMClassifier(**base_params)\n",
    "        fit_call = dict(eval_set=[(X_va, y_va)], eval_metric=\"aucpr\", **_fit_kwargs_local)\n",
    "        if _LGBM_CB_OK:\n",
    "            fit_call[\"callbacks\"] = _callbacks_local\n",
    "        mdl.fit(X_tr, y_tr, **fit_call)\n",
    "\n",
    "        pi = permutation_importance(\n",
    "            mdl, X_va, y_va,\n",
    "            scoring=\"average_precision\",\n",
    "            n_repeats=n_repeats,\n",
    "            random_state=seed + f\n",
    "        )\n",
    "        imps.append(pi.importances_mean)\n",
    "\n",
    "    imp_mean = np.mean(np.vstack(imps), axis=0)\n",
    "    order = np.argsort(imp_mean)[::-1]\n",
    "\n",
    "    if topk is not None:\n",
    "        keep_idx = order[:min(topk, X.shape[1])]\n",
    "    else:\n",
    "        keep_idx = np.array([i for i in order if imp_mean[i] > float(min_delta)], dtype=int)\n",
    "\n",
    "    kept_names    = [feat_names[i] for i in keep_idx]\n",
    "    dropped_idx   = np.array([i for i in range(len(feat_names)) if i not in set(keep_idx)], dtype=int)\n",
    "    dropped_names = [feat_names[i] for i in dropped_idx]\n",
    "\n",
    "    df_imp = (\n",
    "        pd.DataFrame({\"feature\": feat_names, \"imp_mean\": imp_mean})\n",
    "        .sort_values(\"imp_mean\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    df_imp[\"kept\"] = df_imp[\"feature\"].isin(kept_names)\n",
    "\n",
    "    stats = {\n",
    "        \"imp_mean\": imp_mean.tolist(),\n",
    "        \"kept_names\": kept_names,\n",
    "        \"dropped_names\": dropped_names,\n",
    "        \"df\": df_imp\n",
    "    }\n",
    "    return keep_idx, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec5",
   "metadata": {},
   "source": [
    "## 5 — Reducción por PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "hps",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = None\n",
    "def apply_pca_fit_transform(X_tr, X_va, X_te, n_comp=PCA_NCOMP, seed=RANDOM_STATE):\n",
    "    global pca_model\n",
    "    pca_model = PCA(n_components=n_comp, random_state=seed)\n",
    "    Xtr = pca_model.fit_transform(X_tr)\n",
    "    Xva = pca_model.transform(X_va)\n",
    "    Xte = pca_model.transform(X_te)\n",
    "    comp_names = [f\"PC{i+1}\" for i in range(pca_model.n_components_)]\n",
    "    return Xtr, Xva, Xte, comp_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec6",
   "metadata": {},
   "source": [
    "## 6 — Hiperparámetros persistentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "select_apply",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HP] Cargando mejores hiperparámetros previos: BEST_LGBM_REDUCED_PERMcv_thr_SMOTENC.json\n"
     ]
    }
   ],
   "source": [
    "VIEW_TAG = \"FULL\"\n",
    "if USE_MI_REDUCED:   VIEW_TAG = f\"REDUCED_MI{MI_TOPK}\"\n",
    "if USE_PCA_REDUCED:  VIEW_TAG = f\"REDUCED_PCA{PCA_NCOMP}\"\n",
    "if USE_PERM_REDUCED: VIEW_TAG = f\"REDUCED_PERMcv_{PERM_TOPK if PERM_TOPK else 'thr'}\"\n",
    "if USE_L1_REDUCED:   VIEW_TAG = f\"REDUCED_L1_{('top'+str(L1_TOPK)) if L1_TOPK is not None else 'thr'}\"\n",
    "\n",
    "BAL_TAG  = \"SMOTENC\" if USE_BALANCED_TRAIN else \"IMB\"\n",
    "BEST_HP_FILE = OUT_PARAMS / f\"BEST_LGBM_{VIEW_TAG}_{BAL_TAG}.json\"\n",
    "\n",
    "def get_lgbm_defaults(seed=RANDOM_STATE):\n",
    "    mdl = LGBMClassifier(random_state=seed)\n",
    "    return mdl.get_params()\n",
    "\n",
    "def load_best_or_default():\n",
    "    if BEST_HP_FILE.exists():\n",
    "        try:\n",
    "            best = json.loads(BEST_HP_FILE.read_text())\n",
    "            print(\"[HP] Cargando mejores hiperparámetros previos:\", BEST_HP_FILE.name)\n",
    "            base = get_lgbm_defaults()\n",
    "            base.update(best)\n",
    "            return base, True\n",
    "        except Exception as e:\n",
    "            print(\"[HP] Aviso: no se pudo leer BEST (uso defaults).\", e)\n",
    "    print(\"[HP] Usando hiperparámetros DEFAULT.\")\n",
    "    return get_lgbm_defaults(), False\n",
    "\n",
    "seed_params, loaded_best_flag = load_best_or_default()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec7",
   "metadata": {},
   "source": [
    "## 7 — Construcción de matrices (aplica reducción + balanceo) y entrenamiento BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "baseline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.664295\n",
      "[100]\tvalid_0's average_precision: 0.664763\n",
      "[150]\tvalid_0's average_precision: 0.66073\n",
      "[200]\tvalid_0's average_precision: 0.653373\n",
      "[250]\tvalid_0's average_precision: 0.645301\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's average_precision: 0.667534\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.662392\n",
      "[100]\tvalid_0's average_precision: 0.671843\n",
      "[150]\tvalid_0's average_precision: 0.670953\n",
      "[200]\tvalid_0's average_precision: 0.671373\n",
      "[250]\tvalid_0's average_precision: 0.673164\n",
      "[300]\tvalid_0's average_precision: 0.671891\n",
      "[350]\tvalid_0's average_precision: 0.671958\n",
      "[400]\tvalid_0's average_precision: 0.668125\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's average_precision: 0.674161\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.704574\n",
      "[100]\tvalid_0's average_precision: 0.710299\n",
      "[150]\tvalid_0's average_precision: 0.710736\n",
      "[200]\tvalid_0's average_precision: 0.70591\n",
      "[250]\tvalid_0's average_precision: 0.703073\n",
      "[300]\tvalid_0's average_precision: 0.701123\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's average_precision: 0.715114\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.67998\n",
      "[100]\tvalid_0's average_precision: 0.69003\n",
      "[150]\tvalid_0's average_precision: 0.688214\n",
      "[200]\tvalid_0's average_precision: 0.685374\n",
      "[250]\tvalid_0's average_precision: 0.678562\n",
      "[300]\tvalid_0's average_precision: 0.674556\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's average_precision: 0.690866\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.641484\n",
      "[100]\tvalid_0's average_precision: 0.64241\n",
      "[150]\tvalid_0's average_precision: 0.639521\n",
      "[200]\tvalid_0's average_precision: 0.637683\n",
      "[250]\tvalid_0's average_precision: 0.638044\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's average_precision: 0.644311\n",
      "[PERM-CV] Kept: 13 | Dropped: 2\n",
      "[PERM-CV] Eliminados: num__CreditScore, num__Tenure\n",
      "【PERM-CV】Importancias CV guardadas en: LGBM_REDUCED_PERMcv_thr_SMOTENC_perm_cv_importances.csv\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.663686\n",
      "[100]\tvalid_0's average_precision: 0.6789\n",
      "[150]\tvalid_0's average_precision: 0.685202\n",
      "[200]\tvalid_0's average_precision: 0.687644\n",
      "[250]\tvalid_0's average_precision: 0.690313\n",
      "[300]\tvalid_0's average_precision: 0.68799\n",
      "[350]\tvalid_0's average_precision: 0.688029\n",
      "[400]\tvalid_0's average_precision: 0.687788\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's average_precision: 0.690546\n",
      "[BASELINE] best_iteration: 247\n",
      "[BASELINE] Mejor umbral (val) por F1: 0.494 | F1(val)=0.6402\n",
      "[FEATURES] Guardado: LGBM_REDUCED_PERMcv_thr_SMOTENC_feature_sets.json\n"
     ]
    }
   ],
   "source": [
    "_fit_kwargs = {}\n",
    "_callbacks = []\n",
    "if _LGBM_CB_OK:\n",
    "    _callbacks = [early_stopping(stopping_rounds=200), log_evaluation(period=50)]\n",
    "else:\n",
    "    _fit_kwargs[\"early_stopping_rounds\"] = 200\n",
    "\n",
    "seed_params = sanitize_params(seed_params, use_balanced_train=USE_BALANCED_TRAIN)\n",
    "\n",
    "# === Aplicar reducción ===\n",
    "keep_idx_global = None\n",
    "feature_names_used = feature_names_all\n",
    "X_train_fit, X_val_fit, X_test_fit = X_train, X_val, X_test\n",
    "\n",
    "# MI\n",
    "if USE_MI_REDUCED:\n",
    "    keep_idx_global, _mi = fit_mi_selector(X_train, y_train, topk=MI_TOPK, seed=RANDOM_STATE)\n",
    "    X_train_fit = apply_keep_idx(X_train, keep_idx_global)\n",
    "    X_val_fit   = apply_keep_idx(X_val,   keep_idx_global)\n",
    "    X_test_fit  = apply_keep_idx(X_test,  keep_idx_global)\n",
    "    feature_names_used = [feature_names_all[i] for i in keep_idx_global]\n",
    "\n",
    "# PCA\n",
    "if USE_PCA_REDUCED:\n",
    "    X_train_fit, X_val_fit, X_test_fit, feature_names_used = apply_pca_fit_transform(\n",
    "        X_train_fit, X_val_fit, X_test_fit, n_comp=PCA_NCOMP, seed=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "# PERM-CV\n",
    "perm_stats = None\n",
    "if USE_PERM_REDUCED:\n",
    "    keep_idx_global, perm_stats = fit_perm_selector_cv(\n",
    "        X_train, y_train, feature_names_all,\n",
    "        k_folds=CV_FOLDS, n_repeats=PERM_N_REPEATS,\n",
    "        seed=RANDOM_STATE, topk=PERM_TOPK, min_delta=PERM_MIN_DELTA\n",
    "    )\n",
    "    X_train_fit = apply_keep_idx(X_train, keep_idx_global)\n",
    "    X_val_fit   = apply_keep_idx(X_val,   keep_idx_global)\n",
    "    X_test_fit  = apply_keep_idx(X_test,  keep_idx_global)\n",
    "    feature_names_used = [feature_names_all[i] for i in keep_idx_global]\n",
    "\n",
    "    print(f\"[PERM-CV] Kept: {len(feature_names_used)} | Dropped: {len(perm_stats['dropped_names'])}\")\n",
    "    if len(perm_stats['dropped_names']) > 0:\n",
    "        print(\"[PERM-CV] Eliminados:\", \", \".join(perm_stats['dropped_names']))\n",
    "\n",
    "    perm_imp_path = OUT_RESULTS / f\"{EXP_NAME}_perm_cv_importances.csv\"\n",
    "    perm_stats[\"df\"].to_csv(perm_imp_path, index=False)\n",
    "    print(\"【PERM-CV】Importancias CV guardadas en:\", perm_imp_path.name)\n",
    "\n",
    "# --- L1 (Logistic Regression Lasso) ---\n",
    "l1_stats = None\n",
    "if USE_L1_REDUCED:\n",
    "    keep_idx_global, l1_stats = fit_l1_selector(\n",
    "        X_train, y_train, feature_names_all,\n",
    "        C=L1_C, standardize=L1_STANDARDIZE, topk=L1_TOPK,\n",
    "        min_abs_coef=L1_MIN_ABS_COEF, seed=RANDOM_STATE\n",
    "    )\n",
    "    X_train_fit = apply_keep_idx(X_train, keep_idx_global)\n",
    "    X_val_fit   = apply_keep_idx(X_val,   keep_idx_global)\n",
    "    X_test_fit  = apply_keep_idx(X_test,  keep_idx_global)\n",
    "    feature_names_used = [feature_names_all[i] for i in keep_idx_global]\n",
    "\n",
    "    print(f\"[L1] Kept: {len(feature_names_used)} | Dropped: {len(l1_stats['dropped_names'])}\")\n",
    "    if len(l1_stats['dropped_names']) > 0:\n",
    "        print(\"[L1] Eliminados:\", \", \".join(l1_stats['dropped_names']))\n",
    "\n",
    "    l1_coef_path = OUT_RESULTS / f\"{EXP_NAME}_l1_coefs.csv\"\n",
    "    l1_stats[\"df\"].to_csv(l1_coef_path, index=False)\n",
    "    print(\"[L1] Coeficientes guardados en:\", l1_coef_path.name)\n",
    "\n",
    "# === Balanceo SOLO en train ===\n",
    "X_train_final, y_train_final = X_train_fit, y_train\n",
    "if USE_BALANCED_TRAIN:\n",
    "    X_train_final, y_train_final = resample_smote_nc(\n",
    "        X_train_fit, y_train, feature_names_used, seed=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "# === Entrenamiento baseline ===\n",
    "model = LGBMClassifier(**seed_params)\n",
    "_fit_call = dict(\n",
    "    eval_set=[(X_val_fit, y_val)],\n",
    "    eval_metric=\"aucpr\",\n",
    "    **_fit_kwargs\n",
    ")\n",
    "if _LGBM_CB_OK:\n",
    "    _fit_call[\"callbacks\"] = _callbacks\n",
    "\n",
    "model.fit(X_train_final, y_train_final, **_fit_call)\n",
    "\n",
    "best_iter = getattr(model, \"best_iteration_\", None)\n",
    "print(f\"[BASELINE] best_iteration: {best_iter}\")\n",
    "\n",
    "# Validación y umbral baseline\n",
    "proba_val = pred_proba_best(model, X_val_fit)\n",
    "thr_val, best_f1_val = find_best_threshold(y_val, proba_val, metric=\"f1\")\n",
    "val_metrics = compute_all_metrics(y_val, proba_val, thr_val)\n",
    "print(f\"[BASELINE] Mejor umbral (val) por F1: {thr_val:.3f} | F1(val)={best_f1_val:.4f}\")\n",
    "\n",
    "# Guardar sets de features\n",
    "feature_sets_path = OUT_RESULTS / f\"{EXP_NAME}_feature_sets.json\"\n",
    "all_feats_to_save  = feature_names_all\n",
    "used_feats_to_save = feature_names_used\n",
    "\n",
    "meta_reduction = {\n",
    "    \"mi_topk\": MI_TOPK if USE_MI_REDUCED else None,\n",
    "    \"pca_components\": PCA_NCOMP if USE_PCA_REDUCED else None,\n",
    "    \"perm_cv\": {\n",
    "        \"enabled\": bool(USE_PERM_REDUCED),\n",
    "        \"n_repeats\": PERM_N_REPEATS if USE_PERM_REDUCED else None,\n",
    "        \"topk\": PERM_TOPK if USE_PERM_REDUCED else None,\n",
    "        \"min_delta\": PERM_MIN_DELTA if USE_PERM_REDUCED else None\n",
    "    },\n",
    "    \"l1\": {\n",
    "        \"enabled\": bool(USE_L1_REDUCED),\n",
    "        \"C\": L1_C if USE_L1_REDUCED else None,\n",
    "        \"standardize\": bool(L1_STANDARDIZE) if USE_L1_REDUCED else None,\n",
    "        \"topk\": L1_TOPK if USE_L1_REDUCED else None,\n",
    "        \"min_abs_coef\": L1_MIN_ABS_COEF if USE_L1_REDUCED else None\n",
    "    }\n",
    "}\n",
    "\n",
    "dropped_from_perm = (perm_stats[\"dropped_names\"] if (USE_PERM_REDUCED and perm_stats) else [])\n",
    "dropped_from_l1   = (l1_stats[\"dropped_names\"] if (USE_L1_REDUCED and l1_stats) else [])\n",
    "to_dump = {\n",
    "    \"all_features\": all_feats_to_save,\n",
    "    \"used_features\": used_feats_to_save,\n",
    "    \"dropped_features\": dropped_from_perm if USE_PERM_REDUCED else dropped_from_l1,\n",
    "    \"reduction\": meta_reduction\n",
    "}\n",
    "with open(feature_sets_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(to_dump, f, indent=2, ensure_ascii=False)\n",
    "print(\"[FEATURES] Guardado:\", feature_sets_path.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec8",
   "metadata": {},
   "source": [
    "## 8 — Optimización (Optuna) y modelo TUNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "optuna",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:10,353] A new study created in memory with name: LGBM_REDUCED_PERMcv_thr_SMOTENC_AP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OPTUNA] Iniciando 'LGBM_REDUCED_PERMcv_thr_SMOTENC_AP' con 40 pruebas…\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.656887\n",
      "[100]\tvalid_0's average_precision: 0.667936\n",
      "[150]\tvalid_0's average_precision: 0.672786\n",
      "[200]\tvalid_0's average_precision: 0.672304\n",
      "[250]\tvalid_0's average_precision: 0.672506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:11,609] Trial 0 finished with value: 0.67292280168241 and parameters: {'learning_rate': 0.019906996673933378, 'n_estimators': 2900, 'num_leaves': 192, 'max_depth': 10, 'min_child_samples': 124, 'subsample': 0.8832290311184181, 'colsample_bytree': 0.608233797718321, 'reg_alpha': 7.072114131472227, 'reg_lambda': 1.452824663751602, 'min_split_gain': 0.21233911067827616}. Best is trial 0 with value: 0.67292280168241.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\tvalid_0's average_precision: 0.671219\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's average_precision: 0.672923\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.675225\n",
      "[100]\tvalid_0's average_precision: 0.677455\n",
      "[150]\tvalid_0's average_precision: 0.678756\n",
      "[200]\tvalid_0's average_precision: 0.678112\n",
      "[250]\tvalid_0's average_precision: 0.67847\n",
      "[300]\tvalid_0's average_precision: 0.679874\n",
      "[350]\tvalid_0's average_precision: 0.678628\n",
      "[400]\tvalid_0's average_precision: 0.680164\n",
      "[450]\tvalid_0's average_precision: 0.680363\n",
      "[500]\tvalid_0's average_precision: 0.680069\n",
      "[550]\tvalid_0's average_precision: 0.680227\n",
      "[600]\tvalid_0's average_precision: 0.680658\n",
      "[650]\tvalid_0's average_precision: 0.6804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:15,073] Trial 1 finished with value: 0.6808300053865901 and parameters: {'learning_rate': 0.009778325945801386, 'n_estimators': 1200, 'num_leaves': 89, 'max_depth': 8, 'min_child_samples': 65, 'subsample': 0.7465447373174767, 'colsample_bytree': 0.7824279936868144, 'reg_alpha': 0.8431013932082461, 'reg_lambda': 0.0009962513222055108, 'min_split_gain': 0.5142344384136116}. Best is trial 1 with value: 0.6808300053865901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[478]\tvalid_0's average_precision: 0.68083\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.673708\n",
      "[100]\tvalid_0's average_precision: 0.680307\n",
      "[150]\tvalid_0's average_precision: 0.682469\n",
      "[200]\tvalid_0's average_precision: 0.681519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:16,214] Trial 2 finished with value: 0.683173642108792 and parameters: {'learning_rate': 0.04446862319918233, 'n_estimators': 900, 'num_leaves': 162, 'max_depth': 8, 'min_child_samples': 68, 'subsample': 0.6390688456025535, 'colsample_bytree': 0.8736932106048627, 'reg_alpha': 0.015876781526923997, 'reg_lambda': 0.0004075596440072873, 'min_split_gain': 0.4951769101112702}. Best is trial 2 with value: 0.683173642108792.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\tvalid_0's average_precision: 0.681223\n",
      "[300]\tvalid_0's average_precision: 0.681223\n",
      "[350]\tvalid_0's average_precision: 0.681223\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's average_precision: 0.683174\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.61085\n",
      "[100]\tvalid_0's average_precision: 0.622754\n",
      "[150]\tvalid_0's average_precision: 0.62653\n",
      "[200]\tvalid_0's average_precision: 0.633417\n",
      "[250]\tvalid_0's average_precision: 0.638399\n",
      "[300]\tvalid_0's average_precision: 0.64813\n",
      "[350]\tvalid_0's average_precision: 0.654051\n",
      "[400]\tvalid_0's average_precision: 0.656545\n",
      "[450]\tvalid_0's average_precision: 0.660008\n",
      "[500]\tvalid_0's average_precision: 0.663241\n",
      "[550]\tvalid_0's average_precision: 0.665466\n",
      "[600]\tvalid_0's average_precision: 0.666128\n",
      "[650]\tvalid_0's average_precision: 0.666496\n",
      "[700]\tvalid_0's average_precision: 0.665368\n",
      "[750]\tvalid_0's average_precision: 0.665726\n",
      "[800]\tvalid_0's average_precision: 0.666724\n",
      "[850]\tvalid_0's average_precision: 0.667348\n",
      "[900]\tvalid_0's average_precision: 0.667146\n",
      "[950]\tvalid_0's average_precision: 0.666959\n",
      "[1000]\tvalid_0's average_precision: 0.666219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:20,501] Trial 3 finished with value: 0.667347735091636 and parameters: {'learning_rate': 0.005676262589955587, 'n_estimators': 2800, 'num_leaves': 78, 'max_depth': -1, 'min_child_samples': 195, 'subsample': 0.9100531293444458, 'colsample_bytree': 0.9757995766256756, 'reg_alpha': 2.9794544625913595, 'reg_lambda': 0.09761125443110447, 'min_split_gain': 0.9218742350231168}. Best is trial 2 with value: 0.683173642108792.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1050]\tvalid_0's average_precision: 0.666347\n",
      "Early stopping, best iteration is:\n",
      "[850]\tvalid_0's average_precision: 0.667348\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.665205\n",
      "[100]\tvalid_0's average_precision: 0.665719\n",
      "[150]\tvalid_0's average_precision: 0.669953\n",
      "[200]\tvalid_0's average_precision: 0.672271\n",
      "[250]\tvalid_0's average_precision: 0.675474\n",
      "[300]\tvalid_0's average_precision: 0.678542\n",
      "[350]\tvalid_0's average_precision: 0.678116\n",
      "[400]\tvalid_0's average_precision: 0.679332\n",
      "[450]\tvalid_0's average_precision: 0.67826\n",
      "[500]\tvalid_0's average_precision: 0.678109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:22,588] Trial 4 finished with value: 0.6799171266602125 and parameters: {'learning_rate': 0.006930112765148064, 'n_estimators': 1200, 'num_leaves': 26, 'max_depth': 8, 'min_child_samples': 63, 'subsample': 0.8170784332632994, 'colsample_bytree': 0.6563696899899051, 'reg_alpha': 1.025616274847307, 'reg_lambda': 0.0002359137306347715, 'min_split_gain': 0.9868869366005173}. Best is trial 2 with value: 0.683173642108792.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[550]\tvalid_0's average_precision: 0.677899\n",
      "Early stopping, best iteration is:\n",
      "[393]\tvalid_0's average_precision: 0.679917\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.676482\n",
      "[100]\tvalid_0's average_precision: 0.683742\n",
      "[150]\tvalid_0's average_precision: 0.687423\n",
      "[200]\tvalid_0's average_precision: 0.689882\n",
      "[250]\tvalid_0's average_precision: 0.689047\n",
      "[300]\tvalid_0's average_precision: 0.687756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:23,559] Trial 5 finished with value: 0.6904714789188336 and parameters: {'learning_rate': 0.08632815369661433, 'n_estimators': 1200, 'num_leaves': 17, 'max_depth': -1, 'min_child_samples': 78, 'subsample': 0.6463476238100518, 'colsample_bytree': 0.9452413703502374, 'reg_alpha': 0.13076473382928538, 'reg_lambda': 0.004513257622008946, 'min_split_gain': 0.06355835028602363}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[350]\tvalid_0's average_precision: 0.688653\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's average_precision: 0.690471\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.625699\n",
      "[100]\tvalid_0's average_precision: 0.648269\n",
      "[150]\tvalid_0's average_precision: 0.654779\n",
      "[200]\tvalid_0's average_precision: 0.66095\n",
      "[250]\tvalid_0's average_precision: 0.664281\n",
      "[300]\tvalid_0's average_precision: 0.666456\n",
      "[350]\tvalid_0's average_precision: 0.66886\n",
      "[400]\tvalid_0's average_precision: 0.670462\n",
      "[450]\tvalid_0's average_precision: 0.672259\n",
      "[500]\tvalid_0's average_precision: 0.672983\n",
      "[550]\tvalid_0's average_precision: 0.672646\n",
      "[600]\tvalid_0's average_precision: 0.672264\n",
      "[650]\tvalid_0's average_precision: 0.672779\n",
      "Early stopping, best iteration is:\n",
      "[487]\tvalid_0's average_precision: 0.673356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:24,805] Trial 6 finished with value: 0.6733557027230687 and parameters: {'learning_rate': 0.015746438450976667, 'n_estimators': 1500, 'num_leaves': 191, 'max_depth': 4, 'min_child_samples': 155, 'subsample': 0.8245108790277985, 'colsample_bytree': 0.9083868719818244, 'reg_alpha': 0.02944272359149678, 'reg_lambda': 0.04108318894699928, 'min_split_gain': 0.42754101835854963}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.664983\n",
      "[100]\tvalid_0's average_precision: 0.663792\n",
      "[150]\tvalid_0's average_precision: 0.664998\n",
      "[200]\tvalid_0's average_precision: 0.666104\n",
      "[250]\tvalid_0's average_precision: 0.669053\n",
      "[300]\tvalid_0's average_precision: 0.673252\n",
      "[350]\tvalid_0's average_precision: 0.676014\n",
      "[400]\tvalid_0's average_precision: 0.678789\n",
      "[450]\tvalid_0's average_precision: 0.678601\n",
      "[500]\tvalid_0's average_precision: 0.679331\n",
      "[550]\tvalid_0's average_precision: 0.678606\n",
      "[600]\tvalid_0's average_precision: 0.677882\n",
      "[650]\tvalid_0's average_precision: 0.677854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:27,186] Trial 7 finished with value: 0.6795486470506802 and parameters: {'learning_rate': 0.005491525066424382, 'n_estimators': 1000, 'num_leaves': 23, 'max_depth': 8, 'min_child_samples': 88, 'subsample': 0.9022204554172195, 'colsample_bytree': 0.6915192661966489, 'reg_alpha': 0.00024260488932164486, 'reg_lambda': 0.0028103296447636083, 'min_split_gain': 0.16122128725400442}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[493]\tvalid_0's average_precision: 0.679549\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.670363\n",
      "[100]\tvalid_0's average_precision: 0.665787\n",
      "[150]\tvalid_0's average_precision: 0.663544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:27,628] Trial 8 finished with value: 0.6782979946585769 and parameters: {'learning_rate': 0.15431261011638706, 'n_estimators': 2600, 'num_leaves': 168, 'max_depth': 8, 'min_child_samples': 164, 'subsample': 0.9584365199693973, 'colsample_bytree': 0.7272013899887455, 'reg_alpha': 0.000355025561231308, 'reg_lambda': 0.001379354235277248, 'min_split_gain': 0.4271077886262563}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's average_precision: 0.663511\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's average_precision: 0.678298\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.663234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:27,964] Trial 9 finished with value: 0.6671084907144434 and parameters: {'learning_rate': 0.10220655100897388, 'n_estimators': 2700, 'num_leaves': 17, 'max_depth': -1, 'min_child_samples': 190, 'subsample': 0.7292811728083021, 'colsample_bytree': 0.8075162486973464, 'reg_alpha': 0.3274121520988885, 'reg_lambda': 0.0065788201191231774, 'min_split_gain': 0.9717820827209607}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's average_precision: 0.65856\n",
      "[150]\tvalid_0's average_precision: 0.656302\n",
      "[200]\tvalid_0's average_precision: 0.656355\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's average_precision: 0.667108\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.674485\n",
      "[100]\tvalid_0's average_precision: 0.669392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:28,649] Trial 10 finished with value: 0.6770409673699735 and parameters: {'learning_rate': 0.11160520780208899, 'n_estimators': 1200, 'num_leaves': 25, 'max_depth': -1, 'min_child_samples': 154, 'subsample': 0.6304655048035832, 'colsample_bytree': 0.9486757327801338, 'reg_alpha': 0.4625809500171002, 'reg_lambda': 0.02958571414754742, 'min_split_gain': 0.24741350827669434}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\tvalid_0's average_precision: 0.664465\n",
      "[200]\tvalid_0's average_precision: 0.660765\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's average_precision: 0.677041\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.674665\n",
      "[100]\tvalid_0's average_precision: 0.68448\n",
      "[150]\tvalid_0's average_precision: 0.685068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:29,103] Trial 11 finished with value: 0.6868155542420753 and parameters: {'learning_rate': 0.09050232916287854, 'n_estimators': 1550, 'num_leaves': 45, 'max_depth': 4, 'min_child_samples': 32, 'subsample': 0.6084041964777769, 'colsample_bytree': 0.9370913448713828, 'reg_alpha': 0.02268543822568673, 'reg_lambda': 0.004661751603072236, 'min_split_gain': 0.12963345766078527}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's average_precision: 0.68145\n",
      "[250]\tvalid_0's average_precision: 0.678437\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's average_precision: 0.686816\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.681716\n",
      "[100]\tvalid_0's average_precision: 0.683359\n",
      "[150]\tvalid_0's average_precision: 0.682161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:29,548] Trial 12 finished with value: 0.6857966622054906 and parameters: {'learning_rate': 0.12639865324310517, 'n_estimators': 1150, 'num_leaves': 43, 'max_depth': 4, 'min_child_samples': 49, 'subsample': 0.7038072679919442, 'colsample_bytree': 0.9797447789375463, 'reg_alpha': 0.0698312618749519, 'reg_lambda': 0.001149422634021616, 'min_split_gain': 0.09326545536393184}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's average_precision: 0.684234\n",
      "[250]\tvalid_0's average_precision: 0.678251\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's average_precision: 0.685797\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.659472\n",
      "[100]\tvalid_0's average_precision: 0.68058\n",
      "[150]\tvalid_0's average_precision: 0.686381\n",
      "[200]\tvalid_0's average_precision: 0.685544\n",
      "[250]\tvalid_0's average_precision: 0.685411\n",
      "[300]\tvalid_0's average_precision: 0.686022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:30,471] Trial 13 finished with value: 0.6871654919048742 and parameters: {'learning_rate': 0.04060393986072223, 'n_estimators': 1950, 'num_leaves': 24, 'max_depth': 6, 'min_child_samples': 32, 'subsample': 0.647909046328907, 'colsample_bytree': 0.8915277935520681, 'reg_alpha': 0.392721170230632, 'reg_lambda': 0.012181101841488252, 'min_split_gain': 0.12464108666693852}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's average_precision: 0.687165\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.673699\n",
      "[100]\tvalid_0's average_precision: 0.67615\n",
      "[150]\tvalid_0's average_precision: 0.674994\n",
      "[200]\tvalid_0's average_precision: 0.676257\n",
      "[250]\tvalid_0's average_precision: 0.676517\n",
      "[300]\tvalid_0's average_precision: 0.676491\n",
      "[350]\tvalid_0's average_precision: 0.675421\n",
      "[400]\tvalid_0's average_precision: 0.67414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:34,600] Trial 14 finished with value: 0.6776653550556833 and parameters: {'learning_rate': 0.022270028961746353, 'n_estimators': 1000, 'num_leaves': 74, 'max_depth': -1, 'min_child_samples': 69, 'subsample': 0.619310761070061, 'colsample_bytree': 0.7883925500787337, 'reg_alpha': 0.5132368222274102, 'reg_lambda': 0.0002344190516496126, 'min_split_gain': 0.05019731447193783}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[450]\tvalid_0's average_precision: 0.674772\n",
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's average_precision: 0.677665\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.664328\n",
      "[100]\tvalid_0's average_precision: 0.666878\n",
      "[150]\tvalid_0's average_precision: 0.667738\n",
      "[200]\tvalid_0's average_precision: 0.670713\n",
      "[250]\tvalid_0's average_precision: 0.668656\n",
      "[300]\tvalid_0's average_precision: 0.670668\n",
      "[350]\tvalid_0's average_precision: 0.671999\n",
      "[400]\tvalid_0's average_precision: 0.675145\n",
      "[450]\tvalid_0's average_precision: 0.677562\n",
      "[500]\tvalid_0's average_precision: 0.679818\n",
      "[550]\tvalid_0's average_precision: 0.681138\n",
      "[600]\tvalid_0's average_precision: 0.682062\n",
      "[650]\tvalid_0's average_precision: 0.683001\n",
      "[700]\tvalid_0's average_precision: 0.684138\n",
      "[750]\tvalid_0's average_precision: 0.68507\n",
      "[800]\tvalid_0's average_precision: 0.685369\n",
      "[850]\tvalid_0's average_precision: 0.686003\n",
      "[900]\tvalid_0's average_precision: 0.686692\n",
      "[950]\tvalid_0's average_precision: 0.686714\n",
      "[1000]\tvalid_0's average_precision: 0.686182\n",
      "[1050]\tvalid_0's average_precision: 0.686471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:38,705] Trial 15 finished with value: 0.6870217441971062 and parameters: {'learning_rate': 0.00860775338716246, 'n_estimators': 1700, 'num_leaves': 48, 'max_depth': 6, 'min_child_samples': 10, 'subsample': 0.7053303159597494, 'colsample_bytree': 0.8420647314193398, 'reg_alpha': 0.0920373895862211, 'reg_lambda': 0.14810462114524472, 'min_split_gain': 0.22262994600226338}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1100]\tvalid_0's average_precision: 0.686224\n",
      "Early stopping, best iteration is:\n",
      "[906]\tvalid_0's average_precision: 0.687022\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.663291\n",
      "[100]\tvalid_0's average_precision: 0.66921\n",
      "[150]\tvalid_0's average_precision: 0.676035\n",
      "[200]\tvalid_0's average_precision: 0.67928\n",
      "[250]\tvalid_0's average_precision: 0.677498\n",
      "[300]\tvalid_0's average_precision: 0.67644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:39,875] Trial 16 finished with value: 0.6794108064468697 and parameters: {'learning_rate': 0.034903939407243484, 'n_estimators': 2100, 'num_leaves': 98, 'max_depth': 6, 'min_child_samples': 88, 'subsample': 0.8497699881688667, 'colsample_bytree': 0.8085674487212147, 'reg_alpha': 2.3232623729309125, 'reg_lambda': 0.0033555159173703285, 'min_split_gain': 0.09844044462378902}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[350]\tvalid_0's average_precision: 0.675074\n",
      "[400]\tvalid_0's average_precision: 0.674268\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's average_precision: 0.679411\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.661597\n",
      "[100]\tvalid_0's average_precision: 0.66815\n",
      "[150]\tvalid_0's average_precision: 0.670419\n",
      "[200]\tvalid_0's average_precision: 0.673779\n",
      "[250]\tvalid_0's average_precision: 0.677757\n",
      "[300]\tvalid_0's average_precision: 0.680064\n",
      "[350]\tvalid_0's average_precision: 0.680482\n",
      "[400]\tvalid_0's average_precision: 0.67851\n",
      "[450]\tvalid_0's average_precision: 0.67875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:42,917] Trial 17 finished with value: 0.681528378374409 and parameters: {'learning_rate': 0.021214812537338153, 'n_estimators': 850, 'num_leaves': 43, 'max_depth': -1, 'min_child_samples': 69, 'subsample': 0.7986595709599665, 'colsample_bytree': 0.9480772725922231, 'reg_alpha': 0.14295180538223412, 'reg_lambda': 0.23112454254783893, 'min_split_gain': 0.19297865577099715}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalid_0's average_precision: 0.678898\n",
      "Early stopping, best iteration is:\n",
      "[327]\tvalid_0's average_precision: 0.681528\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:43,197] Trial 18 finished with value: 0.681881578453229 and parameters: {'learning_rate': 0.12029985030921832, 'n_estimators': 1950, 'num_leaves': 67, 'max_depth': 6, 'min_child_samples': 35, 'subsample': 0.6758265032585943, 'colsample_bytree': 0.8016858795613105, 'reg_alpha': 6.166588044154373, 'reg_lambda': 0.00012934972189384303, 'min_split_gain': 0.4207158737966231}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's average_precision: 0.680041\n",
      "[100]\tvalid_0's average_precision: 0.68012\n",
      "[150]\tvalid_0's average_precision: 0.68012\n",
      "[200]\tvalid_0's average_precision: 0.68012\n",
      "[250]\tvalid_0's average_precision: 0.68012\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's average_precision: 0.681882\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.667971\n",
      "[100]\tvalid_0's average_precision: 0.681096\n",
      "[150]\tvalid_0's average_precision: 0.680174\n",
      "[200]\tvalid_0's average_precision: 0.679383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:44,100] Trial 19 finished with value: 0.68234787952074 and parameters: {'learning_rate': 0.051172893246778116, 'n_estimators': 2300, 'num_leaves': 97, 'max_depth': 6, 'min_child_samples': 60, 'subsample': 0.6008372141641575, 'colsample_bytree': 0.8858914607898476, 'reg_alpha': 0.4231191251291723, 'reg_lambda': 0.06192882085684199, 'min_split_gain': 0.20016376757462126}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\tvalid_0's average_precision: 0.677769\n",
      "[300]\tvalid_0's average_precision: 0.676193\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's average_precision: 0.682348\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.660443\n",
      "[100]\tvalid_0's average_precision: 0.672247\n",
      "[150]\tvalid_0's average_precision: 0.677286\n",
      "[200]\tvalid_0's average_precision: 0.675538\n",
      "[250]\tvalid_0's average_precision: 0.67348\n",
      "[300]\tvalid_0's average_precision: 0.672729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:44,648] Trial 20 finished with value: 0.6780026979158988 and parameters: {'learning_rate': 0.051222324105519655, 'n_estimators': 1900, 'num_leaves': 55, 'max_depth': 4, 'min_child_samples': 184, 'subsample': 0.6580065273759165, 'colsample_bytree': 0.9064648559026968, 'reg_alpha': 0.004209073282554238, 'reg_lambda': 0.0009361122049775561, 'min_split_gain': 0.056085378296413024}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's average_precision: 0.678003\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.676536\n",
      "[100]\tvalid_0's average_precision: 0.677615\n",
      "[150]\tvalid_0's average_precision: 0.679799\n",
      "[200]\tvalid_0's average_precision: 0.682844\n",
      "[250]\tvalid_0's average_precision: 0.684572\n",
      "[300]\tvalid_0's average_precision: 0.685379\n",
      "[350]\tvalid_0's average_precision: 0.684153\n",
      "[400]\tvalid_0's average_precision: 0.686458\n",
      "[450]\tvalid_0's average_precision: 0.686282\n",
      "[500]\tvalid_0's average_precision: 0.685353\n",
      "[550]\tvalid_0's average_precision: 0.685646\n",
      "[600]\tvalid_0's average_precision: 0.685806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:48,558] Trial 21 finished with value: 0.6871071052038525 and parameters: {'learning_rate': 0.011463055559644568, 'n_estimators': 1850, 'num_leaves': 89, 'max_depth': 8, 'min_child_samples': 47, 'subsample': 0.7550980573641108, 'colsample_bytree': 0.7722792903785042, 'reg_alpha': 0.02010817454257983, 'reg_lambda': 3.734564380811719, 'min_split_gain': 0.37977266952150446}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[419]\tvalid_0's average_precision: 0.687107\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.6723\n",
      "[100]\tvalid_0's average_precision: 0.680152\n",
      "[150]\tvalid_0's average_precision: 0.681951\n",
      "[200]\tvalid_0's average_precision: 0.683086\n",
      "[250]\tvalid_0's average_precision: 0.682748\n",
      "[300]\tvalid_0's average_precision: 0.681589\n",
      "[350]\tvalid_0's average_precision: 0.680818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:50,220] Trial 22 finished with value: 0.6833174472713385 and parameters: {'learning_rate': 0.0280438157089555, 'n_estimators': 1900, 'num_leaves': 90, 'max_depth': 8, 'min_child_samples': 75, 'subsample': 0.7200120731725965, 'colsample_bytree': 0.6985699842251951, 'reg_alpha': 0.0028685569128289816, 'reg_lambda': 6.348448763981449, 'min_split_gain': 0.4610759796138766}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\tvalid_0's average_precision: 0.679555\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's average_precision: 0.683317\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.675905\n",
      "[100]\tvalid_0's average_precision: 0.669436\n",
      "[150]\tvalid_0's average_precision: 0.6666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:51,770] Trial 23 finished with value: 0.6786881964092001 and parameters: {'learning_rate': 0.14002257808531088, 'n_estimators': 1250, 'num_leaves': 54, 'max_depth': -1, 'min_child_samples': 96, 'subsample': 0.7248132483478663, 'colsample_bytree': 0.8232858763255815, 'reg_alpha': 0.006120657016529097, 'reg_lambda': 0.00991441250639292, 'min_split_gain': 0.018519850086984244}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's average_precision: 0.65738\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's average_precision: 0.678688\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.674446\n",
      "[100]\tvalid_0's average_precision: 0.677647\n",
      "[150]\tvalid_0's average_precision: 0.678953\n",
      "[200]\tvalid_0's average_precision: 0.679719\n",
      "[250]\tvalid_0's average_precision: 0.682062\n",
      "[300]\tvalid_0's average_precision: 0.68331\n",
      "[350]\tvalid_0's average_precision: 0.681851\n",
      "[400]\tvalid_0's average_precision: 0.682113\n",
      "[450]\tvalid_0's average_precision: 0.684738\n",
      "[500]\tvalid_0's average_precision: 0.684495\n",
      "[550]\tvalid_0's average_precision: 0.684286\n",
      "[600]\tvalid_0's average_precision: 0.684416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:55,660] Trial 24 finished with value: 0.6853214165205721 and parameters: {'learning_rate': 0.010054497706045348, 'n_estimators': 1400, 'num_leaves': 112, 'max_depth': 8, 'min_child_samples': 58, 'subsample': 0.8123313415794513, 'colsample_bytree': 0.7542533070818238, 'reg_alpha': 0.05846073264902124, 'reg_lambda': 3.420717120918948, 'min_split_gain': 0.31296306875021185}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[650]\tvalid_0's average_precision: 0.684837\n",
      "Early stopping, best iteration is:\n",
      "[457]\tvalid_0's average_precision: 0.685321\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.636553\n",
      "[100]\tvalid_0's average_precision: 0.652561\n",
      "[150]\tvalid_0's average_precision: 0.659855\n",
      "[200]\tvalid_0's average_precision: 0.663138\n",
      "[250]\tvalid_0's average_precision: 0.667681\n",
      "[300]\tvalid_0's average_precision: 0.670872\n",
      "[350]\tvalid_0's average_precision: 0.672378\n",
      "[400]\tvalid_0's average_precision: 0.671974\n",
      "[450]\tvalid_0's average_precision: 0.671819\n",
      "[500]\tvalid_0's average_precision: 0.671296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:57,108] Trial 25 finished with value: 0.6729096684032134 and parameters: {'learning_rate': 0.017132834198442293, 'n_estimators': 1950, 'num_leaves': 16, 'max_depth': -1, 'min_child_samples': 53, 'subsample': 0.7339928673398929, 'colsample_bytree': 0.8790042126144365, 'reg_alpha': 8.710305417916404, 'reg_lambda': 0.01002916496135174, 'min_split_gain': 0.055745487516280806}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[550]\tvalid_0's average_precision: 0.67124\n",
      "Early stopping, best iteration is:\n",
      "[353]\tvalid_0's average_precision: 0.67291\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.65767\n",
      "[100]\tvalid_0's average_precision: 0.671936\n",
      "[150]\tvalid_0's average_precision: 0.674034\n",
      "[200]\tvalid_0's average_precision: 0.6763\n",
      "[250]\tvalid_0's average_precision: 0.678576\n",
      "[300]\tvalid_0's average_precision: 0.680418\n",
      "[350]\tvalid_0's average_precision: 0.681808\n",
      "[400]\tvalid_0's average_precision: 0.682803\n",
      "[450]\tvalid_0's average_precision: 0.684623\n",
      "[500]\tvalid_0's average_precision: 0.685757\n",
      "[550]\tvalid_0's average_precision: 0.686702\n",
      "[600]\tvalid_0's average_precision: 0.687296\n",
      "[650]\tvalid_0's average_precision: 0.687968\n",
      "[700]\tvalid_0's average_precision: 0.688693\n",
      "[750]\tvalid_0's average_precision: 0.688225\n",
      "[800]\tvalid_0's average_precision: 0.688175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:58,619] Trial 26 finished with value: 0.6887178311447969 and parameters: {'learning_rate': 0.02062470595325994, 'n_estimators': 1850, 'num_leaves': 52, 'max_depth': 4, 'min_child_samples': 12, 'subsample': 0.8616163296796211, 'colsample_bytree': 0.6859256826767183, 'reg_alpha': 0.03636247335636547, 'reg_lambda': 0.2507591813156733, 'min_split_gain': 0.5409574372796445}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[850]\tvalid_0's average_precision: 0.688106\n",
      "Early stopping, best iteration is:\n",
      "[698]\tvalid_0's average_precision: 0.688718\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.668373\n",
      "[100]\tvalid_0's average_precision: 0.683526\n",
      "[150]\tvalid_0's average_precision: 0.682173\n",
      "[200]\tvalid_0's average_precision: 0.681148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:56:59,091] Trial 27 finished with value: 0.683734477735256 and parameters: {'learning_rate': 0.0631615983736575, 'n_estimators': 1800, 'num_leaves': 21, 'max_depth': 4, 'min_child_samples': 55, 'subsample': 0.8362827138972705, 'colsample_bytree': 0.7303472759388985, 'reg_alpha': 0.007809199765079714, 'reg_lambda': 0.03849998347802852, 'min_split_gain': 0.6126079648736109}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\tvalid_0's average_precision: 0.681331\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's average_precision: 0.683734\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.651378\n",
      "[100]\tvalid_0's average_precision: 0.664138\n",
      "[150]\tvalid_0's average_precision: 0.668288\n",
      "[200]\tvalid_0's average_precision: 0.670575\n",
      "[250]\tvalid_0's average_precision: 0.673501\n",
      "[300]\tvalid_0's average_precision: 0.675407\n",
      "[350]\tvalid_0's average_precision: 0.675458\n",
      "[400]\tvalid_0's average_precision: 0.675797\n",
      "[450]\tvalid_0's average_precision: 0.676184\n",
      "[500]\tvalid_0's average_precision: 0.677603\n",
      "[550]\tvalid_0's average_precision: 0.679863\n",
      "[600]\tvalid_0's average_precision: 0.680607\n",
      "[650]\tvalid_0's average_precision: 0.679498\n",
      "[700]\tvalid_0's average_precision: 0.68018\n",
      "[750]\tvalid_0's average_precision: 0.680653\n",
      "[800]\tvalid_0's average_precision: 0.681371\n",
      "[850]\tvalid_0's average_precision: 0.682016\n",
      "[900]\tvalid_0's average_precision: 0.682589\n",
      "[950]\tvalid_0's average_precision: 0.683651\n",
      "[1000]\tvalid_0's average_precision: 0.68453\n",
      "[1050]\tvalid_0's average_precision: 0.685103\n",
      "[1100]\tvalid_0's average_precision: 0.685531\n",
      "[1150]\tvalid_0's average_precision: 0.685349\n",
      "[1200]\tvalid_0's average_precision: 0.685587\n",
      "[1250]\tvalid_0's average_precision: 0.685274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:57:01,356] Trial 28 finished with value: 0.685853878812704 and parameters: {'learning_rate': 0.010577902033443165, 'n_estimators': 1600, 'num_leaves': 92, 'max_depth': 4, 'min_child_samples': 15, 'subsample': 0.8863756142343089, 'colsample_bytree': 0.6191528862688613, 'reg_alpha': 1.1745348625378131, 'reg_lambda': 0.14324051215307942, 'min_split_gain': 0.3980903915179079}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300]\tvalid_0's average_precision: 0.684916\n",
      "[1350]\tvalid_0's average_precision: 0.685282\n",
      "Early stopping, best iteration is:\n",
      "[1184]\tvalid_0's average_precision: 0.685854\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.653197\n",
      "[100]\tvalid_0's average_precision: 0.668009\n",
      "[150]\tvalid_0's average_precision: 0.674488\n",
      "[200]\tvalid_0's average_precision: 0.675985\n",
      "[250]\tvalid_0's average_precision: 0.677878\n",
      "[300]\tvalid_0's average_precision: 0.678473\n",
      "[350]\tvalid_0's average_precision: 0.68055\n",
      "[400]\tvalid_0's average_precision: 0.681827\n",
      "[450]\tvalid_0's average_precision: 0.682807\n",
      "[500]\tvalid_0's average_precision: 0.683654\n",
      "[550]\tvalid_0's average_precision: 0.685039\n",
      "[600]\tvalid_0's average_precision: 0.685616\n",
      "[650]\tvalid_0's average_precision: 0.686519\n",
      "[700]\tvalid_0's average_precision: 0.687154\n",
      "[750]\tvalid_0's average_precision: 0.687306\n",
      "[800]\tvalid_0's average_precision: 0.686739\n",
      "[850]\tvalid_0's average_precision: 0.685825\n",
      "[900]\tvalid_0's average_precision: 0.685209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:57:02,934] Trial 29 finished with value: 0.6873290974595205 and parameters: {'learning_rate': 0.015028662132076508, 'n_estimators': 2400, 'num_leaves': 47, 'max_depth': 4, 'min_child_samples': 27, 'subsample': 0.8163550021736568, 'colsample_bytree': 0.6202105548363357, 'reg_alpha': 0.020312274108370075, 'reg_lambda': 0.1691046474861341, 'min_split_gain': 0.796435542230459}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[744]\tvalid_0's average_precision: 0.687329\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.677726\n",
      "[100]\tvalid_0's average_precision: 0.679232\n",
      "[150]\tvalid_0's average_precision: 0.679735\n",
      "[200]\tvalid_0's average_precision: 0.68304\n",
      "[250]\tvalid_0's average_precision: 0.684009\n",
      "[300]\tvalid_0's average_precision: 0.685028\n",
      "[350]\tvalid_0's average_precision: 0.684694\n",
      "[400]\tvalid_0's average_precision: 0.685438\n",
      "[450]\tvalid_0's average_precision: 0.685777\n",
      "[500]\tvalid_0's average_precision: 0.686095\n",
      "[550]\tvalid_0's average_precision: 0.68591\n",
      "[600]\tvalid_0's average_precision: 0.685848\n",
      "[650]\tvalid_0's average_precision: 0.686035\n",
      "[700]\tvalid_0's average_precision: 0.685433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:57:07,385] Trial 30 finished with value: 0.6864013113693422 and parameters: {'learning_rate': 0.009769209061363835, 'n_estimators': 1700, 'num_leaves': 53, 'max_depth': 10, 'min_child_samples': 44, 'subsample': 0.7725274767088244, 'colsample_bytree': 0.6723286322565598, 'reg_alpha': 0.0060841209017200295, 'reg_lambda': 0.019716885563972712, 'min_split_gain': 0.7687196131060924}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[750]\tvalid_0's average_precision: 0.684669\n",
      "[800]\tvalid_0's average_precision: 0.68438\n",
      "Early stopping, best iteration is:\n",
      "[626]\tvalid_0's average_precision: 0.686401\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.676735\n",
      "[100]\tvalid_0's average_precision: 0.684227\n",
      "[150]\tvalid_0's average_precision: 0.685508\n",
      "[200]\tvalid_0's average_precision: 0.683597\n",
      "[250]\tvalid_0's average_precision: 0.681773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:57:08,966] Trial 31 finished with value: 0.6855075666385929 and parameters: {'learning_rate': 0.03016655514313701, 'n_estimators': 2300, 'num_leaves': 53, 'max_depth': 10, 'min_child_samples': 46, 'subsample': 0.9138511189744357, 'colsample_bytree': 0.6353328093940386, 'reg_alpha': 0.057956215898599756, 'reg_lambda': 2.164270187217686, 'min_split_gain': 0.6871484938300318}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\tvalid_0's average_precision: 0.680582\n",
      "[350]\tvalid_0's average_precision: 0.680915\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's average_precision: 0.685508\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.653493\n",
      "[100]\tvalid_0's average_precision: 0.668888\n",
      "[150]\tvalid_0's average_precision: 0.674373\n",
      "[200]\tvalid_0's average_precision: 0.675247\n",
      "[250]\tvalid_0's average_precision: 0.678002\n",
      "[300]\tvalid_0's average_precision: 0.678455\n",
      "[350]\tvalid_0's average_precision: 0.680432\n",
      "[400]\tvalid_0's average_precision: 0.681824\n",
      "[450]\tvalid_0's average_precision: 0.681764\n",
      "[500]\tvalid_0's average_precision: 0.682844\n",
      "[550]\tvalid_0's average_precision: 0.68337\n",
      "[600]\tvalid_0's average_precision: 0.68381\n",
      "[650]\tvalid_0's average_precision: 0.685365\n",
      "[700]\tvalid_0's average_precision: 0.686313\n",
      "[750]\tvalid_0's average_precision: 0.686247\n",
      "[800]\tvalid_0's average_precision: 0.686002\n",
      "[850]\tvalid_0's average_precision: 0.685465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:57:10,494] Trial 32 finished with value: 0.686429651811801 and parameters: {'learning_rate': 0.014793852809524569, 'n_estimators': 2800, 'num_leaves': 17, 'max_depth': 4, 'min_child_samples': 27, 'subsample': 0.8145161246224131, 'colsample_bytree': 0.623605243178975, 'reg_alpha': 0.0162363379975884, 'reg_lambda': 0.01516346121903361, 'min_split_gain': 0.41278690424420433}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900]\tvalid_0's average_precision: 0.685006\n",
      "Early stopping, best iteration is:\n",
      "[707]\tvalid_0's average_precision: 0.68643\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.655865\n",
      "[100]\tvalid_0's average_precision: 0.670231\n",
      "[150]\tvalid_0's average_precision: 0.673007\n",
      "[200]\tvalid_0's average_precision: 0.677284\n",
      "[250]\tvalid_0's average_precision: 0.679851\n",
      "[300]\tvalid_0's average_precision: 0.680987\n",
      "[350]\tvalid_0's average_precision: 0.68288\n",
      "[400]\tvalid_0's average_precision: 0.683177\n",
      "[450]\tvalid_0's average_precision: 0.684715\n",
      "[500]\tvalid_0's average_precision: 0.685702\n",
      "[550]\tvalid_0's average_precision: 0.685262\n",
      "[600]\tvalid_0's average_precision: 0.687052\n",
      "[650]\tvalid_0's average_precision: 0.686878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:57:11,713] Trial 33 finished with value: 0.6873682993185994 and parameters: {'learning_rate': 0.023876388220944955, 'n_estimators': 1500, 'num_leaves': 33, 'max_depth': 4, 'min_child_samples': 34, 'subsample': 0.885582727127363, 'colsample_bytree': 0.698243466950404, 'reg_alpha': 0.01630722628675901, 'reg_lambda': 1.9060405396035807, 'min_split_gain': 0.3944019085571256}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\tvalid_0's average_precision: 0.68665\n",
      "[750]\tvalid_0's average_precision: 0.686306\n",
      "[800]\tvalid_0's average_precision: 0.686297\n",
      "Early stopping, best iteration is:\n",
      "[621]\tvalid_0's average_precision: 0.687368\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.665237\n",
      "[100]\tvalid_0's average_precision: 0.679832\n",
      "[150]\tvalid_0's average_precision: 0.685415\n",
      "[200]\tvalid_0's average_precision: 0.686794\n",
      "[250]\tvalid_0's average_precision: 0.68802\n",
      "[300]\tvalid_0's average_precision: 0.687259\n",
      "[350]\tvalid_0's average_precision: 0.68628\n",
      "[400]\tvalid_0's average_precision: 0.684071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:57:12,411] Trial 34 finished with value: 0.6885376582599366 and parameters: {'learning_rate': 0.06792104790774255, 'n_estimators': 800, 'num_leaves': 87, 'max_depth': 4, 'min_child_samples': 24, 'subsample': 0.8943883316782615, 'colsample_bytree': 0.6750799431658977, 'reg_alpha': 0.01856339515158022, 'reg_lambda': 2.556713874987819, 'min_split_gain': 0.1984483140959624}. Best is trial 5 with value: 0.6904714789188336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[450]\tvalid_0's average_precision: 0.683467\n",
      "Early stopping, best iteration is:\n",
      "[271]\tvalid_0's average_precision: 0.688538\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.663686\n",
      "[100]\tvalid_0's average_precision: 0.6789\n",
      "[150]\tvalid_0's average_precision: 0.685202\n",
      "[200]\tvalid_0's average_precision: 0.687644\n",
      "[250]\tvalid_0's average_precision: 0.690313\n",
      "[300]\tvalid_0's average_precision: 0.68799\n",
      "[350]\tvalid_0's average_precision: 0.688029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:57:13,126] Trial 35 finished with value: 0.6905462114954057 and parameters: {'learning_rate': 0.047200189967689266, 'n_estimators': 1050, 'num_leaves': 32, 'max_depth': 4, 'min_child_samples': 42, 'subsample': 0.9739732874700401, 'colsample_bytree': 0.6570583808610804, 'reg_alpha': 0.01562190879871248, 'reg_lambda': 0.317921120943722, 'min_split_gain': 0.11860590766767039}. Best is trial 35 with value: 0.6905462114954057.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\tvalid_0's average_precision: 0.687788\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's average_precision: 0.690546\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.688533\n",
      "[100]\tvalid_0's average_precision: 0.686862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:57:14,189] Trial 36 finished with value: 0.6890677485047363 and parameters: {'learning_rate': 0.111017381214976, 'n_estimators': 950, 'num_leaves': 64, 'max_depth': 10, 'min_child_samples': 27, 'subsample': 0.960053147480697, 'colsample_bytree': 0.6700803826006128, 'reg_alpha': 0.4963294550030814, 'reg_lambda': 2.3248674522823074, 'min_split_gain': 0.08881276515762723}. Best is trial 35 with value: 0.6905462114954057.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\tvalid_0's average_precision: 0.681565\n",
      "[200]\tvalid_0's average_precision: 0.680791\n",
      "[250]\tvalid_0's average_precision: 0.680791\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's average_precision: 0.689068\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.687759\n",
      "[100]\tvalid_0's average_precision: 0.676841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:57:14,831] Trial 37 finished with value: 0.6882605195172041 and parameters: {'learning_rate': 0.17809242979956885, 'n_estimators': 1300, 'num_leaves': 26, 'max_depth': 10, 'min_child_samples': 17, 'subsample': 0.85158425236166, 'colsample_bytree': 0.7433235351661844, 'reg_alpha': 0.8659378348580851, 'reg_lambda': 1.4443444149162987, 'min_split_gain': 0.06317142414896001}. Best is trial 35 with value: 0.6905462114954057.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\tvalid_0's average_precision: 0.677935\n",
      "[200]\tvalid_0's average_precision: 0.677935\n",
      "[250]\tvalid_0's average_precision: 0.677935\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's average_precision: 0.688261\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.662379\n",
      "[100]\tvalid_0's average_precision: 0.671278\n",
      "[150]\tvalid_0's average_precision: 0.676481\n",
      "[200]\tvalid_0's average_precision: 0.68119\n",
      "[250]\tvalid_0's average_precision: 0.682606\n",
      "[300]\tvalid_0's average_precision: 0.68292\n",
      "[350]\tvalid_0's average_precision: 0.68242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:57:15,611] Trial 38 finished with value: 0.6834245133300783 and parameters: {'learning_rate': 0.03834241296348381, 'n_estimators': 1050, 'num_leaves': 66, 'max_depth': 4, 'min_child_samples': 77, 'subsample': 0.9979753462802349, 'colsample_bytree': 0.6136270648023046, 'reg_alpha': 0.04071040859028056, 'reg_lambda': 0.05532048996280229, 'min_split_gain': 0.04401054225337449}. Best is trial 35 with value: 0.6905462114954057.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\tvalid_0's average_precision: 0.682222\n",
      "[450]\tvalid_0's average_precision: 0.682729\n",
      "Early stopping, best iteration is:\n",
      "[261]\tvalid_0's average_precision: 0.683425\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.682444\n",
      "[100]\tvalid_0's average_precision: 0.678297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 14:57:16,598] Trial 39 finished with value: 0.6831469268092395 and parameters: {'learning_rate': 0.17685099631350062, 'n_estimators': 800, 'num_leaves': 67, 'max_depth': 10, 'min_child_samples': 18, 'subsample': 0.9601984378067066, 'colsample_bytree': 0.6110660035705456, 'reg_alpha': 0.0382795742020348, 'reg_lambda': 7.488551007865272, 'min_split_gain': 0.1100287678561767}. Best is trial 35 with value: 0.6905462114954057.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\tvalid_0's average_precision: 0.680819\n",
      "[200]\tvalid_0's average_precision: 0.679108\n",
      "[250]\tvalid_0's average_precision: 0.679108\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's average_precision: 0.683147\n",
      "[OPTUNA] Mejor AP(val): 0.690546\n",
      "[OPTUNA] Params: {'learning_rate': 0.047200189967689266, 'n_estimators': 1050, 'num_leaves': 32, 'max_depth': 4, 'min_child_samples': 42, 'subsample': 0.9739732874700401, 'colsample_bytree': 0.6570583808610804, 'reg_alpha': 0.01562190879871248, 'reg_lambda': 0.317921120943722, 'min_split_gain': 0.11860590766767039}\n",
      "[OPTUNA] best_iteration: 247\n",
      "[OPTUNA] Guardado BEST en: BEST_LGBM_REDUCED_PERMcv_thr_SMOTENC.json\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.672273\n",
      "[100]\tvalid_0's average_precision: 0.681697\n",
      "[150]\tvalid_0's average_precision: 0.682111\n",
      "[200]\tvalid_0's average_precision: 0.679085\n",
      "[250]\tvalid_0's average_precision: 0.677701\n",
      "[300]\tvalid_0's average_precision: 0.677549\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's average_precision: 0.683281\n",
      "[OPTUNA] Reentreno final completado. best_iteration_ = 135\n"
     ]
    }
   ],
   "source": [
    "tuned_model = None\n",
    "if DO_TUNE:\n",
    "    import optuna\n",
    "    from optuna.samplers import TPESampler\n",
    "\n",
    "    N_TRIALS = 40\n",
    "    STUDY_NAME = f\"LGBM_{VIEW_TAG}_{BAL_TAG}_AP\"\n",
    "    SAMPLER = TPESampler(seed=RANDOM_STATE, multivariate=True, group=False)\n",
    "    study = optuna.create_study(direction=\"maximize\", study_name=STUDY_NAME, sampler=SAMPLER)\n",
    "\n",
    "    def suggest_lgbm_params(trial):\n",
    "        p = {}\n",
    "        p[\"learning_rate\"]     = trial.suggest_float(\"learning_rate\", 0.005, 0.2, log=True)\n",
    "        p[\"n_estimators\"]      = trial.suggest_int(\"n_estimators\", 800, 3000, step=50)\n",
    "        p[\"num_leaves\"]        = trial.suggest_int(\"num_leaves\", 16, 256)\n",
    "        p[\"max_depth\"]         = trial.suggest_categorical(\"max_depth\", [-1, 4, 6, 8, 10])\n",
    "        p[\"min_child_samples\"] = trial.suggest_int(\"min_child_samples\", 10, 200)\n",
    "        p[\"subsample\"]         = trial.suggest_float(\"subsample\", 0.6, 1.0)\n",
    "        p[\"colsample_bytree\"]  = trial.suggest_float(\"colsample_bytree\", 0.6, 1.0)\n",
    "        p[\"reg_alpha\"]         = trial.suggest_float(\"reg_alpha\", 1e-4, 10.0, log=True)\n",
    "        p[\"reg_lambda\"]        = trial.suggest_float(\"reg_lambda\", 1e-4, 10.0, log=True)\n",
    "        p[\"min_split_gain\"]    = trial.suggest_float(\"min_split_gain\", 0.0, 1.0)\n",
    "        if USE_BALANCED_TRAIN:\n",
    "            p[\"class_weight\"] = None\n",
    "        else:\n",
    "            p[\"class_weight\"] = trial.suggest_categorical(\"class_weight\", [None, \"balanced\"])\n",
    "        p[\"random_state\"] = RANDOM_STATE\n",
    "        p[\"n_jobs\"] = -1\n",
    "        p[\"metric\"] = \"average_precision\"\n",
    "        p[\"verbosity\"] = -1\n",
    "        return p\n",
    "\n",
    "    def objective(trial):\n",
    "        hp = suggest_lgbm_params(trial)\n",
    "        hp = sanitize_params(hp, use_balanced_train=USE_BALANCED_TRAIN)\n",
    "\n",
    "        mdl = LGBMClassifier(**hp)\n",
    "\n",
    "        X_tr, y_tr = X_train_fit, y_train\n",
    "        if USE_BALANCED_TRAIN:\n",
    "            X_tr, y_tr = resample_smote_nc(X_tr, y_tr, feature_names_used, seed=RANDOM_STATE)\n",
    "\n",
    "        fit_call = dict(\n",
    "            eval_set=[(X_val_fit, y_val)],\n",
    "            eval_metric=\"aucpr\",\n",
    "            **_fit_kwargs\n",
    "        )\n",
    "        if _LGBM_CB_OK:\n",
    "            fit_call[\"callbacks\"] = _callbacks\n",
    "\n",
    "        mdl.fit(X_tr, y_tr, **fit_call)\n",
    "        proba_val_t = pred_proba_best(mdl, X_val_fit)\n",
    "        ap = average_precision_score(y_val, proba_val_t)\n",
    "        trial.set_user_attr(\"best_iteration\", getattr(mdl, \"best_iteration_\", None))\n",
    "        return ap\n",
    "\n",
    "    print(f\"[OPTUNA] Iniciando '{STUDY_NAME}' con {N_TRIALS} pruebas…\")\n",
    "    study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=False)\n",
    "\n",
    "    best = study.best_trial\n",
    "    print(f\"[OPTUNA] Mejor AP(val): {best.value:.6f}\")\n",
    "    print(f\"[OPTUNA] Params:\", best.params)\n",
    "    print(f\"[OPTUNA] best_iteration:\", best.user_attrs.get(\"best_iteration\"))\n",
    "\n",
    "    best_params = dict(best.params)\n",
    "    best_params.update({\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "        \"n_jobs\": -1,\n",
    "        \"metric\": \"average_precision\",\n",
    "        \"verbosity\": -1\n",
    "    })\n",
    "    with open(BEST_HP_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(best_params, f, indent=2, ensure_ascii=False)\n",
    "    print(\"[OPTUNA] Guardado BEST en:\", BEST_HP_FILE.name)\n",
    "\n",
    "    tuned_model = LGBMClassifier(**best_params)\n",
    "    fit_call = dict(\n",
    "        eval_set=[(X_val_fit, y_val)],\n",
    "        eval_metric=\"aucpr\",\n",
    "        **_fit_kwargs\n",
    "    )\n",
    "    if _LGBM_CB_OK:\n",
    "        fit_call[\"callbacks\"] = _callbacks\n",
    "    tuned_model.fit(X_train_fit, y_train, **fit_call)\n",
    "    print(\"[OPTUNA] Reentreno final completado. best_iteration_ =\", getattr(tuned_model, \"best_iteration_\", None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec9",
   "metadata": {},
   "source": [
    "## 9 — Cross-Validation (OOF) para baseline/tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "oof",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_oof_cv(model_params, X, y, k_folds=CV_FOLDS, seed=RANDOM_STATE, exp_suffix=\"BASELINE\"):\n",
    "\n",
    "    X_arr = np.asarray(X)\n",
    "    y_arr = np.asarray(y).ravel()\n",
    "    if X_arr.shape[0] != y_arr.shape[0]:\n",
    "        raise ValueError(f\"X y y deben tener el mismo número de filas; X={X_arr.shape}, y={y_arr.shape}\")\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
    "    oof_proba = np.zeros(y_arr.shape[0], dtype=float)\n",
    "    fold_rows = []\n",
    "\n",
    "    base_params = dict(model_params)\n",
    "    base_params.pop(\"verbose\", None)\n",
    "    base_params.setdefault(\"verbosity\", -1)\n",
    "    base_params.setdefault(\"metric\", \"average_precision\")\n",
    "\n",
    "    _fit_kwargs_local = {}\n",
    "    _callbacks_local = []\n",
    "    if _LGBM_CB_OK:\n",
    "        _callbacks_local = [early_stopping(stopping_rounds=200), log_evaluation(period=50)]\n",
    "    else:\n",
    "        _fit_kwargs_local[\"early_stopping_rounds\"] = 200\n",
    "\n",
    "    for f, (tr_idx, va_idx) in enumerate(skf.split(X_arr, y_arr), 1):\n",
    "        X_tr, X_va = X_arr[tr_idx], X_arr[va_idx]\n",
    "        y_tr, y_va = y_arr[tr_idx], y_arr[va_idx]\n",
    "\n",
    "        # ← aquí estaba el error: usar 'and' en lugar de '&&'\n",
    "        if USE_BALANCED_TRAIN and BALANCE_IN_CV:\n",
    "            X_tr, y_tr = SMOTE(random_state=RANDOM_STATE).fit_resample(X_tr, y_tr)\n",
    "\n",
    "        mdl = LGBMClassifier(**base_params)\n",
    "        _fit_call = dict(\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            eval_metric=\"aucpr\",\n",
    "            **_fit_kwargs_local\n",
    "        )\n",
    "        if _LGBM_CB_OK:\n",
    "            _fit_call[\"callbacks\"] = _callbacks_local\n",
    "\n",
    "        mdl.fit(X_tr, y_tr, **_fit_call)\n",
    "\n",
    "        proba_va = pred_proba_best(mdl, X_va)\n",
    "        oof_proba[va_idx] = proba_va\n",
    "\n",
    "        fold_rows.append({\n",
    "            \"fold\": f,\n",
    "            \"pr_auc\": average_precision_score(y_va, proba_va),\n",
    "            \"roc_auc\": roc_auc_score(y_va, proba_va)\n",
    "        })\n",
    "\n",
    "    # Métricas OOF\n",
    "    oof_pr  = average_precision_score(y_arr, oof_proba)\n",
    "    oof_roc = roc_auc_score(y_arr, oof_proba)\n",
    "    thr_oof, _ = find_best_threshold(y_arr, oof_proba, metric=\"f1\")\n",
    "    y_oof_pred = (oof_proba >= thr_oof).astype(int)\n",
    "    oof_f1  = f1_score(y_arr, y_oof_pred, zero_division=0)\n",
    "    oof_rec = recall_score(y_arr, y_oof_pred, zero_division=0)\n",
    "    oof_bal = balanced_accuracy_score(y_arr, y_oof_pred)\n",
    "\n",
    "    # Persistencia\n",
    "    cv_tag = f\"{EXP_NAME}_{exp_suffix}_CV{CV_FOLDS}\"\n",
    "    cv_csv = OUT_RESULTS / f\"cv_summary_{cv_tag}.csv\"\n",
    "    folds_df = pd.DataFrame(fold_rows)\n",
    "    agg_row = pd.DataFrame([{\n",
    "        \"fold\": \"OOF\", \"pr_auc\": oof_pr, \"roc_auc\": oof_roc,\n",
    "        \"thr\": float(thr_oof), \"f1\": oof_f1, \"recall\": oof_rec, \"bal_acc\": oof_bal\n",
    "    }])\n",
    "    cv_df = pd.concat([folds_df, agg_row], ignore_index=True)\n",
    "    cv_df.to_csv(cv_csv, index=False)\n",
    "\n",
    "    oof_path = OUT_PREDS / f\"oof_{cv_tag}.parquet\"\n",
    "    pd.DataFrame({\"oof_proba\": oof_proba, \"y_true\": y_arr}).to_parquet(oof_path, index=False)\n",
    "\n",
    "    print(f\"[CV-{exp_suffix}] Guardados: {cv_csv.name} | {oof_path.name}\")\n",
    "    return {\n",
    "        \"oof_pr_auc\": oof_pr,\n",
    "        \"oof_roc_auc\": oof_roc,\n",
    "        \"thr\": float(thr_oof),\n",
    "        \"oof_f1\": oof_f1,\n",
    "        \"oof_recall\": oof_rec,\n",
    "        \"oof_bal_acc\": oof_bal\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec10",
   "metadata": {},
   "source": [
    "## 10 — Evaluación en test + guardados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "evalsave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.679983\n",
      "[100]\tvalid_0's average_precision: 0.689697\n",
      "[150]\tvalid_0's average_precision: 0.69089\n",
      "[200]\tvalid_0's average_precision: 0.694497\n",
      "[250]\tvalid_0's average_precision: 0.694325\n",
      "[300]\tvalid_0's average_precision: 0.692923\n",
      "[350]\tvalid_0's average_precision: 0.690636\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's average_precision: 0.696254\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.683824\n",
      "[100]\tvalid_0's average_precision: 0.687847\n",
      "[150]\tvalid_0's average_precision: 0.691194\n",
      "[200]\tvalid_0's average_precision: 0.690535\n",
      "[250]\tvalid_0's average_precision: 0.689051\n",
      "[300]\tvalid_0's average_precision: 0.684943\n",
      "[350]\tvalid_0's average_precision: 0.683223\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's average_precision: 0.692515\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.715454\n",
      "[100]\tvalid_0's average_precision: 0.726734\n",
      "[150]\tvalid_0's average_precision: 0.733043\n",
      "[200]\tvalid_0's average_precision: 0.730399\n",
      "[250]\tvalid_0's average_precision: 0.730144\n",
      "[300]\tvalid_0's average_precision: 0.729545\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's average_precision: 0.733374\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.684245\n",
      "[100]\tvalid_0's average_precision: 0.692553\n",
      "[150]\tvalid_0's average_precision: 0.698397\n",
      "[200]\tvalid_0's average_precision: 0.699437\n",
      "[250]\tvalid_0's average_precision: 0.701965\n",
      "[300]\tvalid_0's average_precision: 0.700476\n",
      "[350]\tvalid_0's average_precision: 0.699382\n",
      "[400]\tvalid_0's average_precision: 0.699568\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's average_precision: 0.702631\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.645233\n",
      "[100]\tvalid_0's average_precision: 0.652676\n",
      "[150]\tvalid_0's average_precision: 0.659129\n",
      "[200]\tvalid_0's average_precision: 0.657609\n",
      "[250]\tvalid_0's average_precision: 0.659643\n",
      "[300]\tvalid_0's average_precision: 0.660796\n",
      "[350]\tvalid_0's average_precision: 0.662107\n",
      "[400]\tvalid_0's average_precision: 0.661785\n",
      "[450]\tvalid_0's average_precision: 0.660783\n",
      "[500]\tvalid_0's average_precision: 0.660507\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's average_precision: 0.662979\n",
      "[CV-BASELINE] Guardados: cv_summary_LGBM_REDUCED_PERMcv_thr_SMOTENC_BASELINE_CV5.csv | oof_LGBM_REDUCED_PERMcv_thr_SMOTENC_BASELINE_CV5.parquet\n",
      "[OK][BASE] Guardados: \n",
      "  - Seed HPs   : LGBM_REDUCED_PERMcv_thr_SMOTENC_BASE_seed_params.json \n",
      "  - Fitted HPs : LGBM_REDUCED_PERMcv_thr_SMOTENC_BASE_fitted_params.json \n",
      "  - Importancias: LGBM_REDUCED_PERMcv_thr_SMOTENC_feature_importances.csv \n",
      "  - Preds test  : preds_test_LGBM_REDUCED_PERMcv_thr_SMOTENC.parquet \n",
      "  - Baselines   : baselines.csv\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.679983\n",
      "[100]\tvalid_0's average_precision: 0.689697\n",
      "[150]\tvalid_0's average_precision: 0.69089\n",
      "[200]\tvalid_0's average_precision: 0.694497\n",
      "[250]\tvalid_0's average_precision: 0.694325\n",
      "[300]\tvalid_0's average_precision: 0.692923\n",
      "[350]\tvalid_0's average_precision: 0.690636\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's average_precision: 0.696254\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.683824\n",
      "[100]\tvalid_0's average_precision: 0.687847\n",
      "[150]\tvalid_0's average_precision: 0.691194\n",
      "[200]\tvalid_0's average_precision: 0.690535\n",
      "[250]\tvalid_0's average_precision: 0.689051\n",
      "[300]\tvalid_0's average_precision: 0.684943\n",
      "[350]\tvalid_0's average_precision: 0.683223\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's average_precision: 0.692515\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.715454\n",
      "[100]\tvalid_0's average_precision: 0.726734\n",
      "[150]\tvalid_0's average_precision: 0.733043\n",
      "[200]\tvalid_0's average_precision: 0.730399\n",
      "[250]\tvalid_0's average_precision: 0.730144\n",
      "[300]\tvalid_0's average_precision: 0.729545\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's average_precision: 0.733374\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.684245\n",
      "[100]\tvalid_0's average_precision: 0.692553\n",
      "[150]\tvalid_0's average_precision: 0.698397\n",
      "[200]\tvalid_0's average_precision: 0.699437\n",
      "[250]\tvalid_0's average_precision: 0.701965\n",
      "[300]\tvalid_0's average_precision: 0.700476\n",
      "[350]\tvalid_0's average_precision: 0.699382\n",
      "[400]\tvalid_0's average_precision: 0.699568\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's average_precision: 0.702631\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.645233\n",
      "[100]\tvalid_0's average_precision: 0.652676\n",
      "[150]\tvalid_0's average_precision: 0.659129\n",
      "[200]\tvalid_0's average_precision: 0.657609\n",
      "[250]\tvalid_0's average_precision: 0.659643\n",
      "[300]\tvalid_0's average_precision: 0.660796\n",
      "[350]\tvalid_0's average_precision: 0.662107\n",
      "[400]\tvalid_0's average_precision: 0.661785\n",
      "[450]\tvalid_0's average_precision: 0.660783\n",
      "[500]\tvalid_0's average_precision: 0.660507\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's average_precision: 0.662979\n",
      "[CV-TUNED] Guardados: cv_summary_LGBM_REDUCED_PERMcv_thr_SMOTENC_TUNED_CV5.csv | oof_LGBM_REDUCED_PERMcv_thr_SMOTENC_TUNED_CV5.parquet\n",
      "[OK][TUNED] Guardados: \n",
      "  - Fitted HPs : LGBM_REDUCED_PERMcv_thr_SMOTENC_TUNED_fitted_params.json \n",
      "  - Importancias: LGBM_REDUCED_PERMcv_thr_SMOTENC_TUNED_feature_importances.csv \n",
      "  - Preds test  : preds_test_LGBM_REDUCED_PERMcv_thr_SMOTENC_TUNED.parquet \n",
      "  - Baselines   : baselines.csv\n"
     ]
    }
   ],
   "source": [
    "def plot_pr_curve(y_true, y_proba, title, out_path):\n",
    "    prec, rec, _ = precision_recall_curve(y_true, y_proba)\n",
    "    ap = average_precision_score(y_true, y_proba)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.step(rec, prec, where='post')\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'{title} (AP={ap:.4f})')\n",
    "    plt.grid(True, linestyle='--', alpha=.3)\n",
    "    plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def plot_roc_curve(y_true, y_proba, title, out_path):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "    auc = roc_auc_score(y_true, y_proba)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr, tpr, lw=2); plt.plot([0,1],[0,1], 'k--', lw=1)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{title} (AUC={auc:.4f})')\n",
    "    plt.grid(True, linestyle='--', alpha=.3)\n",
    "    plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def plot_confusion(y_true, y_pred, title, out_path, normalize=False):\n",
    "    norm = 'true' if normalize else None\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize=norm)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    im = plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "    plt.title(title); plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    ticks = np.arange(2)\n",
    "    plt.xticks(ticks, ['0','1']); plt.yticks(ticks, ['0','1'])\n",
    "    thresh = cm.max()/2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            txt = f'{cm[i,j]:.2f}' if normalize else str(cm[i,j])\n",
    "            plt.text(j, i, txt, ha='center', va='center',\n",
    "                     color='white' if cm[i,j] > thresh else 'black')\n",
    "    plt.ylabel('True label'); plt.xlabel('Predicted label')\n",
    "    plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "base = EXP_NAME\n",
    "\n",
    "# === BASELINE ===\n",
    "proba_test = pred_proba_best(model, X_test_fit)\n",
    "\n",
    "cv_base = run_oof_cv(model.get_params(), X_train_fit, y_train, exp_suffix=\"BASELINE\") if DO_CV_BASELINE else {\"thr\": 0.5}\n",
    "thr_oof = float(cv_base[\"thr\"])\n",
    "thr_used = thr_oof\n",
    "\n",
    "y_pred_test = (proba_test >= thr_used).astype(int)\n",
    "test_metrics = compute_all_metrics(y_test, proba_test, thr_used)\n",
    "\n",
    "# Guardar HP baseline\n",
    "params_seed_path = OUT_PARAMS / f\"{base}_BASE_seed_params.json\"\n",
    "with open(params_seed_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(seed_params, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "params_fitted_path = OUT_PARAMS / f\"{base}_BASE_fitted_params.json\"\n",
    "with open(params_fitted_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(model.get_params(), f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Figuras baseline\n",
    "plot_pr_curve(y_val,  proba_val,  f\"{base} — PR (val)\",  OUT_FIGS / f\"{base}_pr_val.png\")\n",
    "plot_pr_curve(y_test, proba_test, f\"{base} — PR (test)\", OUT_FIGS / f\"{base}_pr_test.png\")\n",
    "plot_roc_curve(y_val,  proba_val,  f\"{base} — ROC (val)\",  OUT_FIGS / f\"{base}_roc_val.png\")\n",
    "plot_roc_curve(y_test, proba_test, f\"{base} — ROC (test)\", OUT_FIGS / f\"{base}_roc_test.png\")\n",
    "plot_confusion(y_test, y_pred_test,\n",
    "               f\"{base} — Confusion (test @thr_used={thr_used:.3f})\",\n",
    "               OUT_FIGS / f\"{base}_cm_test.png\")\n",
    "\n",
    "# Importancias baseline\n",
    "try:\n",
    "    imp_gain = model.booster_.feature_importance(importance_type=\"gain\")\n",
    "except Exception:\n",
    "    imp_gain = model.feature_importances_\n",
    "imp_df = (\n",
    "    pd.DataFrame({\n",
    "        \"feature\": feature_names_used[:len(imp_gain)],\n",
    "        \"importance_gain\": imp_gain\n",
    "    }).sort_values(\"importance_gain\", ascending=False)\n",
    ")\n",
    "imp_path = OUT_RESULTS / f\"{base}_feature_importances.csv\"\n",
    "imp_df.to_csv(imp_path, index=False)\n",
    "\n",
    "# Preds test baseline\n",
    "preds_path = OUT_PREDS / f\"preds_test_{base}.parquet\"\n",
    "pd.DataFrame({\"proba\": proba_test, \"y_true\": y_test}).to_parquet(preds_path, index=False)\n",
    "\n",
    "# Registro de resultados baseline\n",
    "row_base = {\n",
    "    \"model\": base,\n",
    "    \"thr_val\": thr_val,\n",
    "    \"thr_oof\": thr_oof,\n",
    "    \"thr_used\": thr_used,\n",
    "    \"val_pr_auc\": val_metrics[\"pr_auc\"],\n",
    "    \"val_roc_auc\": val_metrics[\"roc_auc\"],\n",
    "    \"val_precision\": val_metrics[\"precision\"],\n",
    "    \"val_f1\": val_metrics[\"f1\"],\n",
    "    \"val_recall\": val_metrics[\"recall\"],\n",
    "    \"val_bal_acc\": val_metrics[\"bal_acc\"],\n",
    "    \"test_pr_auc\": test_metrics[\"pr_auc\"],\n",
    "    \"test_roc_auc\": test_metrics[\"roc_auc\"],\n",
    "    \"test_precision\": test_metrics[\"precision\"],\n",
    "    \"test_f1\": test_metrics[\"f1\"],\n",
    "    \"test_recall\": test_metrics[\"recall\"],\n",
    "    \"test_bal_acc\": test_metrics[\"bal_acc\"],\n",
    "    \"best_iteration\": best_iter\n",
    "}\n",
    "res_csv = OUT_RESULTS / \"baselines.csv\"\n",
    "pd.DataFrame([row_base]).to_csv(\n",
    "    res_csv,\n",
    "    mode=(\"a\" if res_csv.exists() else \"w\"),\n",
    "    index=False,\n",
    "    header=not res_csv.exists()\n",
    ")\n",
    "\n",
    "print(\"[OK][BASE] Guardados:\",\n",
    "      \"\\n  - Seed HPs   :\", params_seed_path.name,\n",
    "      \"\\n  - Fitted HPs :\", params_fitted_path.name,\n",
    "      \"\\n  - Importancias:\", imp_path.name,\n",
    "      \"\\n  - Preds test  :\", preds_path.name,\n",
    "      \"\\n  - Baselines   :\", res_csv.name)\n",
    "\n",
    "# === TUNED ===\n",
    "if DO_TUNE and (tuned_model is not None):\n",
    "    proba_val_tuned = pred_proba_best(tuned_model, X_val_fit)\n",
    "    thr_val_tuned, _ = find_best_threshold(y_val, proba_val_tuned, metric=\"f1\")\n",
    "    val_metrics_tuned = compute_all_metrics(y_val, proba_val_tuned, thr_val_tuned)\n",
    "\n",
    "    proba_test_tuned = pred_proba_best(tuned_model, X_test_fit)\n",
    "\n",
    "    cv_tuned = run_oof_cv(tuned_model.get_params(), X_train_fit, y_train, exp_suffix=\"TUNED\") if DO_CV_TUNED else {\"thr\": 0.5}\n",
    "    thr_oof_tuned = float(cv_tuned[\"thr\"])\n",
    "    thr_used_tuned = thr_oof_tuned\n",
    "\n",
    "    y_pred_test_tuned = (proba_test_tuned >= thr_used_tuned).astype(int)\n",
    "    test_metrics_tuned = compute_all_metrics(y_test, proba_test_tuned, thr_used_tuned)\n",
    "\n",
    "    tuned_fitted_path = OUT_PARAMS / f\"{base}_TUNED_fitted_params.json\"\n",
    "    with open(tuned_fitted_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(tuned_model.get_params(), f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    base_t = base + \"_TUNED\"\n",
    "    plot_pr_curve(y_val,  proba_val_tuned,  f\"{base_t} — PR (val)\",  OUT_FIGS / f\"{base_t}_pr_val.png\")\n",
    "    plot_pr_curve(y_test, proba_test_tuned, f\"{base_t} — PR (test)\", OUT_FIGS / f\"{base_t}_pr_test.png\")\n",
    "    plot_roc_curve(y_val,  proba_val_tuned,  f\"{base_t} — ROC (val)\",  OUT_FIGS / f\"{base_t}_roc_val.png\")\n",
    "    plot_roc_curve(y_test, proba_test_tuned, f\"{base_t} — ROC (test)\", OUT_FIGS / f\"{base_t}_roc_test.png\")\n",
    "    plot_confusion(y_test, y_pred_test_tuned,\n",
    "                   f\"{base_t} — Confusion (test @thr_used={thr_used_tuned:.3f})\",\n",
    "                   OUT_FIGS / f\"{base_t}_cm_test.png\")\n",
    "\n",
    "    try:\n",
    "        imp_gain_t = tuned_model.booster_.feature_importance(importance_type=\"gain\")\n",
    "    except Exception:\n",
    "        imp_gain_t = tuned_model.feature_importances_\n",
    "    imp_t_path = OUT_RESULTS / f\"{base_t}_feature_importances.csv\"\n",
    "    (\n",
    "        pd.DataFrame({\"feature\": feature_names_used[:len(imp_gain_t)], \"importance_gain\": imp_gain_t})\n",
    "        .sort_values(\"importance_gain\", ascending=False)\n",
    "        .to_csv(imp_t_path, index=False)\n",
    "    )\n",
    "\n",
    "    preds_t_path = OUT_PREDS / f\"preds_test_{base_t}.parquet\"\n",
    "    pd.DataFrame({\"proba\": proba_test_tuned, \"y_true\": y_test}).to_parquet(preds_t_path, index=False)\n",
    "\n",
    "    row_t = {\n",
    "        \"model\": base_t,\n",
    "        \"thr_val\": thr_val_tuned,\n",
    "        \"thr_oof\": thr_oof_tuned,\n",
    "        \"thr_used\": thr_used_tuned,\n",
    "        \"val_pr_auc\": val_metrics_tuned[\"pr_auc\"],\n",
    "        \"val_roc_auc\": val_metrics_tuned[\"roc_auc\"],\n",
    "        \"val_precision\": val_metrics_tuned[\"precision\"],\n",
    "        \"val_f1\": val_metrics_tuned[\"f1\"],\n",
    "        \"val_recall\": val_metrics_tuned[\"recall\"],\n",
    "        \"val_bal_acc\": val_metrics_tuned[\"bal_acc\"],\n",
    "        \"test_pr_auc\": test_metrics_tuned[\"pr_auc\"],\n",
    "        \"test_roc_auc\": test_metrics_tuned[\"roc_auc\"],\n",
    "        \"test_precision\": test_metrics_tuned[\"precision\"],\n",
    "        \"test_f1\": test_metrics_tuned[\"f1\"],\n",
    "        \"test_recall\": test_metrics_tuned[\"recall\"],\n",
    "        \"test_bal_acc\": test_metrics_tuned[\"bal_acc\"],\n",
    "        \"best_iteration\": getattr(tuned_model, \"best_iteration_\", None)\n",
    "    }\n",
    "    pd.DataFrame([row_t]).to_csv(res_csv, mode=\"a\", index=False, header=False)\n",
    "\n",
    "    print(\"[OK][TUNED] Guardados:\",\n",
    "          \"\\n  - Fitted HPs :\", tuned_fitted_path.name,\n",
    "          \"\\n  - Importancias:\", imp_t_path.name,\n",
    "          \"\\n  - Preds test  :\", preds_t_path.name,\n",
    "          \"\\n  - Baselines   :\", res_csv.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89955053",
   "metadata": {},
   "source": [
    "## 11 — Mejores Resultados + CV-OOF + SOTA + Reporte de features eliminadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d893f7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MEJORES EN TEST (por métrica) ===\n",
      "- test_pr_auc: LGBM_REDUCED_PERMcv_thr_SMOTENC | PR-AUC=0.7086 | ROC-AUC=0.8655 | F1=0.6354 | Recall=0.6658 | Precision=0.6076 | thr_used=0.514 | best_iter=247\n",
      "- test_roc_auc: LGBM_REDUCED_PERMcv_thr_SMOTENC | PR-AUC=0.7086 | ROC-AUC=0.8655 | F1=0.6354 | Recall=0.6658 | Precision=0.6076 | thr_used=0.514 | best_iter=247\n",
      "- test_recall: LGBM_REDUCED_PERMcv_thr_SMOTENC | PR-AUC=0.7086 | ROC-AUC=0.8655 | F1=0.6354 | Recall=0.6658 | Precision=0.6076 | thr_used=0.514 | best_iter=247\n",
      "- test_f1: LGBM_REDUCED_PERMcv_thr_SMOTENC | PR-AUC=0.7086 | ROC-AUC=0.8655 | F1=0.6354 | Recall=0.6658 | Precision=0.6076 | thr_used=0.514 | best_iter=247\n",
      "- test_precision: LGBM_REDUCED_PERMcv_thr_SMOTENC_TUNED | PR-AUC=0.7070 | ROC-AUC=0.8654 | F1=0.5849 | Recall=0.4570 | Precision=0.8122 | thr_used=0.514 | best_iter=135\n",
      "\n",
      "=== RESUMEN CV-OOF ===\n",
      "                                         tag   pr_auc  roc_auc       f1   recall  bal_acc   thr\n",
      "LGBM_REDUCED_PERMcv_thr_SMOTENC_BASELINE_CV5 0.693715 0.858637 0.621456 0.663123 0.771273 0.514\n",
      "   LGBM_REDUCED_PERMcv_thr_SMOTENC_TUNED_CV5 0.693715 0.858637 0.621456 0.663123 0.771273 0.514\n",
      "\n",
      "=== COMPARACIÓN SOTA vs. MEJOR TEST ===\n",
      "Paper LGBM: AUC=0.914 | Recall=0.881 | Precision=0.948\n",
      "Mejor  : AUC=0.8655 | Recall=0.6658 | Precision=0.6076\n",
      "Deltas : ΔAUC=-0.049 | ΔRecall=-0.215\n",
      "\n",
      "=== FEATURES ELIMINADAS ===\n",
      "[FEATURES] Total=15 | Kept=13 | Removed=2\n",
      "- Kept (primeros 13): ['Gender_1', 'Geography_0', 'Geography_1', 'Geography_2', 'HasCrCard_1', 'IsActiveMember_1', 'NumOfProducts_0', 'NumOfProducts_1', 'NumOfProducts_2', 'NumOfProducts_3', 'num__Age', 'num__Balance', 'num__EstimatedSalary']\n",
      "- Removed (primeros 2): ['num__CreditScore', 'num__Tenure']\n",
      "[OK] Feature report guardado en: LGBM_REDUCED_PERMcv_thr_SMOTENC_feature_drop_report.md\n",
      "[OK] Normalizado. Backup: baselines_legacy_backup.csv\n"
     ]
    }
   ],
   "source": [
    "AGGREGATE_ALL_RUNS = False\n",
    "\n",
    "def safe(v, fmt=\".4f\"):\n",
    "    try:\n",
    "        return f\"{float(v):{fmt}}\"\n",
    "    except Exception:\n",
    "        return \"NA\"\n",
    "\n",
    "base_csv = OUT_RESULTS / \"baselines.csv\"\n",
    "if not base_csv.exists():\n",
    "    raise FileNotFoundError(f\"No existe {base_csv}\")\n",
    "\n",
    "df = pd.read_csv(base_csv)\n",
    "\n",
    "needed = [\n",
    "    \"model\",\n",
    "    \"thr_val\", \"thr_oof\", \"thr_used\",\n",
    "    \"val_pr_auc\",\"val_roc_auc\",\"val_precision\",\"val_f1\",\"val_recall\",\"val_bal_acc\",\n",
    "    \"test_pr_auc\",\"test_roc_auc\",\"test_precision\",\"test_f1\",\"test_recall\",\"test_bal_acc\",\n",
    "    \"best_iteration\"\n",
    "]\n",
    "for c in needed:\n",
    "    if c not in df.columns:\n",
    "        df[c] = pd.NA\n",
    "df = df[needed].copy()\n",
    "\n",
    "num_cols = [c for c in needed if c not in (\"model\",)]\n",
    "for c in num_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "if AGGREGATE_ALL_RUNS:\n",
    "    root_art = ARTIF_DIR.parent\n",
    "    for p in (root_art).glob(\"LGBM_*/results/baselines.csv\"):\n",
    "        if p == base_csv: continue\n",
    "        try:\n",
    "            d2 = pd.read_csv(p)\n",
    "            for c in needed:\n",
    "                if c not in d2.columns:\n",
    "                    d2[c] = pd.NA\n",
    "            d2 = d2[needed]\n",
    "            for c in num_cols:\n",
    "                d2[c] = pd.to_numeric(d2[c], errors=\"coerce\")\n",
    "            df = pd.concat([df, d2], ignore_index=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "if df.empty:\n",
    "    raise ValueError(\"El dataframe de resultados está vacío.\")\n",
    "\n",
    "def best_by(metric):\n",
    "    if metric not in df.columns or df[metric].dropna().empty:\n",
    "        return None\n",
    "    r = df.loc[df[metric].idxmax()]\n",
    "    print(\n",
    "        f\"- {metric}: {r['model']} | \"\n",
    "        f\"PR-AUC={safe(r['test_pr_auc'])} | \"\n",
    "        f\"ROC-AUC={safe(r['test_roc_auc'])} | \"\n",
    "        f\"F1={safe(r['test_f1'])} | \"\n",
    "        f\"Recall={safe(r['test_recall'])} | \"\n",
    "        f\"Precision={safe(r['test_precision'])} | \"\n",
    "        f\"thr_used={safe(r['thr_used'], '.3f')} | \"\n",
    "        f\"best_iter={int(r['best_iteration']) if pd.notna(r['best_iteration']) else 'NA'}\"\n",
    "    )\n",
    "    return r\n",
    "\n",
    "print(\"=== MEJORES EN TEST (por métrica) ===\")\n",
    "winners = {}\n",
    "for m in [\"test_pr_auc\",\"test_roc_auc\",\"test_recall\",\"test_f1\",\"test_precision\"]:\n",
    "    w = best_by(m)\n",
    "    if w is not None: winners[m] = w\n",
    "\n",
    "# Resumen CV-OOF\n",
    "cv_files = list(OUT_RESULTS.glob(\"cv_summary_*_CV*.csv\"))\n",
    "if cv_files:\n",
    "    print(\"\\n=== RESUMEN CV-OOF ===\")\n",
    "    rows = []\n",
    "    for f in cv_files:\n",
    "        tag = re.sub(r\"^cv_summary_|\\.csv$\", \"\", f.name)\n",
    "        try:\n",
    "            cv = pd.read_csv(f)\n",
    "            oof = cv.loc[cv[\"fold\"] == \"OOF\"]\n",
    "            if not oof.empty:\n",
    "                r = oof.iloc[0]\n",
    "                rows.append({\n",
    "                    \"tag\": tag,\n",
    "                    \"pr_auc\": r.get(\"pr_auc\"),\n",
    "                    \"roc_auc\": r.get(\"roc_auc\"),\n",
    "                    \"f1\": r.get(\"f1\"),\n",
    "                    \"recall\": r.get(\"recall\"),\n",
    "                    \"bal_acc\": r.get(\"bal_acc\"),\n",
    "                    \"thr\": r.get(\"thr\"),\n",
    "                })\n",
    "        except Exception:\n",
    "            pass\n",
    "    if rows:\n",
    "        print(pd.DataFrame(rows).sort_values([\"pr_auc\",\"roc_auc\"], ascending=False).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n(No se hallaron archivos de CV para este experimento)\")\n",
    "\n",
    "# SOTA\n",
    "SOTA = {\"LGBM\": {\"AUC\": 0.914, \"Recall\": 0.881, \"Precision\": 0.948}}\n",
    "if \"test_roc_auc\" in winners:\n",
    "    bt = winners[\"test_roc_auc\"]\n",
    "    try:\n",
    "        d_auc = float(bt[\"test_roc_auc\"]) - SOTA[\"LGBM\"][\"AUC\"]\n",
    "        d_rec = float(bt[\"test_recall\"])   - SOTA[\"LGBM\"][\"Recall\"]\n",
    "        print(\"\\n=== COMPARACIÓN SOTA vs. MEJOR TEST ===\")\n",
    "        print(f\"Paper LGBM: AUC={SOTA['LGBM']['AUC']:.3f} | Recall={SOTA['LGBM']['Recall']:.3f} | Precision={SOTA['LGBM']['Precision']:.3f}\")\n",
    "        print(f\"Mejor  : AUC={safe(bt['test_roc_auc'])} | Recall={safe(bt['test_recall'])} | Precision={safe(bt['test_precision'])}\")\n",
    "        print(f\"Deltas : ΔAUC={d_auc:+.3f} | ΔRecall={d_rec:+.3f}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# === Reporte de features eliminadas ===\n",
    "fs_path = OUT_RESULTS / f\"{EXP_NAME}_feature_sets.json\"\n",
    "drop_md_path = OUT_RESULTS / f\"{EXP_NAME}_feature_drop_report.md\"\n",
    "\n",
    "if fs_path.exists():\n",
    "    fs = json.loads(fs_path.read_text(encoding=\"utf-8\"))\n",
    "    all_feats  = fs.get(\"all_features\", [])\n",
    "    used_feats = fs.get(\"used_features\", [])\n",
    "    all_set, used_set = set(all_feats), set(used_feats)\n",
    "    removed = sorted(list(all_set - used_set))\n",
    "    kept    = sorted(list(used_set))\n",
    "    msg1 = f\"[FEATURES] Total={len(all_set)} | Kept={len(kept)} | Removed={len(removed)}\"\n",
    "    print(\"\\n=== FEATURES ELIMINADAS ===\")\n",
    "    print(msg1)\n",
    "    # Listados\n",
    "    max_list = 120\n",
    "    if kept:\n",
    "        print(f\"- Kept (primeros {min(len(kept), max_list)}): {kept[:max_list]}\" + (\" ...\" if len(kept)>max_list else \"\"))\n",
    "    if removed:\n",
    "        print(f\"- Removed (primeros {min(len(removed), max_list)}): {removed[:max_list]}\" + (\" ...\" if len(removed)>max_list else \"\"))\n",
    "\n",
    "    drop_md = \"\\n\".join([\n",
    "        \"# Feature Drop Report\",\n",
    "        msg1,\n",
    "        f\"- Kept ({len(kept)}): {kept}\",\n",
    "        f\"- Removed ({len(removed)}): {removed}\",\n",
    "        f\"- Reducción usada: {fs.get('reduction')}\"\n",
    "    ])\n",
    "    drop_md_path.write_text(drop_md, encoding=\"utf-8\")\n",
    "    print(\"[OK] Feature report guardado en:\", drop_md_path.name)\n",
    "else:\n",
    "    print(\"\\n[FEATURES] No se encontró\", fs_path.name, \"(no se puede calcular removidas).\")\n",
    "\n",
    "# Normalización con backup\n",
    "backup = OUT_RESULTS / \"baselines_legacy_backup.csv\"\n",
    "base_csv.replace(backup)\n",
    "df.to_csv(base_csv, index=False)\n",
    "print(\"[OK] Normalizado. Backup:\", backup.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
